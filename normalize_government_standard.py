import json
import csv
import re
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class GovernmentStandardNormalizer:
    """ì •ë¶€ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""

    SPECIAL_CHAR_PATTERN = re.compile(r'[(){}\[\]<>ã€Œã€ã€ã€"\'`]|\s{2,}')

    @staticmethod
    def _clean_text(value: str, max_length: int = None):
        """í…ìŠ¤íŠ¸ ì •ë¦¬ - íŠ¹ìˆ˜ë¬¸ì ì œê±° (DB ì ì¬ìš©)"""
        if not value:
            return ""  # None ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°: (), {}, [], <>, ã€Œã€, ã€ã€, "', `, â€§ (ê°€ìš´ëƒì ), Â· (ì¤‘ì ), âˆ™ (bullet operator) ë“±
        cleaned = re.sub(r'[(){}\[\]<>ã€Œã€ã€ã€"\'`â€§Â·âˆ™ãƒ»]', '', value)
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        if max_length:
            return cleaned[:max_length]
        return cleaned

    @staticmethod
    def _normalize_for_matching(value: str):
        """ë§¤ì¹­ìš© í…ìŠ¤íŠ¸ ì •ê·œí™” - ê´„í˜¸, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ ì œê±°"""
        if not value:
            return ""
        # 1. ëª¨ë“  ê´„í˜¸ì™€ ë‚´ìš© ì œê±°
        text = re.sub(r'[\(\)\[\]\{\}<>ã€Œã€ã€ã€]', '', value)
        # 2. ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì œê±° (ê°€ìš´ëƒì , ì¤‘ì , í•˜ì´í”ˆ, ìŠ¬ë˜ì‹œ ë“±)
        text = re.sub(r'[â€§Â·âˆ™ãƒ»\-_/\\\,\.]', '', text)
        # 3. ëª¨ë“  ê³µë°± ì œê±°
        text = re.sub(r'\s+', '', text)
        # 4. ëŒ€ì†Œë¬¸ì í†µì¼
        text = text.upper()
        return text

    def __init__(self, json_path: str, output_dir: str, db_manager=None):
        self.json_path = Path(json_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.db_manager = db_manager  # Oracle DB ì—°ê²° (PLAN_ID ë§¤ì¹­ìš©)

        # íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ (ì˜ˆ: "2024ë…„ë„ ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš.json" -> 2024)
        document_year = 0000  # ê¸°ë³¸ê°’
        filename = self.json_path.stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…

        import re
        year_match = re.search(r'(20\d{2})', filename)
        if year_match:
            document_year = int(year_match.group(1))

        logger.info(f"ğŸ“… ë¬¸ì„œ ì—°ë„ ì¶”ì¶œ: {filename} -> {document_year}ë…„")

        # ID ì¹´ìš´í„° (Oracle DB í˜•ì‹: ë…„ë„ + ì¼ë ¨ë²ˆí˜¸)
        self.id_counters = {
            'sub_project': 1,
            'raw_data': 1,
        }

        # sub_project_id â†’ PLAN_ID ë§¤í•‘ (Oracle DBìš©)
        self.plan_id_mapping = {}  # {sub_project_id: PLAN_ID}

        # ë°ì´í„° ì €ì¥ì†Œ (Oracle DB ìŠ¤í‚¤ë§ˆì™€ ë™ì¼í•œ êµ¬ì¡°)
        self.data = {
            # ë©”ì¸ í…Œì´ë¸” (TB_PLAN_DATAìš© - íšŒì‚¬ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ)
            'plan_data': [],

            # ì˜ˆì‚° ìƒì„¸ (TB_PLAN_BUDGETìš© - 1:N)
            'budgets': [],

            # ì¼ì • ìƒì„¸ (TB_PLAN_SCHEDULEìš© - 1:N)
            'schedules': [],

            # ì„±ê³¼ ìƒì„¸ (TB_PLAN_PERFORMANCEìš© - 1:N)
            'performances': [],

            # ëŒ€í‘œì„±ê³¼ (TB_PLAN_ACHIEVEMENTSìš© - 1:N)
            'achievements': [],

            # ì›ë³¸ ë°ì´í„° (ê°ì‚¬ìš©, DB ì ì¬ ì•ˆí•¨)
            'raw_data': [],
        }

        # ì»¨í…ìŠ¤íŠ¸
        self.current_context = {
            'sub_project_id': None,
            'document_year': document_year,
            'performance_year': document_year - 1,  # ì„±ê³¼ëŠ” ì „ë…„ë„
            'plan_year': document_year  # ê³„íšì€ ë‹¹í•´ë…„ë„
        }

        # ê²€ì¦ í†µê³„
        self.validation_stats = {
            'total_pages': 0,
            'total_tables': 0,
            'processed_tables': 0,
            'normalized_records': 0,
            'errors': []
        }

        # ê¸°ì¡´ PLAN_DATA ìºì‹œ (YEAR, BIZ_NM, DETAIL_BIZ_NM) -> PLAN_ID
        self.existing_plan_data = {}
        if db_manager:
            self._load_existing_plan_data()

    def _load_existing_plan_data(self):
        """ê¸°ì¡´ PLAN_DATAë¥¼ DBì—ì„œ ë¡œë“œ (ìºì‹œìš©)"""
        logger.info("ğŸ”„ ê¸°ì¡´ PLAN_DATA ë¡œë“œ ì¤‘...")
        try:
            cursor = self.db_manager.connection.cursor()
            query = """
                SELECT PLAN_ID, YEAR, BIZ_NM, DETAIL_BIZ_NM
                FROM TB_PLAN_DATA
                WHERE DELETE_YN = 'N'
            """
            cursor.execute(query)
            for plan_id, year, biz_nm, detail_biz_nm in cursor:
                # âœ… ë§¤ì¹­ìš© ì •ê·œí™” ì ìš© (ê´„í˜¸, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ ì œê±°)
                biz_nm_normalized = self._normalize_for_matching(biz_nm) if biz_nm else ""
                detail_biz_nm_normalized = self._normalize_for_matching(detail_biz_nm) if detail_biz_nm else ""
                key = (year, biz_nm_normalized, detail_biz_nm_normalized)
                self.existing_plan_data[key] = plan_id.strip() if plan_id else None
                # ë””ë²„ê¹…: ì²˜ìŒ 5ê°œ ì¶œë ¥
                if len(self.existing_plan_data) <= 5:
                    logger.info(f"   DB í‚¤: ({year}, '{biz_nm[:30]}...', '{detail_biz_nm[:30]}...') -> {plan_id}")

            cursor.close()
            logger.info(f"âœ… ê¸°ì¡´ PLAN_DATA ë¡œë“œ ì™„ë£Œ: {len(self.existing_plan_data)}ê±´")
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°ì¡´ PLAN_DATA ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _get_next_id(self, entity_type: str) -> int:
        """ID ìƒì„±"""
        current = self.id_counters[entity_type]
        self.id_counters[entity_type] += 1
        return current

    def _save_raw_data(self, data_type: str, content: Any,
                      page_number: int, table_index: int) -> int:
        """ì›ë³¸ ë°ì´í„° ì €ì¥ (ê°ì‚¬ìš©, DBì— ì ì¬í•˜ì§€ ì•ŠìŒ)"""
        raw_id = self._get_next_id('raw_data')

        self.data['raw_data'].append({
            'id': raw_id,
            'data_type': data_type,
            'data_year': self.current_context.get(f'{data_type}_year',
                                                 self.current_context['document_year']),
            'raw_content': json.dumps(content, ensure_ascii=False) if isinstance(content, (dict, list)) else str(content),
            'page_number': page_number,
            'table_index': table_index,
            'created_at': datetime.now().isoformat()
        })

        return raw_id

    def _extract_key_achievements(self, full_text: str, page_number: int) -> List[Dict]:
        """ëŒ€í‘œì„±ê³¼ ì¶”ì¶œ - TB_PLAN_ACHIEVEMENTSìš©"""
        achievements = []

        if not self.current_context.get('sub_project_id'):
            return []

        # âœ… PLAN_IDë¥¼ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')

        # "â‘  ëŒ€í‘œì„±ê³¼" ì„¹ì…˜ ì°¾ê¸°
        match = re.search(r'â‘ \s*ëŒ€í‘œì„±ê³¼(.*?)(?:â‘¡|â‘¢|\(2\)|\(3\)|$)', full_text, re.DOTALL)
        if not match:
            return achievements

        achievement_text = match.group(1).strip()

        # "â—‹" ê¸°í˜¸ë¡œ ê°œë³„ ì„±ê³¼ ë¶„ë¦¬
        individual_achievements = re.split(r'\nâ—‹\s+', achievement_text)

        for idx, achievement in enumerate(individual_achievements):
            achievement = achievement.strip()
            if achievement and len(achievement) > 10:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                achievements.append({
                    'PLAN_ID': plan_id,
                    'ACHIEVEMENT_YEAR': self.current_context['performance_year'],
                    'ACHIEVEMENT_ORDER': idx + 1,
                    'DESCRIPTION': achievement[:4000]  # VARCHAR2(4000) ì œí•œ
                })

        return achievements

    def _aggregate_plan_data_fields(self):
        """
        í•˜ìœ„ í…Œì´ë¸”(BUDGET, SCHEDULE)ì—ì„œ ê³„ì‚°í•œ ë°ì´í„°ë¥¼ TB_PLAN_DATA ì§‘ê³„ í•„ë“œì— ì±„ìš°ê¸°
        - RESPERIOD, CUR_RESPERIOD (ì—°êµ¬ê¸°ê°„)
        - BIZ_SDT, BIZ_EDT (ì‚¬ì—… ì‹œì‘ì¼/ì¢…ë£Œì¼)
        - TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV (ì´ ì—°êµ¬ë¹„)
        - CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV (ë‹¹í•´ì—°ë„ ì—°êµ¬ë¹„)
        - PERFORM_PRC, PLAN_PRC (ì‹¤ì /ê³„íš ë¹„ìš©)
        """
        logger.info("ğŸ“Š TB_PLAN_DATA ì§‘ê³„ í•„ë“œ ê³„ì‚° ì¤‘...")

        for plan_data in self.data['plan_data']:
            plan_id = plan_data['PLAN_ID']
            doc_year = plan_data['YEAR']

            # ============================================================
            # 1. ì˜ˆì‚° ë°ì´í„°ë¡œë¶€í„° ì§‘ê³„ (TB_PLAN_BUDGET)
            # ============================================================
            plan_budgets = [b for b in self.data['budgets'] if b['PLAN_ID'] == plan_id]

            if plan_budgets:
                # ì´ ì—°êµ¬ë¹„ ì§‘ê³„ (ëª¨ë“  ì—°ë„ í•©ì‚°)
                total_gov = sum(b.get('GOV_AMOUNT') or 0 for b in plan_budgets)
                total_private = sum(b.get('PRIVATE_AMOUNT') or 0 for b in plan_budgets)
                total_local = sum(b.get('LOCAL_AMOUNT') or 0 for b in plan_budgets)
                total_etc = sum(b.get('ETC_AMOUNT') or 0 for b in plan_budgets)
                total_all = total_gov + total_private + total_local + total_etc

                plan_data['TOTAL_RESPRC'] = f"{total_all:,.0f}" if total_all > 0 else None
                plan_data['TOTAL_RESPRC_GOV'] = total_gov if total_gov > 0 else None
                plan_data['TOTAL_RESPRC_CIV'] = total_private if total_private > 0 else None

                # ë‹¹í•´ì—°ë„ ì—°êµ¬ë¹„ ì§‘ê³„ (ë¬¸ì„œ ì—°ë„ë§Œ)
                cur_year_budgets = [b for b in plan_budgets if b.get('BUDGET_YEAR') == doc_year]
                cur_gov = sum(b.get('GOV_AMOUNT') or 0 for b in cur_year_budgets)
                cur_private = sum(b.get('PRIVATE_AMOUNT') or 0 for b in cur_year_budgets)
                cur_local = sum(b.get('LOCAL_AMOUNT') or 0 for b in cur_year_budgets)
                cur_etc = sum(b.get('ETC_AMOUNT') or 0 for b in cur_year_budgets)
                cur_all = cur_gov + cur_private + cur_local + cur_etc

                plan_data['CUR_RESPRC'] = f"{cur_all:,.0f}" if cur_all > 0 else None
                plan_data['CUR_RESPRC_GOV'] = cur_gov if cur_gov > 0 else None
                plan_data['CUR_RESPRC_CIV'] = cur_private if cur_private > 0 else None

                # ì‹¤ì  ë¹„ìš© (ì‹¤ì  ì—°ë„ í•©ì‚°)
                perform_budgets = [b for b in plan_budgets if b.get('CATEGORY') == 'ì‹¤ì ']
                perform_total = sum(b.get('TOTAL_AMOUNT') or 0 for b in perform_budgets)
                plan_data['PERFORM_PRC'] = perform_total if perform_total > 0 else None

                # ê³„íš ë¹„ìš© (ê³„íš ì—°ë„ í•©ì‚°)
                plan_budgets_only = [b for b in plan_budgets if b.get('CATEGORY') == 'ê³„íš']
                plan_total = sum(b.get('TOTAL_AMOUNT') or 0 for b in plan_budgets_only)
                plan_data['PLAN_PRC'] = plan_total if plan_total > 0 else None

                # ì—°êµ¬ê¸°ê°„ ê³„ì‚° (ì˜ˆì‚° í…Œì´ë¸”ì˜ ìµœì†Œ~ìµœëŒ€ ì—°ë„)
                all_years = [b['BUDGET_YEAR'] for b in plan_budgets if b.get('BUDGET_YEAR')]
                if all_years:
                    min_year = min(all_years)
                    max_year = max(all_years)
                    plan_data['RESPERIOD'] = f"{min_year}~{max_year}"

                    # ë‹¹í•´ì—°ë„ ì—°êµ¬ê¸°ê°„ (ë¬¸ì„œ ì—°ë„ë§Œ)
                    if doc_year in all_years:
                        plan_data['CUR_RESPERIOD'] = f"{doc_year}"

            # ============================================================
            # 2. ì¼ì • ë°ì´í„°ë¡œë¶€í„° ì‚¬ì—… ì‹œì‘ì¼/ì¢…ë£Œì¼ (TB_PLAN_SCHEDULE)
            # ============================================================
            plan_schedules = [s for s in self.data['schedules'] if s['PLAN_ID'] == plan_id]

            if plan_schedules:
                # START_DATEê°€ ìˆëŠ” ë ˆì½”ë“œì—ì„œ ìµœì†Œê°’
                start_dates = [s.get('START_DATE') for s in plan_schedules if s.get('START_DATE')]
                if start_dates:
                    plan_data['BIZ_SDT'] = min(start_dates)

                # END_DATEê°€ ìˆëŠ” ë ˆì½”ë“œì—ì„œ ìµœëŒ€ê°’
                end_dates = [s.get('END_DATE') for s in plan_schedules if s.get('END_DATE')]
                if end_dates:
                    plan_data['BIZ_EDT'] = max(end_dates)

        logger.info("âœ… TB_PLAN_DATA ì§‘ê³„ ì™„ë£Œ")

    def _extract_plan_details(self, full_text: str, page_number: int) -> List[Dict]:
        """ì£¼ìš” ì¶”ì§„ê³„íš ë‚´ìš© ì¶”ì¶œ"""
        plans = []

        # "â‘  ì£¼ìš” ì¶”ì§„ê³„íš ë‚´ìš©" ì„¹ì…˜ ì°¾ê¸°
        match = re.search(r'â‘ \s*ì£¼ìš”\s*ì¶”ì§„ê³„íš\s*ë‚´ìš©(.*?)(?:â‘¡|â‘¢|\(2\)|\(3\)|$)', full_text, re.DOTALL)

        # íŒ¨í„´1ì´ ì—†ìœ¼ë©´ "(3) ë…„ë„ ì¶”ì§„ê³„íš" ì„¹ì…˜ì—ì„œ â‘  ì´í›„ ë‚´ìš© ì°¾ê¸° (ì—°ë„ ë¬´ê´€)
        if not match:
            match = re.search(r'\(3\)\s*\d{4}ë…„ë„\s*ì¶”ì§„ê³„íš\s*â‘ \s*(.*?)(?:â‘¡|â‘¢|$)', full_text, re.DOTALL)

        if not match:
            return []

        plan_text = match.group(1).strip()

        # "â—‹" ë˜ëŠ” "-" ê¸°í˜¸ë¡œ ê°œë³„ ê³„íš ë¶„ë¦¬
        individual_plans = re.split(r'\n[â—‹\-]\s+', plan_text)

        for idx, plan in enumerate(individual_plans):
            plan = plan.strip()
            if plan and len(plan) > 5:
                plans.append({
                    'sub_project_id': self.current_context['sub_project_id'],
                    'plan_year': self.current_context['plan_year'],
                    'plan_order': idx + 1,
                    'description': plan,
                    'page_number': page_number
                })

        return plans

    def _extract_qualitative_achievements(self, full_text: str, page_num: int) -> List[Dict]:
        """ì •ì„±ì  ì„±ê³¼ ì¶”ì¶œ (í…ìŠ¤íŠ¸ ê¸°ë°˜)"""
        normalized = []

        if not self.current_context.get('sub_project_id'):
            return []

        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')
        year = self.current_context.get('plan_year', self.current_context.get('document_year'))

        # "ì¶”ì§„ì‹¤ì ", "ì£¼ìš”ì„±ê³¼" ì„¹ì…˜ ì°¾ê¸°
        patterns = [
            r'(?:ì¶”ì§„ì‹¤ì |ì£¼ìš”ì„±ê³¼)\s*[:\n]?\s*(.*?)(?=\n\n|$|\(2\)|â‘¡)',
            r'â—‹\s*(?:ì¶”ì§„ì‹¤ì |ì£¼ìš”ì„±ê³¼)\s*(.*?)(?=â—‹|$)',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, full_text, re.DOTALL)
            for match in matches:
                content = match.strip()
                if len(content) > 10:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì—¬ëŸ¬ í•­ëª© ì¶”ì¶œ
                    items = [item.strip() for item in content.split('\n') if item.strip()]

                    for item in items:
                        # ë¶ˆë¦¿ í¬ì¸íŠ¸ë‚˜ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” í•­ëª©
                        if re.match(r'^[â€¢\-\d).]\s*', item):
                            normalized.append({
                                'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                'PERFORMANCE_YEAR': year,
                                'PERFORMANCE_TYPE': 'ì •ì„±ì ì‹¤ì ',
                                'CATEGORY': 'ì¶”ì§„ì‹¤ì ',
                                'VALUE': None,
                                'UNIT': None,
                                'ORIGINAL_TEXT': item[:4000]
                            })

        return normalized

    def _normalize_schedule_data(self, period: str, task: str, detail: str,
                                raw_data_id: int) -> List[Dict]:
        """ì¼ì • ë°ì´í„° ì •ê·œí™” - ì„¸ë¶€ì¼ì •(task/detail)ì—ì„œ ì‹¤ì œ ë‚ ì§œ ì¶”ì¶œ"""
        normalized = []
        year = self.current_context['plan_year']

        if not self.current_context.get('sub_project_id'):
            return []

        # âœ… PLAN_ID ê°€ì ¸ì˜¤ê¸°
        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')

        if not period or not task or period in ['êµ¬ë¶„', 'ì¶”ì§„ì¼ì •', 'ì¶”ì§„ì‚¬í•­', 'í•­ëª©', 'ì£¼ìš”ë‚´ìš©']:
            return []

        # âœ… taskì™€ detailì„ í•©ì³ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
        full_task_text = f"{task}\n{detail}" if detail else task

        # taskë¥¼ ê°œë³„ í•­ëª©ìœ¼ë¡œ ë¶„ë¦¬
        task_items = []
        if 'â€¢' in full_task_text:
            parts = full_task_text.split('â€¢')
            for part in parts:
                part = part.strip()
                if part:
                    task_items.append('â€¢ ' + part)
        else:
            task_items = [full_task_text]

        def get_quarter_end_date(year: int, quarter: int) -> str:
            month_end = quarter * 3
            return f"{year}-{month_end:02d}-{[31,30,30,31][quarter-1]:02d}"

        # âœ… ì„¸ë¶€ì¼ì • í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ë‚ ì§œ ì¶”ì¶œ
        def extract_month_range_from_detail(text):
            """
            ì„¸ë¶€ì¼ì •ì—ì„œ ì‹¤ì œ ë‚ ì§œ ì¶”ì¶œ:
            - '20.1ì›”~12ì›”
            - 1ì›”~3ì›”
            - 21ë…„ 1ì›”
            """
            # íŒ¨í„´ 1: "'20.1ì›”~12ì›”", "'21.1ì›”~3ì›”"
            match1 = re.search(r"'(\d{2})\.(\d+)ì›”\s*[~\-]\s*(\d+)ì›”", text)
            if match1:
                year_short = int(match1.group(1))
                start_month = int(match1.group(2))
                end_month = int(match1.group(3))
                full_year = 2000 + year_short
                return (full_year, start_month, end_month)

            # íŒ¨í„´ 2: "1ì›”~12ì›”", "1ì›” ~ 3ì›”"
            match2 = re.search(r'(\d+)ì›”\s*[~\-]\s*(\d+)ì›”', text)
            if match2:
                start_month = int(match2.group(1))
                end_month = int(match2.group(2))
                return (year, start_month, end_month)

            # íŒ¨í„´ 3: "'20.1~12", "2020.1~12"
            match3 = re.search(r"'?(\d{2,4})\.(\d+)\s*[~\-]\s*(\d+)", text)
            if match3:
                year_str = match3.group(1)
                full_year = 2000 + int(year_str) if len(year_str) == 2 else int(year_str)
                start_month = int(match3.group(2))
                end_month = int(match3.group(3))
                return (full_year, start_month, end_month)

            # íŒ¨í„´ 4: "21ë…„ 1ì›”" (ë‹¨ì¼ ì›”)
            match4 = re.search(r'(\d{2})ë…„\s*(\d+)ì›”', text)
            if match4:
                year_short = int(match4.group(1))
                month = int(match4.group(2))
                full_year = 2000 + year_short
                return (full_year, month, month)

            return None

        def extract_quarters(period_text):
            quarters = []
            if '~' in period_text and 'ë¶„ê¸°' in period_text:
                quarter_match = re.search(r'(\d)/4\s*ë¶„ê¸°\s*~\s*(\d)/4\s*ë¶„ê¸°', period_text)
                if quarter_match:
                    start_q = int(quarter_match.group(1))
                    end_q = int(quarter_match.group(2))
                    quarters = list(range(start_q, end_q + 1))
            elif 'ì—°ì¤‘' in period_text:
                quarters = [1, 2, 3, 4]
            elif 'ë¶„ê¸°' in period_text:
                quarter_match = re.search(r'(\d)/4\s*ë¶„ê¸°', period_text)
                if quarter_match:
                    quarters = [int(quarter_match.group(1))]
            return quarters

        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')

        for task_item in task_items:
            task_item = task_item.strip()
            if not task_item:
                continue

            task_category = ""
            if 'â€¢' in task_item:
                first_line = task_item.split('\n')[0].replace('â€¢', '').strip()
                task_category = first_line

            # âœ… 1ìˆœìœ„: ì„¸ë¶€ì¼ì •ì—ì„œ ì‹¤ì œ ë‚ ì§œ ì¶”ì¶œ
            month_info = extract_month_range_from_detail(task_item)

            if month_info:
                parsed_year, start_month, end_month = month_info
                import calendar
                last_day = calendar.monthrange(parsed_year, end_month)[1]

                record = {
                    'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                    'SCHEDULE_YEAR': parsed_year,
                    'QUARTER': f"{start_month}ì›”~{end_month}ì›”",
                    'TASK_NAME': task_category[:768] if task_category else None,
                    'TASK_CONTENT': task_item[:4000] if task_item else None,
                    'START_DATE': f"{parsed_year}-{start_month:02d}-01",
                    'END_DATE': f"{parsed_year}-{end_month:02d}-{last_day:02d}"
                }
                normalized.append(record)
            else:
                # âœ… 2ìˆœìœ„: periodì˜ ë¶„ê¸°ë¡œ ëŒ€ì²´
                quarters = extract_quarters(period)

                if quarters:
                    for quarter in quarters:
                        record = {
                            'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                            'SCHEDULE_YEAR': year,
                            'QUARTER': f"{quarter}/4ë¶„ê¸°",
                            'TASK_NAME': task_category[:768] if task_category else None,
                            'TASK_CONTENT': task_item[:4000] if task_item else None,
                            'START_DATE': f"{year}-{(quarter-1)*3+1:02d}-01",
                            'END_DATE': get_quarter_end_date(year, quarter)
                        }
                        normalized.append(record)
                else:
                    record = {
                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                        'SCHEDULE_YEAR': year,
                        'QUARTER': 'ì—°ì¤‘',
                        'TASK_NAME': task_category[:768] if task_category else None,
                        'TASK_CONTENT': task_item[:4000] if task_item else None,
                        'START_DATE': f"{year}-01-01",
                        'END_DATE': f"{year}-12-31"
                    }
                    normalized.append(record)

        return normalized

    def _normalize_performance_table(self, rows: List[List], raw_data_id: int) -> List[Dict]:
        """ì„±ê³¼ í…Œì´ë¸” ì •ê·œí™” - PLAN_IDë§Œ ì‚¬ìš©"""
        normalized = []
        year = self.current_context['performance_year']

        if not rows or len(rows) < 2:
            return []

        if not self.current_context.get('sub_project_id'):
            return []

        # âœ… PLAN_ID ê°€ì ¸ì˜¤ê¸°
        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')

        # í…Œì´ë¸” íƒ€ì… ê°ì§€
        header_text = ' '.join(str(c) for c in rows[0]).lower()

        # 1. íŠ¹í—ˆ/ë…¼ë¬¸ ë³µí•© í…Œì´ë¸”
        if 'íŠ¹í—ˆì„±ê³¼' in header_text and 'ë…¼ë¬¸ì„±ê³¼' in header_text:
            if len(rows) >= 4:
                data_row = rows[-1]

                # íŠ¹í—ˆ ë°ì´í„°
                for indicator_type, idx in [('êµ­ë‚´ì¶œì›', 0), ('êµ­ë‚´ë“±ë¡', 1), ('êµ­ì™¸ì¶œì›', 2), ('êµ­ì™¸ë“±ë¡', 3)]:
                    if idx < len(data_row):
                        try:
                            val_str = str(data_row[idx]).replace(',', '').strip()
                            if val_str and val_str != '-':
                                val = float(val_str)
                                if val > 0:
                                    normalized.append({
                                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                        'PERFORMANCE_YEAR': year,
                                        'PERFORMANCE_TYPE': 'íŠ¹í—ˆ',
                                        'CATEGORY': indicator_type,
                                        'VALUE': val,
                                        'UNIT': 'ê±´',
                                        'ORIGINAL_TEXT': str(rows)[:4000]
                                    })
                        except: pass

                # ë…¼ë¬¸ ë°ì´í„°
                for indicator_type, idx in [('IF20ì´ìƒ', 4), ('IF10ì´ìƒ', 5), ('SCIE', 6), ('ë¹„SCIE', 7)]:
                    if idx < len(data_row):
                        try:
                            val_str = str(data_row[idx]).replace(',', '').strip()
                            if val_str and val_str != '-':
                                val = float(val_str)
                                if val > 0:
                                    normalized.append({
                                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                        'PERFORMANCE_YEAR': year,
                                        'PERFORMANCE_TYPE': 'ë…¼ë¬¸',
                                        'CATEGORY': indicator_type,
                                        'VALUE': val,
                                        'UNIT': 'í¸',
                                        'ORIGINAL_TEXT': str(rows)[:4000]
                                    })
                        except: pass

        # 2. ê¸°ìˆ ì´ì „ í…Œì´ë¸”
        elif 'ê¸°ìˆ ì´ì „' in header_text or 'ê¸°ìˆ ë£Œ' in header_text:
            if len(rows) >= 3:
                data_row = rows[-1]
                indicators = [('ê¸°ìˆ ì§€ë„', 0, 'ê±´'), ('ê¸°ìˆ ì´ì „', 1, 'ê±´'), ('ê¸°ìˆ ë£Œ', 3, 'ë°±ë§Œì›')]

                for category, idx, unit in indicators:
                    if idx < len(data_row):
                        try:
                            val_str = str(data_row[idx]).replace(',', '').strip()
                            if val_str and val_str != '-':
                                val = float(val_str)
                                if val > 0:
                                    normalized.append({
                                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                        'PERFORMANCE_YEAR': year,
                                        'PERFORMANCE_TYPE': 'ê¸°ìˆ ì´ì „',
                                        'CATEGORY': category,
                                        'VALUE': val,
                                        'UNIT': unit,
                                        'ORIGINAL_TEXT': str(rows)[:4000]
                                    })
                        except: pass

        # 3. êµ­ì œí˜‘ë ¥ í…Œì´ë¸”
        elif 'êµ­ì œí˜‘ë ¥' in header_text or 'í•´ì™¸ì—°êµ¬ì' in header_text:
            if len(rows) >= 3:
                data_row = rows[-1]
                indicators = [('í•´ì™¸ì—°êµ¬ììœ ì¹˜', 0, 'ëª…'), ('êµ­ë‚´ì—°êµ¬ìíŒŒê²¬', 1, 'ëª…'), ('êµ­ì œí•™ìˆ íšŒì˜ê°œìµœ', 2, 'ê±´')]

                for category, idx, unit in indicators:
                    if idx < len(data_row):
                        try:
                            val_str = str(data_row[idx]).replace(',', '').strip()
                            if val_str and val_str != '-':
                                val = float(val_str)
                                if val > 0:
                                    normalized.append({
                                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                        'PERFORMANCE_YEAR': year,
                                        'PERFORMANCE_TYPE': 'êµ­ì œí˜‘ë ¥',
                                        'CATEGORY': category,
                                        'VALUE': val,
                                        'UNIT': unit,
                                        'ORIGINAL_TEXT': str(rows)[:4000]
                                    })
                        except: pass

        # 4. ì¸ë ¥ì–‘ì„± í…Œì´ë¸”
        elif 'í•™ìœ„ë°°ì¶œ' in header_text or 'ë°•ì‚¬' in header_text:
            if len(rows) >= 3:
                data_row = rows[-1]
                indicators = [('ë°•ì‚¬ë°°ì¶œ', 0, 'ëª…'), ('ì„ì‚¬ë°°ì¶œ', 1, 'ëª…'), ('ì—°êµ¬ê³¼ì œì°¸ì—¬ì¸ë ¥', 4, 'ëª…')]

                for category, idx, unit in indicators:
                    if idx < len(data_row):
                        try:
                            val_str = str(data_row[idx]).replace(',', '').strip()
                            if val_str and val_str != '-':
                                val = float(val_str)
                                if val > 0:
                                    normalized.append({
                                        'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                                        'PERFORMANCE_YEAR': year,
                                        'PERFORMANCE_TYPE': 'ì¸ë ¥ì–‘ì„±',
                                        'CATEGORY': category,
                                        'VALUE': val,
                                        'UNIT': unit,
                                        'ORIGINAL_TEXT': str(rows)[:4000]
                                    })
                        except: pass

        return normalized

    def _normalize_budget_data(self, rows: List[List], raw_data_id: int) -> List[Dict]:
        """ì˜ˆì‚° ë°ì´í„° ì •ê·œí™” - Oracle TB_PLAN_BUDGET ìŠ¤í‚¤ë§ˆì— ë§ì¶¤"""
        normalized = []

        if not rows or len(rows) < 2:
            return []

        if not self.current_context.get('sub_project_id'):
            return []

        # âœ… PLAN_IDë¥¼ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ (ë‚˜ì¤‘ì— ë§¤ì¹­)
        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'], '')

        # 1ë‹¨ê³„: ì—°ë„ ì»¬ëŸ¼ íŒŒì‹±
        year_columns = {}  # {ì»¬ëŸ¼ ì¸ë±ìŠ¤: (ì—°ë„, ì‹¤ì /ê³„íš)}
        first_row = rows[0]

        for col_idx, cell in enumerate(first_row):
            cell_str = str(cell).strip()
            lines = cell_str.split('\n')
            year = None
            category = 'ê³„íš'

            for line in lines:
                line = line.strip()
                year_match = re.search(r'(20\d{2})', line)
                if year_match:
                    year = int(year_match.group(1))
                if 'ì‹¤ì ' in line:
                    category = 'ì‹¤ì '
                elif 'ê³„íš' in line:
                    category = 'ê³„íš'

            if year:
                year_columns[col_idx] = (year, category)

        if not year_columns:
            return []

        # 2ë‹¨ê³„: ì˜ˆì‚° íƒ€ì…ë³„ë¡œ ê¸ˆì•¡ ì§‘ê³„ (ì—°ë„ë³„ë¡œ ê·¸ë£¹í™”)
        budget_by_year = {}  # {(year, category): {gov: amount, private: amount, ...}}

        for row_idx, row in enumerate(rows[1:], 1):
            if not any(cell for cell in row if cell and str(cell).strip()):
                continue

            # ì˜ˆì‚° íƒ€ì… ì¶”ì¶œ (ë³´í†µ 3ë²ˆì§¸ ì»¬ëŸ¼)
            budget_type_col_idx = 2
            for idx, cell in enumerate(first_row):
                if 'êµ¬ ë¶„' in str(cell) or 'êµ¬ë¶„' in str(cell):
                    budget_type_col_idx = idx
                    break

            if budget_type_col_idx >= len(row):
                continue

            budget_type_text = str(row[budget_type_col_idx]).strip()

            # ìŠ¤í‚µ í‚¤ì›Œë“œ
            if any(kw in budget_type_text for kw in ['ì†Œê³„', 'í•©ê³„', 'ì´ê³„', 'ì‚¬ì—…ëª…', 'êµ¬ë¶„']):
                continue

            # ì˜ˆì‚° íƒ€ì… ë§¤í•‘
            budget_type_key = None
            if 'ì •ë¶€' in budget_type_text or 'êµ­ë¹„' in budget_type_text:
                budget_type_key = 'gov'
            elif 'ë¯¼ê°„' in budget_type_text:
                budget_type_key = 'private'
            elif 'ì§€ë°©' in budget_type_text:
                budget_type_key = 'local'
            else:
                budget_type_key = 'etc'

            # ê° ì—°ë„ ì»¬ëŸ¼ì˜ ê¸ˆì•¡ ì¶”ì¶œ
            for col_idx, (year, category) in year_columns.items():
                if col_idx >= len(row):
                    continue

                cell_str = str(row[col_idx]).strip()
                if not cell_str or cell_str in ['-', '', 'nan']:
                    continue

                try:
                    amount = float(cell_str.replace(',', '').replace('ë°±ë§Œì›', '').strip().split('\n')[0])
                    if amount <= 0:
                        continue

                    key = (year, category)
                    if key not in budget_by_year:
                        budget_by_year[key] = {'gov': 0, 'private': 0, 'local': 0, 'etc': 0}
                    budget_by_year[key][budget_type_key] += amount

                except (ValueError, TypeError):
                    continue

        # 3ë‹¨ê³„: Oracle ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë ˆì½”ë“œ ìƒì„±
        for (year, category), amounts in budget_by_year.items():
            total = amounts['gov'] + amounts['private'] + amounts['local'] + amounts['etc']

            record = {
                'PLAN_ID': plan_id,  # âœ… ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©
                'BUDGET_YEAR': year,
                'CATEGORY': category,
                'TOTAL_AMOUNT': total if total > 0 else None,
                'GOV_AMOUNT': amounts['gov'] if amounts['gov'] > 0 else None,
                'PRIVATE_AMOUNT': amounts['private'] if amounts['private'] > 0 else None,
                'LOCAL_AMOUNT': amounts['local'] if amounts['local'] > 0 else None,
                'ETC_AMOUNT': amounts['etc'] if amounts['etc'] > 0 else None,
                'PERFORM_PRC': total if category == 'ì‹¤ì ' else None,
                'PLAN_PRC': total if category == 'ê³„íš' else None
            }
            normalized.append(record)

        return normalized

    def _process_overview(self, full_text: str, tables: List[Dict], page_number: int, raw_data_id: int):
        """ì‚¬ì—…ê°œìš” ì²˜ë¦¬ - TB_PLAN_DATA ì—…ë°ì´íŠ¸ (ê°œì„  ë²„ì „)"""

        if not self.current_context.get('sub_project_id'):
            return

        # âœ… PLAN_IDë¥¼ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ None (ì—…ë°ì´íŠ¸ ë¶ˆê°€)
        plan_id = self.plan_id_mapping.get(self.current_context['sub_project_id'])
        if not plan_id:
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ TEMP_ë¡œ ì‹œì‘í•˜ë©´ ì§„í–‰ (ë‚˜ì¤‘ì— ë§¤ì¹­)
            plan_id = ''

        # í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (ë‹¤ì–‘í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        overview_data = {}
        for table in tables:
            rows = table.get('data', [])
            for row in rows:
                if len(row) >= 2:
                    key = str(row[0]).strip()
                    value = str(row[1]).strip()
                    if key and value:
                        overview_data[key] = value

        # ëŒ€ì²´ í‚¤ì›Œë“œ ë§¤í•‘
        def get_value_with_alternatives(data: dict, *keys):
            """ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ì‹œë„í•˜ì—¬ ê°’ ì°¾ê¸°"""
            for key in keys:
                if key in data and data[key]:
                    return data[key]
            return None

        # full_textì—ì„œ ì‚¬ì—…ëª©í‘œ, ì‚¬ì—…ë‚´ìš© ì¶”ì¶œ (ë‹¤ì–‘í•œ íŒ¨í„´)
        objective = ""
        content = ""

        # ì‚¬ì—…ëª©í‘œ ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
        obj_patterns = [
            r'â—‹\s*ì‚¬ì—…ëª©í‘œ\s*(.*?)(?:â—‹\s*ì‚¬ì—…ë‚´ìš©|â—‹\s*ì¶”ì§„ë‚´ìš©|\(2\)|â‘¡|$)',
            r'ì‚¬ì—…\s*ëª©í‘œ\s*[:\s]*(.*?)(?:ì‚¬ì—…\s*ë‚´ìš©|ì¶”ì§„\s*ë‚´ìš©|\(2\)|â‘¡|$)',
            r'ìµœì¢…\s*ëª©í‘œ\s*[:\s]*(.*?)(?:ì‚¬ì—…\s*ë‚´ìš©|ì¶”ì§„\s*ë‚´ìš©|\(2\)|â‘¡|$)',
        ]
        for pattern in obj_patterns:
            match = re.search(pattern, full_text, re.DOTALL | re.IGNORECASE)
            if match:
                objective = match.group(1).strip()
                if len(objective) > 10:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    break

        # ì‚¬ì—…ë‚´ìš© ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
        content_patterns = [
            r'â—‹\s*ì‚¬ì—…ë‚´ìš©\s*(.*?)(?:\(2\)|â‘¡|â‘¢|$)',
            r'ì‚¬ì—…\s*ë‚´ìš©\s*[:\s]*(.*?)(?:\(2\)|â‘¡|â‘¢|$)',
            r'ì¶”ì§„\s*ë‚´ìš©\s*[:\s]*(.*?)(?:\(2\)|â‘¡|â‘¢|$)',
        ]
        for pattern in content_patterns:
            match = re.search(pattern, full_text, re.DOTALL | re.IGNORECASE)
            if match:
                content = match.group(1).strip()
                if len(content) > 10:
                    break

        # âœ¨ ì‹ ê·œ: í…ìŠ¤íŠ¸ ë³¸ë¬¸ì—ì„œ ì£¼ê´€ê¸°ê´€, ê´€ë¦¬ê¸°ê´€ ì¶”ì¶œ (PDF êµ¬ì¡° ë°˜ì˜)
        lead_organ_text = None
        mng_organ_text = None

        # ì£¼ê´€ê¸°ê´€ íŒ¨í„´ (ì˜ˆ: "â—‹ ì£¼ê´€ê¸°ê´€ : ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€")
        lead_patterns = [
            r'â—‹\s*ì£¼ê´€ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
            r'ì£¼ê´€\s*ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
            r'â—‹\s*ì¶”ì§„ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
        ]
        for pattern in lead_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                lead_organ_text = match.group(1).strip()
                if len(lead_organ_text) > 2:
                    break

        # ê´€ë¦¬ê¸°ê´€ íŒ¨í„´ (ì˜ˆ: "â—‹ ê´€ë¦¬ê¸°ê´€ : í•œêµ­ì—°êµ¬ì¬ë‹¨")
        mng_patterns = [
            r'â—‹\s*ê´€ë¦¬ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
            r'ê´€ë¦¬\s*ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
            r'â—‹\s*ì „ë‹´ê¸°ê´€\s*[:ï¼š]\s*([^\nâ—‹]+)',
        ]
        for pattern in mng_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                mng_organ_text = match.group(1).strip()
                if len(mng_organ_text) > 2:
                    break

        # âœ¨ ì‹ ê·œ: ëŒ€í‘œë¶„ì•¼ ë° ë¹„ì¤‘ í…ìŠ¤íŠ¸ íŒŒì‹± (ì˜ˆ: "ëŒ€í‘œë¶„ì•¼ ìƒëª…ê³¼í•™ ë¹„ì¤‘ ìƒëª…ê³¼í•™(100), Red(10), Green(10), White(10)")
        rep_fld_text = None
        biology_wei = None
        red_wei = None
        green_wei = None
        white_wei = None

        # ëŒ€í‘œë¶„ì•¼ íŒ¨í„´
        rep_fld_patterns = [
            r'ëŒ€í‘œë¶„ì•¼\s*[:ï¼š]?\s*([ê°€-í£]+)',
            r'ëŒ€í‘œ\s*ë¶„ì•¼\s*[:ï¼š]?\s*([ê°€-í£]+)',
        ]
        for pattern in rep_fld_patterns:
            match = re.search(pattern, full_text, re.IGNORECASE)
            if match:
                rep_fld_text = match.group(1).strip()
                break

        # ë¹„ì¤‘ íŒ¨í„´ (ì˜ˆ: "ìƒëª…ê³¼í•™(100), Red(10), Green(10), White(10)")
        weight_pattern = r'ë¹„ì¤‘\s*[:ï¼š]?\s*([^\nâ—‹]+)'
        weight_match = re.search(weight_pattern, full_text, re.IGNORECASE)
        if weight_match:
            weight_text = weight_match.group(1).strip()

            # ê°œë³„ ê°€ì¤‘ì¹˜ ì¶”ì¶œ (ìƒëª…ê³¼í•™(100), Red(10) í˜•ì‹)
            biology_match = re.search(r'ìƒëª…ê³¼í•™\s*\((\d+)\)', weight_text)
            if biology_match:
                biology_wei = int(biology_match.group(1))

            red_match = re.search(r'Red\s*\((\d+)\)', weight_text, re.IGNORECASE)
            if red_match:
                red_wei = int(red_match.group(1))

            green_match = re.search(r'Green\s*\((\d+)\)', weight_text, re.IGNORECASE)
            if green_match:
                green_wei = int(green_match.group(1))

            white_match = re.search(r'White\s*\((\d+)\)', weight_text, re.IGNORECASE)
            if white_match:
                white_wei = int(white_match.group(1))

        # TB_PLAN_DATA ë ˆì½”ë“œ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
        for plan_data in self.data['plan_data']:
            if plan_data['PLAN_ID'] == plan_id:
                # âœ… ë¶€ì²˜ëª… (NATION_ORGAN_NM) - í•„ìˆ˜ í•„ë“œ!
                nation_organ = get_value_with_alternatives(
                    overview_data,
                    'ë¶€ì²˜ëª…', 'ì†Œê´€ë¶€ì²˜', 'ì†Œê´€', 'ë¶€ì²˜',
                    'ì£¼ë¬´ë¶€ì²˜', 'ë‹´ë‹¹ë¶€ì²˜'
                )
                if not nation_organ:
                    # ë³¸ë¬¸ì—ì„œ ã€ë¶€ì²˜ëª…ã€ íŒ¨í„´ ì¶”ì¶œ
                    bracket_match = re.search(r'ã€\s*([^ã€]+)\s*ã€', full_text)
                    if bracket_match:
                        nation_organ = bracket_match.group(1).strip()

                if not nation_organ and lead_organ_text:
                    # ì£¼ê´€ê¸°ê´€ì—ì„œ "~ë¶€" í˜•íƒœ ì¶”ì¶œ
                    lead_organ_str = str(lead_organ_text) if lead_organ_text else ""
                    ministry_match = re.search(r'([ê°€-í£]+ë¶€)(?:ê´€ë¦¬ê¸°ê´€|ì „ë‹´ê¸°ê´€|ì£¼ê´€|[\s:]|$)', lead_organ_str)
                    if ministry_match:
                        nation_organ = ministry_match.group(1).strip()

                # í•„ìˆ˜ í•„ë“œ - NULL ë°©ì§€
                if nation_organ:
                    plan_data['NATION_ORGAN_NM'] = self._clean_text(nation_organ, 768)
                else:
                    logger.warning(f"âš ï¸ ë¶€ì²˜ëª… ë¯¸ì¶”ì¶œ: {plan_data.get('BIZ_NM', 'unknown')}")
                    plan_data['NATION_ORGAN_NM'] = "ë¯¸ë¶„ë¥˜"

                # âœ… DETAIL_BIZ_NM: ì„¸ë¶€ì‚¬ì—…ëª… (overview í…Œì´ë¸”ì˜ "ì„¸ë¶€ì‚¬ì—…ëª…")
                detail_biz_nm = get_value_with_alternatives(overview_data, 'ì„¸ë¶€ì‚¬ì—…ëª…', 'ì‚¬ì—…ëª…', 'ì‚¬ì—…ì´ë¦„')
                if detail_biz_nm:
                    plan_data['DETAIL_BIZ_NM'] = self._clean_text(detail_biz_nm, 768)

                # âœ… BIZ_NM: ë‚´ì—­ì‚¬ì—…ëª… (overview í…Œì´ë¸”ì˜ "ë‚´ì—­ì‚¬ì—…ëª…")
                biz_nm = get_value_with_alternatives(overview_data, 'ë‚´ì—­ì‚¬ì—…ëª…')
                if biz_nm:
                    plan_data['BIZ_NM'] = self._clean_text(biz_nm, 768)

                biz_type = get_value_with_alternatives(overview_data, 'ì‚¬ì—…ì„±ê²©', 'ì‚¬ì—…ìœ í˜•', 'ìœ í˜•')
                plan_data['BIZ_TYPE'] = self._clean_text(biz_type, 768) if biz_type else None

                rep_fld = rep_fld_text if rep_fld_text else get_value_with_alternatives(overview_data, 'ëŒ€í‘œë¶„ì•¼', 'ë¶„ì•¼', 'ëŒ€í‘œ ë¶„ì•¼')
                plan_data['REP_FLD'] = self._clean_text(rep_fld, 768) if rep_fld else None

                # ê°€ì¤‘ì¹˜ (í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•œ ê°’ ì €ì¥)
                if biology_wei is not None:
                    plan_data['BIOLOGY_WEI'] = biology_wei
                if red_wei is not None:
                    plan_data['RED_WEI'] = red_wei
                if green_wei is not None:
                    plan_data['GREEN_WEI'] = green_wei
                if white_wei is not None:
                    plan_data['WHITE_WEI'] = white_wei

                # 3ëŒ€ ì˜ì—­
                area = get_value_with_alternatives(overview_data, '3ëŒ€ì˜ì—­', '3ëŒ€ ì˜ì—­', 'ì˜ì—­')
                plan_data['AREA'] = area[:768] if area else None

                # ì£¼ê´€ê¸°ê´€ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ìš°ì„ , ì—†ìœ¼ë©´ í…Œì´ë¸”ì—ì„œ)
                lead_organ = lead_organ_text if lead_organ_text else get_value_with_alternatives(
                    overview_data,
                    'ì£¼ê´€ê¸°ê´€', 'ì£¼ê´€ ê¸°ê´€', 'ì£¼ê´€ê¸°ê´€ëª…',
                    'ì£¼ê´€', 'ì£¼ê´€ë¶€ì²˜', 'ì „ë‹´ê¸°ê´€'
                )
                plan_data['LEAD_ORGAN_NM'] = self._clean_text(lead_organ, 768) if lead_organ else None

                # ê´€ë¦¬ê¸°ê´€ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ìš°ì„ , ì—†ìœ¼ë©´ í…Œì´ë¸”ì—ì„œ)
                mng_organ = mng_organ_text if mng_organ_text else get_value_with_alternatives(
                    overview_data,
                    'ê´€ë¦¬ê¸°ê´€', 'ê´€ë¦¬ ê¸°ê´€', 'ê´€ë¦¬ê¸°ê´€ëª…',
                    'ì´ê´„ê¸°ê´€', 'ì „ë¬¸ê¸°ê´€'
                )
                plan_data['MNG_ORGAN_NM'] = self._clean_text(mng_organ, 768) if mng_organ else None

                # ìµœì¢…ëª©í‘œ
                plan_data['LAST_GOAL'] = self._clean_text(objective, 4000) if objective else None

                # ì‚¬ì—…ë‚´ìš©
                plan_data['BIZ_CONTENTS'] = self._clean_text(content, 4000) if content else None

                # ë””ë²„ê·¸ ë¡œê·¸ (ì²˜ìŒ 3ê°œ ì‚¬ì—…ë§Œ)
                if plan_data['NUM'] <= 3:
                    logger.debug(f"ğŸ“‹ PLAN_ID {plan_id} overview ì—…ë°ì´íŠ¸:")
                    logger.debug(f"  - BIZ_TYPE: {'âœ…' if plan_data['BIZ_TYPE'] else 'âŒ'}")
                    logger.debug(f"  - LEAD_ORGAN_NM: {'âœ…' if plan_data['LEAD_ORGAN_NM'] else 'âŒ'}")
                    logger.debug(f"  - LAST_GOAL: {'âœ…' if plan_data['LAST_GOAL'] else 'âŒ'} ({len(objective) if objective else 0}ì)")
                    logger.debug(f"  - BIZ_CONTENTS: {'âœ…' if plan_data['BIZ_CONTENTS'] else 'âŒ'} ({len(content) if content else 0}ì)")

                break

    def _process_sub_project(self, text: str, tables: List[Dict]) -> bool:
        """ë‚´ì—­ì‚¬ì—… ì²˜ë¦¬ - TB_PLAN_DATA ìƒì„±"""
        biz_name = None         # ë‚´ì—­ì‚¬ì—…ëª… â†’ BIZ_NM
        detail_biz_name = None  # ì„¸ë¶€ì‚¬ì—…ëª… â†’ DETAIL_BIZ_NM

        # í…Œì´ë¸”ì—ì„œ ì°¾ê¸°
        for table in tables:
            rows = table.get('data', [])
            for row in rows:
                if len(row) < 2:
                    continue

                key = str(row[0]).strip()
                value = str(row[1]).strip()

                if 'ë‚´ì—­ì‚¬ì—…ëª…' in key and value:
                    biz_name = value         # ë‚´ì—­ì‚¬ì—…ëª… â†’ BIZ_NM
                elif 'ì„¸ë¶€ì‚¬ì—…ëª…' in key and value:  # âœ… value ì²´í¬ ì¶”ê°€
                    detail_biz_name = value  # ì„¸ë¶€ì‚¬ì—…ëª… â†’ DETAIL_BIZ_NM

        # í…ìŠ¤íŠ¸ì—ì„œ ì°¾ê¸° (í…Œì´ë¸”ì—ì„œ ëª» ì°¾ì•˜ì„ ê²½ìš°)
        if not biz_name:
            match = re.search(r'ë‚´ì—­ì‚¬ì—…ëª…\s+([^\n]+)', text)
            if match:
                biz_name = match.group(1).strip()

        if not detail_biz_name:
            match = re.search(r'ì„¸ë¶€ì‚¬ì—…ëª…\s+([^\n]+)', text)
            if match:
                detail_biz_name = match.group(1).strip()

        if not biz_name:
            return False

        # âœ… DETAIL_BIZ_NMì´ ì—†ìœ¼ë©´ BIZ_NMì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        if not detail_biz_name:
            detail_biz_name = biz_name
            logger.debug(f"  ğŸ“Œ DETAIL_BIZ_NM ì—†ìŒ â†’ BIZ_NM ì‚¬ìš©: {biz_name}")

        # ì´ë¯¸ ë“±ë¡ëœ ë‚´ì—­ì‚¬ì—…ì¸ì§€ ì²´í¬ (DETAIL_BIZ_NM = ë‚´ì—­ì‚¬ì—…ëª…)
        for plan_data in self.data['plan_data']:
            if plan_data['DETAIL_BIZ_NM'] == detail_biz_name:  # âœ… detail_biz_nameì€ ë‚´ì—­ì‚¬ì—…ëª…
                self.current_context['sub_project_id'] = plan_data['_internal_id']
                logger.info(f"ğŸ“Œ ê¸°ì¡´ ë‚´ì—­ì‚¬ì—… ì¬ì‚¬ìš©: {detail_biz_name} (PLAN_ID: {plan_data['PLAN_ID']})")
                return True

        # âœ… ê¸°ì¡´ Oracle DBì—ì„œ PLAN_ID ì¡°íšŒ (ìºì‹œì—ì„œ)
        existing_plan_id = None
        year = self.current_context['document_year']

        # âœ… ë§¤ì¹­ìš© ì •ê·œí™” ì ìš© (ê´„í˜¸, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ëª¨ë‘ ì œê±°)
        biz_nm_normalized = self._normalize_for_matching(biz_name) if biz_name else ""
        detail_biz_nm_normalized = self._normalize_for_matching(detail_biz_name) if detail_biz_name else ""

        # ìºì‹œì—ì„œ ë§¤ì¹­ ì‹œë„ (YEAR, BIZ_NM, DETAIL_BIZ_NM)
        key = (year, biz_nm_normalized, detail_biz_nm_normalized)
        logger.info(f"ğŸ” ë§¤ì¹­ ì‹œë„: YEAR={year}, BIZ_NM='{biz_name}', DETAIL_BIZ_NM='{detail_biz_name}'")
        logger.debug(f"   ì •ê·œí™”ëœ í‚¤: ({year}, '{biz_nm_normalized}', '{detail_biz_nm_normalized}')")
        existing_plan_id = self.existing_plan_data.get(key)

        if existing_plan_id:
            logger.info(f"âœ… ê¸°ì¡´ DBì—ì„œ PLAN_ID ë°œê²¬: {biz_name} -> {existing_plan_id}")
        else:
            logger.warning(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨ - BIZ_NM: '{biz_name}', DETAIL_BIZ_NM: '{detail_biz_name}'")

        # ìƒˆë¡œìš´ ë‚´ì—­ì‚¬ì—… ìƒì„±
        sub_id = self._get_next_id('sub_project')

        # PLAN_ID ê²°ì •
        if existing_plan_id:
            # ê¸°ì¡´ DBì— ìˆìœ¼ë©´ í•´ë‹¹ PLAN_ID ì‚¬ìš©
            plan_id = existing_plan_id
            logger.info(f"ğŸ” ê¸°ì¡´ PLAN_ID ì‚¬ìš©: {plan_id}")
        else:
            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì„ì‹œ PLAN_ID ìƒì„±: TEMP_ë…„ë„_ì¼ë ¨ë²ˆí˜¸
            # ë‚˜ì¤‘ì— load_oracle_directì—ì„œ ì´ë¥¼ ê°ì§€í•˜ê³  ì‹¤ì œ ë§¤ì¹­ ìˆ˜í–‰
            plan_id = f"TEMP_{year}_{str(sub_id).zfill(3)}"
            logger.warning(f"âš ï¸ ì‹ ê·œ ë‚´ì—­ì‚¬ì—… (ì„ì‹œ PLAN_ID ìƒì„±): {plan_id}")

        # TB_PLAN_DATA ë ˆì½”ë“œ ìƒì„± (íšŒì‚¬ ê¸°ì¡´ 43ê°œ ì»¬ëŸ¼)
        # âœ… í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë¶€ì²˜ëª…(NATION_ORGAN_NM) ì¶”ì¶œ
        nation_organ = None
        bracket_match = re.search(r'ã€\s*([^ã€]+)\s*ã€', text)
        if bracket_match:
            nation_organ = bracket_match.group(1).strip()

        # TB_PLAN_DATA ë ˆì½”ë“œ ìƒì„± (íšŒì‚¬ ê¸°ì¡´ 43ê°œ ì»¬ëŸ¼)
        plan_data_record = {
            '_internal_id': sub_id,
            'PLAN_ID': plan_id,
            'YEAR': self.current_context['document_year'],
            'NUM': sub_id,
            'NATION_ORGAN_NM': self._clean_text(nation_organ, 768) if nation_organ else "ë¯¸ë¶„ë¥˜",
            'BIZ_NM': biz_name if biz_name else '',  # ë‚´ì—­ì‚¬ì—…ëª… â†’ BIZ_NM
            'DETAIL_BIZ_NM': detail_biz_name if detail_biz_name else '',  # ì„¸ë¶€ì‚¬ì—…ëª… â†’ DETAIL_BIZ_NM
            'BIZ_TYPE': None,
            'AREA': None,
            'REP_FLD': None,
            'BIOLOGY_WEI': None,  # ê°€ì¤‘ì¹˜ëŠ” NULL (ë‚˜ì¤‘ì— ìˆ˜ë™ ì…ë ¥)
            'RED_WEI': None,
            'GREEN_WEI': None,
            'WHITE_WEI': None,
            'FUSION_WEI': None,
            'LEAD_ORGAN_NM': None,
            'MNG_ORGAN_NM': None,
            'BIZ_SDT': None,
            'BIZ_EDT': None,
            'RESPERIOD': None,
            'CUR_RESPERIOD': None,
            'TOTAL_RESPRC': None,  # ë‚˜ì¤‘ì— ì˜ˆì‚° í…Œì´ë¸”ì—ì„œ ì§‘ê³„
            'TOTAL_RESPRC_GOV': None,
            'TOTAL_RESPRC_CIV': None,
            'CUR_RESPRC': None,
            'CUR_RESPRC_GOV': None,
            'CUR_RESPRC_CIV': None,
            'LAST_GOAL': None,
            'BIZ_CONTENTS': None,
            'BIZ_CONTENTS_KEYWORD': None,
            'REGUL_WEI': None,
            'WEI': None,
            'PERFORM_PRC': None,
            'PLAN_PRC': None
        }

        self.data['plan_data'].append(plan_data_record)
        self.current_context['sub_project_id'] = sub_id
        self.plan_id_mapping[sub_id] = plan_id  # ë§¤í•‘ ì €ì¥

        logger.info(f"âœ… ë‚´ì—­ì‚¬ì—… ë“±ë¡: {detail_biz_name} (ID: {sub_id}, PLAN_ID: {plan_id})")
        return True


    def normalize(self, json_data: Dict) -> bool:
        """JSON ë°ì´í„° ì •ê·œí™” (ì „ì²´ ì²˜ë¦¬)"""
        try:
            logger.info(f"ğŸš€ ì •ë¶€ í‘œì¤€ ì •ê·œí™” ì‹œì‘")

            # âœ… ë©”íƒ€ë°ì´í„°ì—ì„œ ë¬¸ì„œ ì—°ë„ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ 1)
            metadata = json_data.get('metadata', {})
            if metadata and 'document_year' in metadata:
                self.current_context['document_year'] = metadata['document_year']
                logger.info(f"ğŸ“… JSON metadataì—ì„œ ì—°ë„ ì¶”ì¶œ: {metadata['document_year']}ë…„")
            # âœ… JSON íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•œ ì—°ë„ ìœ ì§€ (ìš°ì„ ìˆœìœ„ 2)
            else:
                logger.info(f"ğŸ“… íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì‚¬ìš©: {self.current_context['document_year']}ë…„")

            self.current_context['performance_year'] = self.current_context['document_year'] - 1
            self.current_context['plan_year'] = self.current_context['document_year']

            # í˜ì´ì§€ë³„ ì²˜ë¦¬
            pages_data = json_data.get('pages', [])
            self.validation_stats['total_pages'] = len(pages_data)

            for page in pages_data:
                page_num = page.get('page_number', 1)
                page_category = page.get('category')
                page_sub_project = page.get('sub_project')
                page_full_text = page.get('full_text', '')
                page_tables = page.get('tables', [])

                self.validation_stats['total_tables'] += len(page_tables)

                # sub_projectê°€ í˜ì´ì§€ì— ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ ì„¤ì •/ì „í™˜ (nullì´ ì•„ë‹ ë•Œë§Œ)
                if page_sub_project:
                    # ì´ë¯¸ ë“±ë¡ëœ ë‚´ì—­ì‚¬ì—…ì¸ì§€ ì²´í¬ (BIZ_NM = ë‚´ì—­ì‚¬ì—…ëª…)
                    existing_project = None
                    for plan_data in self.data['plan_data']:
                        # BIZ_NM(ë‚´ì—­ì‚¬ì—…ëª…)ìœ¼ë¡œ ë§¤ì¹­
                        if plan_data['BIZ_NM'] == page_sub_project:
                            existing_project = plan_data
                            break

                    if existing_project:
                        # ê¸°ì¡´ í”„ë¡œì íŠ¸ë¡œ ì „í™˜
                        if self.current_context.get('sub_project_id') != existing_project['_internal_id']:
                            self.current_context['sub_project_id'] = existing_project['_internal_id']
                            logger.info(f"ğŸ“Œ ë‚´ì—­ì‚¬ì—… ì „í™˜: {page_sub_project} (PLAN_ID: {existing_project['PLAN_ID']})")
                    else:
                        # ìƒˆë¡œìš´ ë‚´ì—­ì‚¬ì—… ì²˜ë¦¬
                        self._process_sub_project(page_full_text, page_tables)
                elif 'ë‚´ì—­ì‚¬ì—…ëª…' in page_full_text or 'ì„¸ë¶€ì‚¬ì—…ëª…' in page_full_text:
                    # í˜ì´ì§€ì— sub_project ì •ë³´ê°€ ì—†ì§€ë§Œ í…ìŠ¤íŠ¸ì— ìˆìœ¼ë©´ ì°¾ê¸°
                    self._process_sub_project(page_full_text, page_tables)
                # else: ë‚´ì—­ì‚¬ì—… ì •ë³´ê°€ ì—†ìœ¼ë©´ ì´ì „ í˜ì´ì§€ì˜ sub_project_idë¥¼ ìœ ì§€

                # sub_project_idê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ê²½ê³  í›„ ê±´ë„ˆë›°ê¸°
                if not self.current_context.get('sub_project_id'):
                    logger.debug(f"âš ï¸ í˜ì´ì§€ {page_num}: sub_project_id ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue

                # ì›ë³¸ ë°ì´í„° ì €ì¥
                raw_data_id = self._save_raw_data(
                    page_category or 'unknown',
                    {'full_text': page_full_text, 'tables': page_tables},
                    page_num,
                    0
                )

                # â­ ëŒ€í‘œì„±ê³¼ëŠ” ëª¨ë“  í˜ì´ì§€ì—ì„œ ì¶”ì¶œ (categoryì™€ ë¬´ê´€)
                if self.current_context.get('sub_project_id'):
                    # ëŒ€í‘œì„±ê³¼ ì¶”ì¶œ
                    if 'â‘  ëŒ€í‘œì„±ê³¼' in page_full_text:
                        achievements = self._extract_key_achievements(page_full_text, page_num)
                        self.data['achievements'].extend(achievements)

                # ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬
                if page_category == 'overview':
                    # ì‚¬ì—…ê°œìš” ì²˜ë¦¬
                    self._process_overview(page_full_text, page_tables, page_num, raw_data_id)

                elif page_category == 'performance':

                    # í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ì •ì„±ì  ì„±ê³¼ ì¶”ì¶œ
                    qualitative = self._extract_qualitative_achievements(page_full_text, page_num)
                    if qualitative:
                        self.data['performances'].extend(qualitative)
                        self.validation_stats['normalized_records'] += len(qualitative)

                    # í…Œì´ë¸” ì²˜ë¦¬ (ì„±ê³¼ ë˜ëŠ” ì˜ˆì‚°)
                    for idx, table in enumerate(page_tables):
                        rows = table.get('data', [])
                        if not rows:
                            continue

                        # í…Œì´ë¸” íƒ€ì… ê°ì§€
                        header_text = ' '.join(str(c) for c in rows[0]).lower()

                        # ì˜ˆì‚° í…Œì´ë¸”ì¸ì§€ í™•ì¸ (performance ì¹´í…Œê³ ë¦¬ì— ì˜ˆì‚° í…Œì´ë¸”ì´ ìˆì„ ìˆ˜ ìˆìŒ)
                        if 'ì‚¬ì—…ë¹„' in header_text or ('êµ¬ë¶„' in header_text and 'ì‹¤ì ' in header_text and 'ê³„íš' in header_text):
                            # ì˜ˆì‚° í…Œì´ë¸”
                            table_raw_id = self._save_raw_data('plan', table, page_num, idx)
                            normalized = self._normalize_budget_data(rows, table_raw_id)
                            self.data['budgets'].extend(normalized)
                            self.validation_stats['normalized_records'] += len(normalized)
                        else:
                            # ì„±ê³¼ í…Œì´ë¸”
                            table_raw_id = self._save_raw_data('performance', table, page_num, idx)
                            normalized = self._normalize_performance_table(rows, table_raw_id)
                            self.data['performances'].extend(normalized)
                            self.validation_stats['normalized_records'] += len(normalized)

                        self.validation_stats['processed_tables'] += 1

                elif page_category == 'plan':

                    # í…Œì´ë¸” ì²˜ë¦¬
                    for idx, table in enumerate(page_tables):
                        rows = table.get('data', [])
                        if not rows:
                            continue

                        table_raw_id = self._save_raw_data('plan', table, page_num, idx)

                        # í…Œì´ë¸” íƒ€ì… ê°ì§€
                        header_text = ' '.join(str(c) for c in rows[0]).lower()

                        if 'ì¼ì •' in header_text or 'ë¶„ê¸°' in header_text or 'ì¶”ì§„' in header_text:
                            # ì¼ì • í…Œì´ë¸”
                            for row in rows[1:]:
                                if len(row) >= 2:
                                    period = str(row[0]).strip()
                                    task = str(row[1]).strip() if len(row) > 1 else ""
                                    detail = str(row[2]).strip() if len(row) > 2 else ""

                                    if period and 'êµ¬ë¶„' not in period:
                                        normalized = self._normalize_schedule_data(
                                            period, task, detail, table_raw_id
                                        )
                                        self.data['schedules'].extend(normalized)
                                        self.validation_stats['normalized_records'] += len(normalized)

                        elif 'ì˜ˆì‚°' in header_text or 'ì‚¬ì—…ë¹„' in header_text:
                            # ì˜ˆì‚° í…Œì´ë¸”
                            normalized = self._normalize_budget_data(rows, table_raw_id)
                            self.data['budgets'].extend(normalized)
                            self.validation_stats['normalized_records'] += len(normalized)

                        self.validation_stats['processed_tables'] += 1

            # âœ… ìµœì¢… ë‹¨ê³„: "ë¯¸ë¶„ë¥˜" NATION_ORGAN_NM ì¬ê²€ìƒ‰
            logger.info("ğŸ” ë¯¸ë¶„ë¥˜ ë¶€ì²˜ëª… ì¬ê²€ìƒ‰ ì¤‘...")
            for plan_data in self.data['plan_data']:
                if plan_data['NATION_ORGAN_NM'] == "ë¯¸ë¶„ë¥˜":
                    # í•´ë‹¹ ë‚´ì—­ì‚¬ì—…ì˜ ëª¨ë“  í˜ì´ì§€ì—ì„œ ã€ã€ íŒ¨í„´ ì°¾ê¸°
                    sub_project_name = plan_data['BIZ_NM']  # ë‚´ì—­ì‚¬ì—…ëª…

                    for page in pages_data:
                        page_full_text = page.get('full_text', '')

                        # ì´ í˜ì´ì§€ê°€ í•´ë‹¹ ë‚´ì—­ì‚¬ì—…ê³¼ ê´€ë ¨ìˆëŠ”ì§€ í™•ì¸
                        if sub_project_name in page_full_text:
                            bracket_match = re.search(r'ã€\s*([^ã€]+)\s*ã€', page_full_text)
                            if bracket_match:
                                nation_organ = bracket_match.group(1).strip()
                                plan_data['NATION_ORGAN_NM'] = self._clean_text(nation_organ, 768)
                                logger.info(f"âœ… ë¶€ì²˜ëª… ë°œê²¬: {sub_project_name} -> {nation_organ}")
                                break

            logger.info(f"âœ… ì •ê·œí™” ì™„ë£Œ: {len(self.data['plan_data'])}ê°œ ë‚´ì—­ì‚¬ì—…")
            return True

        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def save_to_csv(self):
        """CSV ì €ì¥ - TB_PLAN_DATA ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ"""

        # âœ… 1ë‹¨ê³„: í•˜ìœ„ í…Œì´ë¸”ì— PLAN_ID ì±„ìš°ê¸° (plan_id_mapping ì‚¬ìš©)
        for budget in self.data['budgets']:
            if not budget.get('PLAN_ID') or budget['PLAN_ID'] == '':
                # _internal_idë¥¼ í†µí•´ PLAN_ID ì°¾ê¸° (ì´ë¯¸ ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì±„ì›Œì§)
                # í•˜ì§€ë§Œ ì •ê·œí™” ì‹œ sub_project_idë¡œ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ, plan_dataì—ì„œ ì°¾ì•„ì•¼ í•¨
                pass  # ì´ë¯¸ ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨

        for schedule in self.data['schedules']:
            if not schedule.get('PLAN_ID') or schedule['PLAN_ID'] == '':
                pass  # ì´ë¯¸ ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨

        for performance in self.data['performances']:
            if not performance.get('PLAN_ID') or performance['PLAN_ID'] == '':
                pass  # ì´ë¯¸ ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨

        for achievement in self.data['achievements']:
            if not achievement.get('PLAN_ID') or achievement['PLAN_ID'] == '':
                pass  # ì´ë¯¸ ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨

        # âœ… 2ë‹¨ê³„: TB_PLAN_DATA ì§‘ê³„ í•„ë“œ ê³„ì‚°
        self._aggregate_plan_data_fields()


        # TB_PLAN_DATA (íšŒì‚¬ ê¸°ì¡´ 43ê°œ ì»¬ëŸ¼, _internal_id ì œì™¸)
        if self.data['plan_data']:
            csv_path = self.output_dir / "TB_PLAN_DATA.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # _internal_id ì œì™¸í•œ ì „ì²´ ì»¬ëŸ¼
                fieldnames = [k for k in self.data['plan_data'][0].keys()
                            if k != '_internal_id']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                for record in self.data['plan_data']:
                    row = {k: v for k, v in record.items()
                          if k != '_internal_id'}
                    writer.writerow(row)
            logger.info(f"âœ… TB_PLAN_DATA.csv ì €ì¥ ({len(self.data['plan_data'])}ê±´)")

        # TB_PLAN_BUDGET
        if self.data['budgets']:
            csv_path = self.output_dir / "TB_PLAN_BUDGET.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # âœ… PLAN_IDë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ
                fieldnames = ['PLAN_ID', 'BUDGET_YEAR', 'CATEGORY', 'TOTAL_AMOUNT',
                             'GOV_AMOUNT', 'PRIVATE_AMOUNT', 'LOCAL_AMOUNT', 'ETC_AMOUNT',
                             'PERFORM_PRC', 'PLAN_PRC']
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                writer.writerows(self.data['budgets'])
            logger.info(f"âœ… TB_PLAN_BUDGET.csv ì €ì¥ ({len(self.data['budgets'])}ê±´)")

        # TB_PLAN_SCHEDULE
        if self.data['schedules']:
            csv_path = self.output_dir / "TB_PLAN_SCHEDULE.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # âœ… PLAN_IDë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ
                fieldnames = ['PLAN_ID', 'SCHEDULE_YEAR', 'QUARTER', 'TASK_NAME',
                             'TASK_CONTENT', 'START_DATE', 'END_DATE']
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                writer.writerows(self.data['schedules'])
            logger.info(f"âœ… TB_PLAN_SCHEDULE.csv ì €ì¥ ({len(self.data['schedules'])}ê±´)")

        # TB_PLAN_PERFORMANCE
        if self.data['performances']:
            csv_path = self.output_dir / "TB_PLAN_PERFORMANCE.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # âœ… PLAN_IDë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ
                fieldnames = ['PLAN_ID', 'PERFORMANCE_YEAR', 'PERFORMANCE_TYPE', 'CATEGORY',
                             'INDICATOR_NAME', 'TARGET_VALUE', 'ACTUAL_VALUE', 'UNIT',
                             'ORIGINAL_TEXT', 'VALUE']
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                writer.writerows(self.data['performances'])
            logger.info(f"âœ… TB_PLAN_PERFORMANCE.csv ì €ì¥ ({len(self.data['performances'])}ê±´)")

        # TB_PLAN_ACHIEVEMENTS
        if self.data['achievements']:
            csv_path = self.output_dir / "TB_PLAN_ACHIEVEMENTS.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                # âœ… PLAN_IDë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ ëª…ì‹œì  ìˆœì„œ ì§€ì •
                fieldnames = ['PLAN_ID', 'ACHIEVEMENT_YEAR', 'ACHIEVEMENT_TYPE',
                             'TITLE', 'DESCRIPTION', 'PAGE_NUMBER']
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                writer.writerows(self.data['achievements'])
            logger.info(f"âœ… TB_PLAN_ACHIEVEMENTS.csv ì €ì¥ ({len(self.data['achievements'])}ê±´)")

        # ì›ë³¸ ë°ì´í„° (ê°ì‚¬ìš©)
        if self.data['raw_data']:
            csv_path = self.output_dir / "raw_data.csv"
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=self.data['raw_data'][0].keys())
                writer.writeheader()
                writer.writerows(self.data['raw_data'])
            logger.info(f"âœ… raw_data.csv ì €ì¥ ({len(self.data['raw_data'])}ê±´)")

    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š ì •ë¶€ í‘œì¤€ ì •ê·œí™” ì™„ë£Œ (TB_PLAN_DATA + í•˜ìœ„ í…Œì´ë¸”)")
        print("="*80)

        print(f"\nğŸ“ ë‚´ì—­ì‚¬ì—… (TB_PLAN_DATA): {len(self.data['plan_data'])}ê°œ")
        for plan_data in self.data['plan_data'][:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            print(f"  - {plan_data['BIZ_NM']} (PLAN_ID: {plan_data['PLAN_ID']})")
        if len(self.data['plan_data']) > 10:
            print(f"  ... ì™¸ {len(self.data['plan_data']) - 10}ê°œ")

        print(f"\nğŸ“‹ Oracle í…Œì´ë¸”ë³„ ë°ì´í„° í†µê³„:")
        print(f"  TB_PLAN_DATA:        {len(self.data['plan_data'])}ê±´")
        print(f"  TB_PLAN_BUDGET:      {len(self.data['budgets'])}ê±´")
        print(f"  TB_PLAN_SCHEDULE:    {len(self.data['schedules'])}ê±´")
        print(f"  TB_PLAN_PERFORMANCE: {len(self.data['performances'])}ê±´")
        print(f"  TB_PLAN_ACHIEVEMENTS: {len(self.data['achievements'])}ê±´")
        print(f"  raw_data (ê°ì‚¬ìš©):    {len(self.data['raw_data'])}ê±´")

        print("="*80 + "\n")


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python normalize_government_standard.py <JSONíŒŒì¼ê²½ë¡œ> [ì¶œë ¥ë””ë ‰í† ë¦¬]")
        print("ì˜ˆì œ: python normalize_government_standard.py output/2024ë…„ë„_ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš.json normalized_output_government")
        sys.exit(1)

    json_file = sys.argv[1]
    output_folder = sys.argv[2] if len(sys.argv) > 2 else "normalized_output_government"

    if not Path(json_file).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        sys.exit(1)

    normalizer = GovernmentStandardNormalizer(json_file, output_folder)

    with open(json_file, 'r', encoding='utf-8') as f:
        json_data = json.load(f)

    success = normalizer.normalize(json_data)

    if success:
        normalizer.save_to_csv()
        normalizer.print_statistics()
        print(f"\nâœ… ì •ê·œí™” ì™„ë£Œ! CSV ì €ì¥ ìœ„ì¹˜: {output_folder}/")
    else:
        print("âŒ ì •ê·œí™” ì‹¤íŒ¨!")
        sys.exit(1)
