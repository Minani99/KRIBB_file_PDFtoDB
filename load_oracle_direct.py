"""
Oracle DB ì ì¬ - TB_PLAN_DATA + í•˜ìœ„ í…Œì´ë¸” 4ê°œ
"""
import pandas as pd
import logging
from pathlib import Path
from typing import Dict, Any

from oracle_db_manager import OracleDBManager
from oracle_table_ddl import (
    TABLE_DEFINITIONS,
    TABLE_CREATE_ORDER
)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OracleDirectLoader:
    """Oracle ì§ì ‘ ì ì¬ í´ë˜ìŠ¤ - TB_PLAN_DATA ê¸°ë°˜"""

    def __init__(self, db_config_read: Dict[str, Any], db_config_write: Dict[str, Any], csv_dir: str):
        """
        Args:
            db_config_read: TB_PLAN_DATA ì½ê¸°ìš© DB ì„¤ì • (BICS)
            db_config_write: í•˜ìœ„ í…Œì´ë¸” ì“°ê¸°ìš© DB ì„¤ì • (BICS_DEV)
            csv_dir: CSV íŒŒì¼ ë””ë ‰í† ë¦¬
        """
        self.db_manager_read = OracleDBManager(db_config_read)   # ì½ê¸°ìš© (BICS)
        self.db_manager_write = OracleDBManager(db_config_write)  # ì“°ê¸°ìš© (BICS_DEV)
        self.csv_dir = Path(csv_dir)

        self.load_stats = {
            'tables_created': 0,
            'total_records': 0,
            'records_by_table': {},
            'errors': [],
            'matched': 0,
            'unmatched': 0,
            'diff_found': 0
        }

        # ê¸°ì¡´ PLAN_DATA ìºì‹œ (YEAR, DETAIL_BIZ_NM) -> PLAN_ID
        self.existing_plan_data = {}
        self.matching_report = []
        self.unmatched_records = []
        self.diff_records = []

    def connect(self):
        """Oracle ì—°ê²° (ì½ê¸°ìš© + ì“°ê¸°ìš©)"""
        self.db_manager_read.connect()
        self.db_manager_write.connect()
        return True
    def connect(self):
        """Oracle ì—°ê²° (ì½ê¸°ìš© + ì“°ê¸°ìš©)"""
        self.db_manager_read.connect()
        self.db_manager_write.connect()
        return True

    def create_tables(self):
        """í…Œì´ë¸” ìƒì„±"""
        logger.info("\nğŸ—ï¸ Oracle í…Œì´ë¸” ìƒì„± ì¤‘...")

        for table_name in TABLE_CREATE_ORDER:
            try:
                table_def = TABLE_DEFINITIONS[table_name]
                # DDL ì‹¤í–‰
                self.db_manager_write.execute_ddl(table_def['ddl'])
                logger.info(f"  âœ… {table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

                # ì»¬ëŸ¼ ì£¼ì„ ì‹¤í–‰
                for comment_sql in table_def['comments']:
                    try:
                        self.db_manager_write.execute_ddl(comment_sql)
                    except Exception as e:
                        logger.debug(f"  ì£¼ì„ ì‹¤í–‰ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

                self.load_stats['tables_created'] += 1
            except Exception as e:
                logger.warning(f"  âš ï¸ {table_name} ìƒì„± ì‹¤íŒ¨ (ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì—ëŸ¬): {e}")

    def truncate_tables(self):
        """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í…Œì´ë¸” êµ¬ì¡°ëŠ” ìœ ì§€)"""
        logger.info("\nğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")

        # ì—­ìˆœìœ¼ë¡œ DELETE (FK ì œì•½ ë•Œë¬¸)
        delete_order = list(reversed(TABLE_CREATE_ORDER))

        deleted_count = 0
        cursor = self.db_manager_write.connection.cursor()

        for table_name in delete_order:
            try:
                # TRUNCATE ëŒ€ì‹  DELETE ì‚¬ìš© (FK ì œì•½ì¡°ê±´ ê³ ë ¤)
                cursor.execute(f"DELETE FROM {table_name}")
                deleted_rows = cursor.rowcount
                self.db_manager_write.connection.commit()
                logger.info(f"  âœ… {table_name} ë°ì´í„° ì‚­ì œ ì™„ë£Œ ({deleted_rows}ê±´)")
                deleted_count += 1
            except Exception as e:
                error_msg = str(e)
                if "ORA-00942" in error_msg:
                    logger.debug(f"  â­ï¸ {table_name} í…Œì´ë¸” ì—†ìŒ (ê±´ë„ˆëœ€)")
                else:
                    logger.error(f"  âŒ {table_name} ì‚­ì œ ì‹¤íŒ¨: {error_msg}")

        cursor.close()
        if deleted_count > 0:
            logger.info(f"âœ… {deleted_count}ê°œ í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        return deleted_count

    def load_existing_plan_data(self):
        """ê¸°ì¡´ TB_PLAN_DATA ì „ì²´ ì¡°íšŒ ë° ìºì‹± (BICS ìŠ¤í‚¤ë§ˆì—ì„œ ì½ê¸°)"""
        logger.info("\nğŸ“‚ ê¸°ì¡´ TB_PLAN_DATA ì¡°íšŒ ì¤‘...")

        cursor = self.db_manager_read.connection.cursor()

        try:
            cursor.execute("""
                SELECT 
                    PLAN_ID, YEAR, NUM, NATION_ORGAN_NM, DETAIL_BIZ_NM, BIZ_NM,
                    BIZ_TYPE, AREA, REP_FLD, LEAD_ORGAN_NM, MNG_ORGAN_NM,
                    RESPERIOD, CUR_RESPERIOD,
                    TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV,
                    CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV,
                    LAST_GOAL, BIZ_CONTENTS
                FROM TB_PLAN_DATA
                WHERE DELETE_YN = 'N'
                ORDER BY YEAR, NUM
            """)

            rows = cursor.fetchall()
            logger.info(f"  âœ… ê¸°ì¡´ ë ˆì½”ë“œ: {len(rows)}ê±´")

            # ìºì‹œ ìƒì„±: (YEAR, BIZ_NM, DETAIL_BIZ_NM) -> ì „ì²´ ë ˆì½”ë“œ
            for row in rows:
                year = row[1]
                detail_biz_nm = row[4] if row[4] else ""  # DETAIL_BIZ_NM (ì„¸ë¶€ì‚¬ì—…ëª…)
                biz_nm = row[5] if row[5] else ""  # BIZ_NM (ë‚´ì—­ì‚¬ì—…ëª…)

                # ì •ê·œí™”: ê³µë°± ì œê±°
                key = (year, biz_nm.strip(), detail_biz_nm.strip())

                self.existing_plan_data[key] = {
                    'PLAN_ID': row[0],
                    'YEAR': row[1],
                    'NUM': row[2],
                    'NATION_ORGAN_NM': row[3],
                    'DETAIL_BIZ_NM': row[4],
                    'BIZ_NM': row[5],
                    'BIZ_TYPE': row[6],
                    'AREA': row[7],
                    'REP_FLD': row[8],
                    'LEAD_ORGAN_NM': row[9],
                    'MNG_ORGAN_NM': row[10],
                    'RESPERIOD': row[11],
                    'CUR_RESPERIOD': row[12],
                    'TOTAL_RESPRC': row[13],
                    'TOTAL_RESPRC_GOV': row[14],
                    'TOTAL_RESPRC_CIV': row[15],
                    'CUR_RESPRC': row[16],
                    'CUR_RESPRC_GOV': row[17],
                    'CUR_RESPRC_CIV': row[18],
                    'LAST_GOAL': row[19],
                    'BIZ_CONTENTS': row[20]
                }

            logger.info(f"  âœ… ìºì‹œ ìƒì„± ì™„ë£Œ: {len(self.existing_plan_data)}ê°œ í‚¤")

        except Exception as e:
            logger.error(f"  âŒ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
        finally:
            cursor.close()

    def copy_plan_data_to_dev(self):
        """BICSì˜ TB_PLAN_DATAë¥¼ BICS_DEVë¡œ ë³µì‚¬ (FK ì œì•½ì¡°ê±´ìš©)"""
        logger.info("\nğŸ“‹ BICS â†’ BICS_DEV TB_PLAN_DATA ë³µì‚¬ ì¤‘...")

        try:
            cursor_write = self.db_manager_write.connection.cursor()

            # 1. BICS_DEVì— TB_PLAN_DATA í…Œì´ë¸”ì´ ìˆëŠ”ì§€ í™•ì¸
            cursor_write.execute("""
                SELECT COUNT(*) FROM user_tables 
                WHERE table_name = 'TB_PLAN_DATA'
            """)
            table_exists = cursor_write.fetchone()[0] > 0

            if not table_exists:
                # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
                logger.info("  ğŸ“ TB_PLAN_DATA í…Œì´ë¸” ìƒì„± ì¤‘...")
                from oracle_table_ddl import TABLE_DEFINITIONS
                table_def = TABLE_DEFINITIONS['TB_PLAN_DATA']
                self.db_manager_write.execute_ddl(table_def['ddl'])
                logger.info("  âœ… TB_PLAN_DATA í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

            # 2. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            cursor_write.execute("DELETE FROM TB_PLAN_DATA WHERE DELETE_YN = 'N'")
            deleted = cursor_write.rowcount
            logger.info(f"  ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {deleted}ê±´")

            # 3. BICSì—ì„œ ë°ì´í„° ì¡°íšŒ
            cursor_read = self.db_manager_read.connection.cursor()
            cursor_read.execute("""
                SELECT PLAN_ID, YEAR, NUM, NATION_ORGAN_NM, BIZ_NM, DETAIL_BIZ_NM,
                       BIZ_TYPE, AREA, REP_FLD, BIOLOGY_WEI, RED_WEI, GREEN_WEI, 
                       WHITE_WEI, FUSION_WEI, LEAD_ORGAN_NM, MNG_ORGAN_NM,
                       BIZ_SDT, BIZ_EDT, RESPERIOD, CUR_RESPERIOD,
                       TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV,
                       CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV,
                       LAST_GOAL, BIZ_CONTENTS, BIZ_CONTENTS_KEYWORD,
                       REGUL_WEI, WEI, PERFORM_PRC, PLAN_PRC
                FROM TB_PLAN_DATA
                WHERE DELETE_YN = 'N'
            """)

            rows = cursor_read.fetchall()
            logger.info(f"  ğŸ“¥ BICSì—ì„œ {len(rows)}ê±´ ì¡°íšŒ")

            # 4. BICS_DEVì— INSERT
            insert_sql = """
                INSERT INTO TB_PLAN_DATA (
                    PLAN_ID, YEAR, NUM, NATION_ORGAN_NM, BIZ_NM, DETAIL_BIZ_NM,
                    BIZ_TYPE, AREA, REP_FLD, BIOLOGY_WEI, RED_WEI, GREEN_WEI,
                    WHITE_WEI, FUSION_WEI, LEAD_ORGAN_NM, MNG_ORGAN_NM,
                    BIZ_SDT, BIZ_EDT, RESPERIOD, CUR_RESPERIOD,
                    TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV,
                    CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV,
                    LAST_GOAL, BIZ_CONTENTS, BIZ_CONTENTS_KEYWORD,
                    REGUL_WEI, WEI, PERFORM_PRC, PLAN_PRC,
                    REGIST_DT, DELETE_YN
                ) VALUES (
                    :1, :2, :3, :4, :5, :6, :7, :8, :9, :10, :11, :12, :13, :14,
                    :15, :16, :17, :18, :19, :20, :21, :22, :23, :24, :25, :26,
                    :27, :28, :29, :30, :31, :32, :33, SYSDATE, 'N'
                )
            """

            cursor_write.executemany(insert_sql, rows)
            self.db_manager_write.connection.commit()

            logger.info(f"  âœ… BICS_DEVì— {len(rows)}ê±´ ë³µì‚¬ ì™„ë£Œ")

            cursor_read.close()
            cursor_write.close()

        except Exception as e:
            logger.error(f"  âŒ TB_PLAN_DATA ë³µì‚¬ ì‹¤íŒ¨: {e}")
            raise


    def match_plan_id(self, csv_row: pd.Series) -> Dict[str, Any]:
        """
        CSV ë ˆì½”ë“œë¥¼ ê¸°ì¡´ TB_PLAN_DATAì™€ ë§¤ì¹­

        âœ… ë§¤ì¹­ ìš°ì„ ìˆœìœ„:
        1ìˆœìœ„: CSVì— ì´ë¯¸ ìœ íš¨í•œ PLAN_IDê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        2ìˆœìœ„: PLAN_IDê°€ ì—†ê±°ë‚˜ TEMP_ë¡œ ì‹œì‘í•˜ë©´ ë§¤ì¹­ ì‹œë„

        ë§¤ì¹­ ê¸°ì¤€: YEAR + BIZ_NM(ë‚´ì—­ì‚¬ì—…ëª…) + DETAIL_BIZ_NM(ì„¸ë¶€ì‚¬ì—…ëª…)

        Returns:
            {
                'matched': bool,
                'plan_id': str or None,
                'has_diff': bool,
                'diff_details': dict
            }
        """
        # âœ… 1ìˆœìœ„: CSVì— ì´ë¯¸ ìœ íš¨í•œ PLAN_IDê°€ ìˆëŠ”ì§€ í™•ì¸
        csv_plan_id = str(csv_row['PLAN_ID']).strip() if pd.notna(csv_row['PLAN_ID']) and csv_row['PLAN_ID'] else None

        if csv_plan_id and not csv_plan_id.startswith('TEMP_') and csv_plan_id != '':
            # ìœ íš¨í•œ PLAN_IDê°€ ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            return {
                'matched': True,
                'plan_id': csv_plan_id,
                'has_diff': False,
                'diff_details': {},
                'reason': 'CSVì— ì´ë¯¸ ë§¤ì¹­ëœ PLAN_ID ì¡´ì¬'
            }

        # 2ìˆœìœ„: ë§¤ì¹­ ì‹œë„ (PLAN_IDê°€ ì—†ê±°ë‚˜ TEMP_ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°)
        year = int(csv_row['YEAR']) if pd.notna(csv_row['YEAR']) else None
        biz_nm = str(csv_row['BIZ_NM']).strip() if pd.notna(csv_row['BIZ_NM']) else ""
        detail_biz_nm = str(csv_row['DETAIL_BIZ_NM']).strip() if pd.notna(csv_row['DETAIL_BIZ_NM']) else ""

        if not year or not biz_nm:
            return {
                'matched': False,
                'plan_id': None,
                'has_diff': False,
                'diff_details': {},
                'reason': 'YEAR ë˜ëŠ” BIZ_NM ëˆ„ë½'
            }

        # ë§¤ì¹­ ì‹œë„: YEAR + BIZ_NM + DETAIL_BIZ_NM
        key = (year, biz_nm, detail_biz_nm)
        existing = self.existing_plan_data.get(key)

        if not existing:
            return {
                'matched': False,
                'plan_id': None,
                'has_diff': False,
                'diff_details': {},
                'reason': f'ê¸°ì¡´ ë°ì´í„°ì— ì—†ìŒ: {year}ë…„ - {biz_nm} - {detail_biz_nm}'
            }

        # ë§¤ì¹­ ì„±ê³µ! ì°¨ì´ì  í™•ì¸
        diff_details = {}

        # ë¹„êµí•  í•„ë“œë“¤
        compare_fields = [
            'NATION_ORGAN_NM', 'BIZ_TYPE', 'AREA', 'REP_FLD',
            'LEAD_ORGAN_NM', 'MNG_ORGAN_NM', 'RESPERIOD',
            'TOTAL_RESPRC_GOV', 'TOTAL_RESPRC_CIV',
            'LAST_GOAL', 'BIZ_CONTENTS'
        ]

        for field in compare_fields:
            csv_val = str(csv_row[field]).strip() if pd.notna(csv_row.get(field)) else ""
            db_val = str(existing.get(field)).strip() if existing.get(field) else ""

            if csv_val and db_val and csv_val != db_val:
                diff_details[field] = {
                    'csv': csv_val[:100],  # ìµœëŒ€ 100ì
                    'db': db_val[:100]
                }

        return {
            'matched': True,
            'plan_id': existing['PLAN_ID'],
            'has_diff': len(diff_details) > 0,
            'diff_details': diff_details,
            'reason': 'SUCCESS'
        }

    def process_matching(self) -> Dict[int, str]:
        """
        CSV ë°ì´í„°ì™€ ê¸°ì¡´ TB_PLAN_DATA ë§¤ì¹­
        Returns: {csv_index(int): plan_id(str)}
        """
        logger.info("\nğŸ” PLAN_ID ë§¤ì¹­ ì‹œì‘...")

        csv_file = self.csv_dir / "TB_PLAN_DATA.csv"
        if not csv_file.exists():
            logger.error(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return {}

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ì²˜ë¦¬í•  ë ˆì½”ë“œ: {len(df)}ê±´")

        plan_id_mapping: Dict[int, str] = {}  # íƒ€ì… ëª…ì‹œ

        for idx, row in df.iterrows():
            result = self.match_plan_id(row)

            match_record = {
                'csv_index': int(idx),  # type: ignore
                'year': row.get('YEAR'),
                'biz_nm': row.get('BIZ_NM'),  # ë‚´ì—­ì‚¬ì—…ëª…
                'detail_biz_nm': row.get('DETAIL_BIZ_NM'),  # ì„¸ë¶€ì‚¬ì—…ëª…
                'matched': result['matched'],
                'plan_id': result['plan_id'],
                'has_diff': result.get('has_diff', False),
                'reason': result.get('reason', '')
            }

            self.matching_report.append(match_record)

            if result['matched']:
                plan_id_mapping[int(idx)] = result['plan_id']  # type: ignore
                self.load_stats['matched'] += 1

                if result['has_diff']:
                    self.load_stats['diff_found'] += 1
                    self.diff_records.append({
                        'csv_index': idx,
                        'plan_id': result['plan_id'],
                        'year': row.get('YEAR'),
                        'detail_biz_nm': row.get('DETAIL_BIZ_NM'),
                        'diffs': result['diff_details']
                    })
            else:
                self.load_stats['unmatched'] += 1
                self.unmatched_records.append(match_record)

        logger.info(f"  âœ… ë§¤ì¹­ ì™„ë£Œ:")
        logger.info(f"     - ì„±ê³µ: {self.load_stats['matched']}ê±´")
        logger.info(f"     - ì‹¤íŒ¨: {self.load_stats['unmatched']}ê±´")
        logger.info(f"     - ì°¨ì´ì  ë°œê²¬: {self.load_stats['diff_found']}ê±´")

        return plan_id_mapping

    def update_csv_with_plan_ids(self, plan_id_mapping: Dict[int, str]):
        """
        ë§¤ì¹­ëœ PLAN_IDë¥¼ ëª¨ë“  CSVì— ì—…ë°ì´íŠ¸

        Args:
            plan_id_mapping: {csv_index: plan_id}
        """
        logger.info("\nğŸ“ ë§¤ì¹­ëœ PLAN_IDë¥¼ CSVì— ì—…ë°ì´íŠ¸ ì¤‘...")

        # 1. TB_PLAN_DATA ì—…ë°ì´íŠ¸
        plan_data_file = self.csv_dir / "TB_PLAN_DATA.csv"
        if plan_data_file.exists():
            df = pd.read_csv(plan_data_file, encoding='utf-8-sig')

            for idx, plan_id in plan_id_mapping.items():
                if idx < len(df):
                    df.at[idx, 'PLAN_ID'] = plan_id

            df.to_csv(plan_data_file, index=False, encoding='utf-8-sig')
            logger.info(f"  âœ… TB_PLAN_DATA.csv ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(plan_id_mapping)}ê±´)")

        # 2. í•˜ìœ„ í…Œì´ë¸” ì—…ë°ì´íŠ¸ (TB_PLAN_BUDGET, SCHEDULE, PERFORMANCE, ACHIEVEMENTS)
        # CSVì˜ _internal_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ PLAN_ID ë§¤í•‘ (ì •ê·œí™” ë‹¨ê³„ì—ì„œ sub_project_idë¡œ ì—°ê²°)
        # ì‹¤ì œë¡œëŠ” TB_PLAN_DATAì˜ indexì™€ í•˜ìœ„ í…Œì´ë¸”ì´ ì§ì ‘ ì—°ê²°ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ,
        # í•˜ìœ„ í…Œì´ë¸”ì˜ ë¹ˆ PLAN_IDë¥¼ ì±„ìš°ëŠ” ë°©ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.

        # ì „ëµ: TB_PLAN_DATAì˜ (YEAR, BIZ_NM, DETAIL_BIZ_NM)ìœ¼ë¡œ ì—­ë§¤í•‘
        year_biz_to_plan_id = {}
        plan_data_df = pd.read_csv(plan_data_file, encoding='utf-8-sig')

        for _, row in plan_data_df.iterrows():
            if pd.notna(row['PLAN_ID']) and row['PLAN_ID']:
                year = row['YEAR']
                biz_nm = str(row['BIZ_NM']).strip() if pd.notna(row['BIZ_NM']) else ""
                detail_biz_nm = str(row['DETAIL_BIZ_NM']).strip() if pd.notna(row['DETAIL_BIZ_NM']) else ""

                if year and biz_nm:
                    key = (int(year), biz_nm, detail_biz_nm)
                    year_biz_to_plan_id[key] = row['PLAN_ID']

        logger.info(f"  ğŸ“‹ PLAN_ID ë§¤í•‘ í…Œì´ë¸” ìƒì„±: {len(year_biz_to_plan_id)}ê°œ")

        # í•˜ìœ„ í…Œì´ë¸” íŒŒì¼ë“¤
        sub_tables = [
            'TB_PLAN_BUDGET',
            'TB_PLAN_SCHEDULE',
            'TB_PLAN_PERFORMANCE',
            'TB_PLAN_ACHIEVEMENTS'
        ]

        updated_counts = {}

        for table_name in sub_tables:
            csv_file = self.csv_dir / f"{table_name}.csv"
            if not csv_file.exists():
                continue

            df = pd.read_csv(csv_file, encoding='utf-8-sig')

            # PLAN_IDê°€ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš°ë§Œ ì—…ë°ì´íŠ¸ í•„ìš”
            # í•˜ì§€ë§Œ í•˜ìœ„ í…Œì´ë¸”ì—ëŠ” YEAR, BIZ_NM, DETAIL_BIZ_NMì´ ì—†ìœ¼ë¯€ë¡œ
            # ì •ê·œí™” ë‹¨ê³„ì—ì„œ ì´ë¯¸ ì—°ê²°ë˜ì–´ ìˆì–´ì•¼ í•¨

            # âš ï¸ í˜„ì¬ í•˜ìœ„ í…Œì´ë¸”ì—ëŠ” PLAN_IDë§Œ ìˆê³  ë§¤ì¹­ í‚¤ê°€ ì—†ìŒ!
            # í•´ê²°ì±…: ì •ê·œí™” ë‹¨ê³„ì—ì„œ _internal_idë¥¼ ë³´ì¡´í•˜ê±°ë‚˜,
            # CSVì— ì„ì‹œë¡œ ë§¤ì¹­ í‚¤ë¥¼ ì¶”ê°€í•´ì•¼ í•¨

            # ì„ì‹œ í•´ê²°: í•˜ìœ„ í…Œì´ë¸”ë„ YEAR ì •ë³´ê°€ ìˆë‹¤ë©´ í™œìš©
            if 'BUDGET_YEAR' in df.columns:  # TB_PLAN_BUDGET
                # ì˜ˆì‚° í…Œì´ë¸”ì€ BUDGET_YEARê°€ ìˆìŒ
                # í•˜ì§€ë§Œ BIZ_NMì´ ì—†ì–´ì„œ ë§¤ì¹­ ë¶ˆê°€...
                pass
            elif 'SCHEDULE_YEAR' in df.columns:  # TB_PLAN_SCHEDULE
                pass
            elif 'PERFORMANCE_YEAR' in df.columns:  # TB_PLAN_PERFORMANCE
                pass

            # âš ï¸ ê·¼ë³¸ì  ë¬¸ì œ: í•˜ìœ„ í…Œì´ë¸”ì— ë§¤ì¹­ í‚¤ê°€ ì—†ìŒ!
            logger.warning(f"  âš ï¸ {table_name}: ë§¤ì¹­ í‚¤ ì—†ìŒ (PLAN_ID ì—…ë°ì´íŠ¸ ë¶ˆê°€)")
            updated_counts[table_name] = 0

        logger.info(f"  âš ï¸ í•˜ìœ„ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: ë§¤ì¹­ í‚¤ ë¶€ì¡±")
        logger.info(f"     â†’ í•´ê²° ë°©ë²•: ì •ê·œí™” ë‹¨ê³„ì—ì„œ sub_project_id ë³´ì¡´ í•„ìš”")

    def save_reports(self):
        """ë§¤ì¹­ ë¦¬í¬íŠ¸ ì €ì¥"""
        logger.info("\nğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        report_dir = self.csv_dir / "matching_reports"
        report_dir.mkdir(exist_ok=True)

        # 1. ì „ì²´ ë§¤ì¹­ ë¦¬í¬íŠ¸
        if self.matching_report:
            df_report = pd.DataFrame(self.matching_report)
            report_file = report_dir / "matching_report.csv"
            df_report.to_csv(report_file, index=False, encoding='utf-8-sig')
            logger.info(f"  âœ… ë§¤ì¹­ ë¦¬í¬íŠ¸: {report_file}")

        # 2. ë§¤ì¹­ ì‹¤íŒ¨ ëª©ë¡
        if self.unmatched_records:
            df_unmatched = pd.DataFrame(self.unmatched_records)
            unmatched_file = report_dir / "unmatched_records.csv"
            df_unmatched.to_csv(unmatched_file, index=False, encoding='utf-8-sig')
            logger.info(f"  âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: {unmatched_file} ({len(self.unmatched_records)}ê±´)")

        # 3. ì°¨ì´ì  ë°œê²¬ ëª©ë¡
        if self.diff_records:
            diff_data = []
            for record in self.diff_records:
                base = {
                    'csv_index': record['csv_index'],
                    'plan_id': record['plan_id'],
                    'year': record['year'],
                    'detail_biz_nm': record['detail_biz_nm']
                }
                for field, diff in record['diffs'].items():
                    diff_data.append({
                        **base,
                        'field': field,
                        'csv_value': diff['csv'],
                        'db_value': diff['db']
                    })

            df_diff = pd.DataFrame(diff_data)
            diff_file = report_dir / "diff_report.csv"
            df_diff.to_csv(diff_file, index=False, encoding='utf-8-sig')
            logger.info(f"  ğŸ” ì°¨ì´ì  ë°œê²¬: {diff_file} ({len(self.diff_records)}ê±´)")

    def load_tb_plan_data(self) -> int:
        """TB_PLAN_DATA ì ì¬"""
        logger.info("\n1ï¸âƒ£ TB_PLAN_DATA ì ì¬ ì¤‘...")

        csv_file = self.csv_dir / "TB_PLAN_DATA.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return 0

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ë¡œë“œëœ ë ˆì½”ë“œ: {len(df)}ê±´")

        inserted = 0
        cursor = self.db_manager_write.connection.cursor()

        for idx, row in df.iterrows():
            try:
                # ë°ì´í„° ì¤€ë¹„
                plan_id = str(row['PLAN_ID']) if pd.notna(row['PLAN_ID']) else None
                year = int(row['YEAR']) if pd.notna(row['YEAR']) else None
                num = int(row['NUM']) if pd.notna(row['NUM']) else None

                # MERGE: ì¤‘ë³µ ì‹œ UPDATE, ì—†ìœ¼ë©´ INSERT
                cursor.execute("""
                    MERGE INTO TB_PLAN_DATA tgt
                    USING (
                        SELECT
                            :1 AS PLAN_ID, :2 AS YEAR, :3 AS NUM, :4 AS NATION_ORGAN_NM,
                            :5 AS DETAIL_BIZ_NM, :6 AS BIZ_NM, :7 AS BIZ_TYPE, :8 AS AREA,
                            :9 AS REP_FLD, :10 AS BIOLOGY_WEI, :11 AS RED_WEI, :12 AS GREEN_WEI,
                            :13 AS WHITE_WEI, :14 AS FUSION_WEI, :15 AS LEAD_ORGAN_NM, :16 AS MNG_ORGAN_NM,
                            :17 AS BIZ_SDT, :18 AS BIZ_EDT, :19 AS RESPERIOD, :20 AS CUR_RESPERIOD,
                            :21 AS TOTAL_RESPRC, :22 AS TOTAL_RESPRC_GOV, :23 AS TOTAL_RESPRC_CIV,
                            :24 AS CUR_RESPRC, :25 AS CUR_RESPRC_GOV, :26 AS CUR_RESPRC_CIV,
                            :27 AS LAST_GOAL, :28 AS BIZ_CONTENTS, :29 AS BIZ_CONTENTS_KEYWORD,
                            :30 AS REGUL_WEI, :31 AS WEI, :32 AS PERFORM_PRC, :33 AS PLAN_PRC
                        FROM dual
                    ) src
                    ON (tgt.PLAN_ID = src.PLAN_ID)
                    WHEN MATCHED THEN
                        UPDATE SET
                            tgt.YEAR = src.YEAR,
                            tgt.NUM = src.NUM,
                            tgt.NATION_ORGAN_NM = src.NATION_ORGAN_NM,
                            tgt.DETAIL_BIZ_NM = src.DETAIL_BIZ_NM,
                            tgt.BIZ_NM = src.BIZ_NM,
                            tgt.BIZ_TYPE = src.BIZ_TYPE,
                            tgt.AREA = src.AREA,
                            tgt.REP_FLD = src.REP_FLD,
                            tgt.BIOLOGY_WEI = src.BIOLOGY_WEI,
                            tgt.RED_WEI = src.RED_WEI,
                            tgt.GREEN_WEI = src.GREEN_WEI,
                            tgt.WHITE_WEI = src.WHITE_WEI,
                            tgt.FUSION_WEI = src.FUSION_WEI,
                            tgt.LEAD_ORGAN_NM = src.LEAD_ORGAN_NM,
                            tgt.MNG_ORGAN_NM = src.MNG_ORGAN_NM,
                            tgt.BIZ_SDT = src.BIZ_SDT,
                            tgt.BIZ_EDT = src.BIZ_EDT,
                            tgt.RESPERIOD = src.RESPERIOD,
                            tgt.CUR_RESPERIOD = src.CUR_RESPERIOD,
                            tgt.TOTAL_RESPRC = src.TOTAL_RESPRC,
                            tgt.TOTAL_RESPRC_GOV = src.TOTAL_RESPRC_GOV,
                            tgt.TOTAL_RESPRC_CIV = src.TOTAL_RESPRC_CIV,
                            tgt.CUR_RESPRC = src.CUR_RESPRC,
                            tgt.CUR_RESPRC_GOV = src.CUR_RESPRC_GOV,
                            tgt.CUR_RESPRC_CIV = src.CUR_RESPRC_CIV,
                            tgt.LAST_GOAL = src.LAST_GOAL,
                            tgt.BIZ_CONTENTS = src.BIZ_CONTENTS,
                            tgt.BIZ_CONTENTS_KEYWORD = src.BIZ_CONTENTS_KEYWORD,
                            tgt.REGUL_WEI = src.REGUL_WEI,
                            tgt.WEI = src.WEI,
                            tgt.PERFORM_PRC = src.PERFORM_PRC,
                            tgt.PLAN_PRC = src.PLAN_PRC,
                            tgt.MODIFY_DT = SYSDATE,
                            tgt.MODIFY_ID = 'SYSTEM'
                    WHEN NOT MATCHED THEN
                        INSERT (
                            PLAN_ID, YEAR, NUM, NATION_ORGAN_NM, DETAIL_BIZ_NM, BIZ_NM,
                            BIZ_TYPE, AREA, REP_FLD,
                            BIOLOGY_WEI, RED_WEI, GREEN_WEI, WHITE_WEI, FUSION_WEI,
                            LEAD_ORGAN_NM, MNG_ORGAN_NM, BIZ_SDT, BIZ_EDT,
                            RESPERIOD, CUR_RESPERIOD,
                            TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV,
                            CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV,
                            LAST_GOAL, BIZ_CONTENTS, BIZ_CONTENTS_KEYWORD,
                            REGIST_DT, DELETE_YN, REGIST_ID,
                            REGUL_WEI, WEI, PERFORM_PRC, PLAN_PRC
                        ) VALUES (
                            src.PLAN_ID, src.YEAR, src.NUM, src.NATION_ORGAN_NM, src.DETAIL_BIZ_NM, src.BIZ_NM,
                            src.BIZ_TYPE, src.AREA, src.REP_FLD,
                            src.BIOLOGY_WEI, src.RED_WEI, src.GREEN_WEI, src.WHITE_WEI, src.FUSION_WEI,
                            src.LEAD_ORGAN_NM, src.MNG_ORGAN_NM, src.BIZ_SDT, src.BIZ_EDT,
                            src.RESPERIOD, src.CUR_RESPERIOD,
                            src.TOTAL_RESPRC, src.TOTAL_RESPRC_GOV, src.TOTAL_RESPRC_CIV,
                            src.CUR_RESPRC, src.CUR_RESPRC_GOV, src.CUR_RESPRC_CIV,
                            src.LAST_GOAL, src.BIZ_CONTENTS, src.BIZ_CONTENTS_KEYWORD,
                            SYSDATE, 'N', 'SYSTEM',
                            src.REGUL_WEI, src.WEI, src.PERFORM_PRC, src.PLAN_PRC
                        )
                """, (
                    plan_id,
                    year,
                    num,
                    str(row['NATION_ORGAN_NM'])[:768] if pd.notna(row['NATION_ORGAN_NM']) else None,
                    str(row['DETAIL_BIZ_NM'])[:768] if pd.notna(row['DETAIL_BIZ_NM']) else None,
                    str(row['BIZ_NM'])[:768] if pd.notna(row['BIZ_NM']) else None,
                    str(row['BIZ_TYPE'])[:768] if pd.notna(row['BIZ_TYPE']) else None,
                    str(row['AREA'])[:768] if pd.notna(row['AREA']) else None,
                    str(row['REP_FLD'])[:768] if pd.notna(row['REP_FLD']) else None,
                    float(row['BIOLOGY_WEI']) if pd.notna(row['BIOLOGY_WEI']) else None,
                    float(row['RED_WEI']) if pd.notna(row['RED_WEI']) else None,
                    float(row['GREEN_WEI']) if pd.notna(row['GREEN_WEI']) else None,
                    float(row['WHITE_WEI']) if pd.notna(row['WHITE_WEI']) else None,
                    float(row['FUSION_WEI']) if pd.notna(row['FUSION_WEI']) else None,
                    str(row['LEAD_ORGAN_NM'])[:768] if pd.notna(row['LEAD_ORGAN_NM']) else None,
                    str(row['MNG_ORGAN_NM'])[:768] if pd.notna(row['MNG_ORGAN_NM']) else None,
                    None,  # BIZ_SDT
                    None,  # BIZ_EDT
                    str(row['RESPERIOD'])[:768] if pd.notna(row['RESPERIOD']) else None,
                    str(row['CUR_RESPERIOD'])[:768] if pd.notna(row['CUR_RESPERIOD']) else None,
                    str(row['TOTAL_RESPRC'])[:768] if pd.notna(row['TOTAL_RESPRC']) else None,
                    float(row['TOTAL_RESPRC_GOV']) if pd.notna(row['TOTAL_RESPRC_GOV']) else None,
                    float(row['TOTAL_RESPRC_CIV']) if pd.notna(row['TOTAL_RESPRC_CIV']) else None,
                    str(row['CUR_RESPRC'])[:768] if pd.notna(row['CUR_RESPRC']) else None,
                    float(row['CUR_RESPRC_GOV']) if pd.notna (row['CUR_RESPRC_GOV']) else None,
                    float(row['CUR_RESPRC_CIV']) if pd.notna(row['CUR_RESPRC_CIV']) else None,
                    str(row['LAST_GOAL'])[:4000] if pd.notna(row['LAST_GOAL']) else None,
                    str(row['BIZ_CONTENTS'])[:4000] if pd.notna(row['BIZ_CONTENTS']) else None,
                    str(row['BIZ_CONTENTS_KEYWORD'])[:4000] if pd.notna(row['BIZ_CONTENTS_KEYWORD']) else None,
                    float(row['REGUL_WEI']) if pd.notna(row['REGUL_WEI']) else None,
                    str(row['WEI'])[:768] if pd.notna(row['WEI']) else None,
                    float(row['PERFORM_PRC']) if pd.notna(row['PERFORM_PRC']) else None,
                    float(row['PLAN_PRC']) if pd.notna(row['PLAN_PRC']) else None,
                ))
                inserted += 1
            except Exception as e:
                logger.error(f"âŒ í–‰ {idx} ì‚½ì… ì‹¤íŒ¨: {e}")

        self.db_manager_write.connection.commit()
        logger.info(f"  âœ… TB_PLAN_DATA ì ì¬ ì™„ë£Œ: {inserted}ê±´")
        self.load_stats['records_by_table']['TB_PLAN_DATA'] = inserted
        return inserted

    def load_child_tables_with_mapping(self, plan_id_mapping: Dict[int, str]):
        """
        ë§¤ì¹­ëœ PLAN_IDë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ìœ„ í…Œì´ë¸” ì ì¬

        Args:
            plan_id_mapping: {csv_index: plan_id}
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ í•˜ìœ„ í…Œì´ë¸” ì ì¬ ì‹œì‘ (ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©)")
        logger.info("="*80)

        # ê° í•˜ìœ„ í…Œì´ë¸” ì ì¬
        self.load_tb_plan_budget_with_mapping(plan_id_mapping)
        self.load_tb_plan_schedule_with_mapping(plan_id_mapping)
        self.load_tb_plan_performance_with_mapping(plan_id_mapping)
        self.load_tb_plan_achievements_with_mapping(plan_id_mapping)

        total = sum(self.load_stats['records_by_table'].values())
        self.load_stats['total_records'] = total

        logger.info("\n" + "="*80)
        logger.info("âœ… í•˜ìœ„ í…Œì´ë¸” ì ì¬ ì™„ë£Œ")
        logger.info("="*80)
        logger.info(f"ì´ ë ˆì½”ë“œ: {total}ê±´")
        logger.info(f"í…Œì´ë¸”ë³„ ë ˆì½”ë“œ:")
        for table, count in self.load_stats['records_by_table'].items():
            logger.info(f"  â€¢ {table}: {count}ê±´")

    def load_tb_plan_budget_with_mapping(self, plan_id_mapping: Dict[int, str]) -> int:
        """TB_PLAN_BUDGET ì ì¬ (ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©)"""
        logger.info("\n2ï¸âƒ£ TB_PLAN_BUDGET ì ì¬ ì¤‘...")

        csv_file = self.csv_dir / "TB_PLAN_BUDGET.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return 0

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ë¡œë“œëœ ë ˆì½”ë“œ: {len(df)}ê±´")

        inserted = 0
        skipped = 0
        cursor = self.db_manager_write.connection.cursor()

        # ë§¤ì¹­ í‚¤ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        has_matching_keys = 'BIZ_NM' in df.columns and 'DETAIL_BIZ_NM' in df.columns and 'DOC_YEAR' in df.columns

        for idx, row in df.iterrows():
            try:
                # âœ… 1ìˆœìœ„: CSVì— ìˆëŠ” PLAN_ID ì‚¬ìš© (ì •ê·œí™” ë‹¨ê³„ì—ì„œ ë§¤ì¹­ëœ ê²½ìš°)
                plan_id = str(row['PLAN_ID']).strip() if pd.notna(row['PLAN_ID']) and row['PLAN_ID'] else None

                # PLAN_IDê°€ ì—†ê±°ë‚˜ "TEMP_"ë¡œ ì‹œì‘í•˜ë©´ ë§¤ì¹­ ì‹œë„
                if not plan_id or plan_id.startswith('TEMP_'):
                    if has_matching_keys:
                        biz_nm = str(row['BIZ_NM']).strip() if pd.notna(row['BIZ_NM']) else ""
                        detail_biz_nm = str(row['DETAIL_BIZ_NM']).strip() if pd.notna(row['DETAIL_BIZ_NM']) else ""
                        doc_year = int(row['DOC_YEAR']) if pd.notna(row['DOC_YEAR']) else None

                        if biz_nm and doc_year:
                            # ê¸°ì¡´ PLAN_DATAì—ì„œ ë§¤ì¹­
                            key = (doc_year, biz_nm, detail_biz_nm)
                            existing = self.existing_plan_data.get(key)

                            if existing:
                                plan_id = existing['PLAN_ID']
                                logger.debug(f"  ğŸ” ë§¤ì¹­ ì„±ê³µ: {biz_nm} -> {plan_id}")
                            else:
                                logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: ë§¤ì¹­ ì‹¤íŒ¨ ({doc_year}ë…„ - {biz_nm})")
                                skipped += 1
                                continue
                        else:
                            logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: BIZ_NM ë˜ëŠ” DOC_YEAR ëˆ„ë½")
                            skipped += 1
                            continue
                    else:
                        logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: ë§¤ì¹­ í‚¤ ì—†ìŒ")
                        skipped += 1
                        continue

                # PLAN_ID ê²€ì¦ (ìµœì¢… í™•ì¸)
                if not plan_id or plan_id.startswith('TEMP_'):
                    logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: ìœ íš¨í•œ PLAN_ID ì—†ìŒ")
                    skipped += 1
                    continue

                budget_id = f"{plan_id}B{str(inserted+1).zfill(3)}"

                # INSERT (ì¤‘ë³µ ì‹œ ë¬´ì‹œ)
                cursor.execute("""
                    INSERT INTO TB_PLAN_BUDGET (
                        BUDGET_ID, PLAN_ID, BUDGET_YEAR, CATEGORY,
                        TOTAL_AMOUNT, GOV_AMOUNT, PRIVATE_AMOUNT,
                        LOCAL_AMOUNT, ETC_AMOUNT, PERFORM_PRC, PLAN_PRC,
                        REGIST_DT
                    ) VALUES (
                        :1, :2, :3, :4, :5, :6, :7, :8, :9, :10, :11, SYSDATE
                    )
                """, (
                    budget_id,                                                                         # :1
                    plan_id,                                                                          # :2
                    int(row['BUDGET_YEAR']) if pd.notna(row['BUDGET_YEAR']) else None,              # :3
                    str(row['CATEGORY'])[:50] if pd.notna(row['CATEGORY']) else None,               # :4
                    float(row['TOTAL_AMOUNT']) if pd.notna(row['TOTAL_AMOUNT']) else None,          # :5
                    float(row['GOV_AMOUNT']) if pd.notna(row['GOV_AMOUNT']) else None,              # :6
                    float(row['PRIVATE_AMOUNT']) if pd.notna(row['PRIVATE_AMOUNT']) else None,      # :7
                    float(row['LOCAL_AMOUNT']) if pd.notna(row['LOCAL_AMOUNT']) else None,          # :8
                    float(row['ETC_AMOUNT']) if pd.notna(row['ETC_AMOUNT']) else None,              # :9
                    float(row['PERFORM_PRC']) if pd.notna(row['PERFORM_PRC']) else None,            # :10
                    float(row['PLAN_PRC']) if pd.notna(row['PLAN_PRC']) else None                   # :11
                ))
                inserted += 1
            except Exception as e:
                logger.error(f"âŒ í–‰ {idx} ì‚½ì… ì‹¤íŒ¨: {e}")

        self.db_manager_write.connection.commit()
        cursor.close()
        logger.info(f"  âœ… TB_PLAN_BUDGET ì ì¬ ì™„ë£Œ: {inserted}ê±´ (ê±´ë„ˆëœ€: {skipped}ê±´)")
        self.load_stats['records_by_table']['TB_PLAN_BUDGET'] = inserted
        return inserted

    def load_tb_plan_schedule_with_mapping(self, plan_id_mapping: Dict[int, str]) -> int:
        """TB_PLAN_SCHEDULE ì ì¬ (ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©)"""
        logger.info("\n3ï¸âƒ£ TB_PLAN_SCHEDULE ì ì¬ ì¤‘...")

        csv_file = self.csv_dir / "TB_PLAN_SCHEDULE.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return 0

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ë¡œë“œëœ ë ˆì½”ë“œ: {len(df)}ê±´")

        inserted = 0
        skipped = 0
        cursor = self.db_manager_write.connection.cursor()

        for idx, row in df.iterrows():
            try:
                # âœ… CSVì— ìˆëŠ” PLAN_ID ì§ì ‘ ì‚¬ìš©
                plan_id = str(row['PLAN_ID']).strip() if pd.notna(row['PLAN_ID']) and row['PLAN_ID'] else None

                if not plan_id or plan_id.startswith('TEMP_'):
                    logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: ìœ íš¨í•œ PLAN_ID ì—†ìŒ")
                    skipped += 1
                    continue

                schedule_id = f"{plan_id}S{str(inserted+1).zfill(3)}"

                # INSERT
                cursor.execute("""
                    INSERT INTO TB_PLAN_SCHEDULE (
                        SCHEDULE_ID, PLAN_ID, SCHEDULE_YEAR, QUARTER,
                        TASK_NAME, TASK_CONTENT, START_DATE, END_DATE,
                        REGIST_DT
                    ) VALUES (
                        :1, :2, :3, :4, :5, :6,
                        TO_DATE(:7, 'YYYY-MM-DD'),
                        TO_DATE(:8, 'YYYY-MM-DD'),
                        SYSDATE
                    )
                """, (
                    schedule_id,                                                                      # :1
                    plan_id,                                                                          # :2
                    int(row['SCHEDULE_YEAR']) if pd.notna(row['SCHEDULE_YEAR']) else None,          # :3
                    str(row['QUARTER'])[:50] if pd.notna(row['QUARTER']) else None,                 # :4
                    str(row['TASK_NAME'])[:768] if pd.notna(row['TASK_NAME']) else None,            # :5
                    str(row['TASK_CONTENT'])[:4000] if pd.notna(row['TASK_CONTENT']) else None,     # :6
                    str(row['START_DATE']) if pd.notna(row['START_DATE']) else None,                # :7
                    str(row['END_DATE']) if pd.notna(row['END_DATE']) else None                     # :8
                ))
                inserted += 1
            except Exception as e:
                logger.error(f"âŒ í–‰ {idx} ì‚½ì… ì‹¤íŒ¨: {e}")

        self.db_manager_write.connection.commit()
        logger.info(f"  âœ… TB_PLAN_SCHEDULE ì ì¬ ì™„ë£Œ: {inserted}ê±´ (ê±´ë„ˆëœ€: {skipped}ê±´)")
        self.load_stats['records_by_table']['TB_PLAN_SCHEDULE'] = inserted
        return inserted

    def load_tb_plan_performance_with_mapping(self, plan_id_mapping: Dict[int, str]) -> int:
        """TB_PLAN_PERFORMANCE ì ì¬ (ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©)"""
        logger.info("\n4ï¸âƒ£ TB_PLAN_PERFORMANCE ì ì¬ ì¤‘...")

        csv_file = self.csv_dir / "TB_PLAN_PERFORMANCE.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return 0

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ë¡œë“œëœ ë ˆì½”ë“œ: {len(df)}ê±´")

        inserted = 0
        skipped = 0
        cursor = self.db_manager_write.connection.cursor()

        for idx, row in df.iterrows():
            try:
                # âœ… CSVì— ìˆëŠ” PLAN_ID ì§ì ‘ ì‚¬ìš©
                plan_id = str(row['PLAN_ID']).strip() if pd.notna(row['PLAN_ID']) and row['PLAN_ID'] else None

                if not plan_id or plan_id.startswith('TEMP_'):
                    logger.warning(f"  âš ï¸ í–‰ {idx} ê±´ë„ˆëœ€: ìœ íš¨í•œ PLAN_ID ì—†ìŒ")
                    skipped += 1
                    continue

                performance_id = f"{plan_id}P{str(inserted+1).zfill(3)}"

                # INSERT
                cursor.execute("""
                    INSERT INTO TB_PLAN_PERFORMANCE (
                        PERFORMANCE_ID, PLAN_ID, PERFORMANCE_YEAR,
                        PERFORMANCE_TYPE, CATEGORY, VALUE, UNIT,
                        ORIGINAL_TEXT, REGIST_DT
                    ) VALUES (
                        :1, :2, :3, :4, :5, :6, :7, :8, SYSDATE
                    )
                """, (
                    performance_id,                                                                          # :1
                    plan_id,                                                                                 # :2
                    int(row['PERFORMANCE_YEAR']) if pd.notna(row['PERFORMANCE_YEAR']) else None,           # :3
                    str(row['PERFORMANCE_TYPE'])[:100] if pd.notna(row['PERFORMANCE_TYPE']) else None,     # :4
                    str(row['CATEGORY'])[:200] if pd.notna(row['CATEGORY']) else None,                     # :5
                    float(row['VALUE']) if pd.notna(row['VALUE']) else None,                               # :6
                    str(row['UNIT'])[:50] if pd.notna(row['UNIT']) else None,                              # :7
                    str(row['ORIGINAL_TEXT'])[:4000] if pd.notna(row['ORIGINAL_TEXT']) else None           # :8
                ))
                inserted += 1
            except Exception as e:
                logger.error(f"âŒ í–‰ {idx} ì‚½ì… ì‹¤íŒ¨: {e}")

        self.db_manager_write.connection.commit()
        logger.info(f"  âœ… TB_PLAN_PERFORMANCE ì ì¬ ì™„ë£Œ: {inserted}ê±´ (ê±´ë„ˆëœ€: {skipped}ê±´)")
        self.load_stats['records_by_table']['TB_PLAN_PERFORMANCE'] = inserted
        return inserted

    def load_tb_plan_achievements_with_mapping(self, plan_id_mapping: Dict[int, str]) -> int:
        """TB_PLAN_ACHIEVEMENTS ì ì¬ (ë§¤ì¹­ëœ PLAN_ID ì‚¬ìš©)"""
        logger.info("\n5ï¸âƒ£ TB_PLAN_ACHIEVEMENTS ì ì¬ ì¤‘...")

        csv_file = self.csv_dir / "TB_PLAN_ACHIEVEMENTS.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_file}")
            return 0

        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        logger.info(f"  ğŸ“„ ë¡œë“œëœ ë ˆì½”ë“œ: {len(df)}ê±´")

        inserted = 0
        skipped = 0
        cursor = self.db_manager_write.connection.cursor()

        for idx, row in df.iterrows():
            try:
                # âœ… CSVì— ìˆëŠ” PLAN_ID ì§ì ‘ ì‚¬ìš©
                plan_id = str(row['PLAN_ID']).strip() if pd.notna(row['PLAN_ID']) and row['PLAN_ID'] else None

                if not plan_id or plan_id.startswith('TEMP_'):
                    skipped += 1
                    continue

                achievement_id = f"{plan_id}A{str(inserted+1).zfill(3)}"

                # INSERT
                cursor.execute("""
                    INSERT INTO TB_PLAN_ACHIEVEMENTS (
                        ACHIEVEMENT_ID, PLAN_ID, ACHIEVEMENT_YEAR,
                        ACHIEVEMENT_ORDER, DESCRIPTION, REGIST_DT
                    ) VALUES (
                        :1, :2, :3, :4, :5, SYSDATE
                    )
                """, (
                    achievement_id,                                                                      # :1
                    plan_id,                                                                             # :2
                    int(row['ACHIEVEMENT_YEAR']) if pd.notna(row['ACHIEVEMENT_YEAR']) else None,       # :3
                    idx + 1,                                                                             # :4 (ìˆœì„œëŠ” idx ì‚¬ìš©)
                    str(row['DESCRIPTION'])[:4000] if pd.notna(row['DESCRIPTION']) else None           # :5
                ))
                inserted += 1
            except Exception as e:
                logger.error(f"âŒ í–‰ {idx} ì‚½ì… ì‹¤íŒ¨: {e}")

        self.db_manager_write.connection.commit()
        logger.info(f"  âœ… TB_PLAN_ACHIEVEMENTS ì ì¬ ì™„ë£Œ: {inserted}ê±´ (ê±´ë„ˆëœ€: {skipped}ê±´)")
        self.load_stats['records_by_table']['TB_PLAN_ACHIEVEMENTS'] = inserted
        return inserted

    def load_all_tables(self):
        """ëª¨ë“  í…Œì´ë¸” ì ì¬ (ë ˆê±°ì‹œ - ì‚¬ìš© ì¤‘ë‹¨ ì˜ˆì •)"""
        logger.warning("âš ï¸ load_all_tables()ëŠ” deprecatedì…ë‹ˆë‹¤. load_with_matching()ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ Oracle DB ì ì¬ ì‹œì‘")
        logger.info("="*80)

        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì¤‘ë³µ ë°©ì§€)
        self.truncate_tables()

        # ìˆœì„œ ë³´ì¥: ë¶€ëª¨ í…Œì´ë¸” ë¨¼ì € ì ì¬
        logger.info("\nğŸ“Œ ë¶€ëª¨ í…Œì´ë¸”(TB_PLAN_DATA) ì ì¬...")
        self.load_tb_plan_data()

        logger.info("\nğŸ“Œ í•˜ìœ„ í…Œì´ë¸” ì ì¬...")
        # ì£¼ì˜: ì´ ë©”ì„œë“œë“¤ì€ ì´ì œ _with_mappingìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤
        # ì—¬ê¸°ì„œëŠ” ë¹ˆ ë§¤í•‘ìœ¼ë¡œ í˜¸ì¶œ
        empty_mapping = {}
        self.load_tb_plan_budget_with_mapping(empty_mapping)
        self.load_tb_plan_schedule_with_mapping(empty_mapping)
        self.load_tb_plan_performance_with_mapping(empty_mapping)
        self.load_tb_plan_achievements_with_mapping(empty_mapping)

        total = sum(self.load_stats['records_by_table'].values())
        self.load_stats['total_records'] = total

        logger.info("\n" + "="*80)
        logger.info("âœ… ë°ì´í„° ì ì¬ ì™„ë£Œ")
        logger.info("="*80)
        logger.info(f"ì´ ë ˆì½”ë“œ: {total}ê±´")
        logger.info(f"í…Œì´ë¸”ë³„ ë ˆì½”ë“œ:")
        for table, count in self.load_stats['records_by_table'].items():
            logger.info(f"  â€¢ {table}: {count}ê±´")

        return self.load_stats

    def load_with_matching(self):
        """
        ê¸°ì¡´ TB_PLAN_DATAì™€ ë§¤ì¹­í•˜ì—¬ í•˜ìœ„ í…Œì´ë¸”ë§Œ ì ì¬
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ ë§¤ì¹­ ê¸°ë°˜ DB ì ì¬ ì‹œì‘")
        logger.info("="*80)

        # 0ë‹¨ê³„: BICSì˜ TB_PLAN_DATAë¥¼ BICS_DEVë¡œ ë³µì‚¬ (FK ì œì•½ì¡°ê±´ìš©)
        self.copy_plan_data_to_dev()

        # 1ë‹¨ê³„: ê¸°ì¡´ TB_PLAN_DATA ì¡°íšŒ
        self.load_existing_plan_data()

        # 2ë‹¨ê³„: CSVì™€ ë§¤ì¹­
        plan_id_mapping = self.process_matching()

        # 3ë‹¨ê³„: ë¦¬í¬íŠ¸ ì €ì¥
        self.save_reports()

        # 4ë‹¨ê³„: í•˜ìœ„ í…Œì´ë¸”ë§Œ ì ì¬ (ê¸°ì¡´ PLAN_ID ì‚¬ìš©)
        if plan_id_mapping:
            # ê¸°ì¡´ í•˜ìœ„ í…Œì´ë¸” ë°ì´í„° ì‚­ì œ
            logger.info("\nğŸ—‘ï¸ ê¸°ì¡´ í•˜ìœ„ í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì¤‘...")
            cursor = self.db_manager_write.connection.cursor()
            for table in ['TB_PLAN_ACHIEVEMENTS', 'TB_PLAN_PERFORMANCE', 'TB_PLAN_SCHEDULE', 'TB_PLAN_BUDGET']:
                try:
                    cursor.execute(f"DELETE FROM {table}")
                    deleted = cursor.rowcount
                    self.db_manager_write.connection.commit()
                    logger.info(f"  âœ… {table} ì‚­ì œ: {deleted}ê±´")
                except Exception as e:
                    logger.error(f"  âŒ {table} ì‚­ì œ ì‹¤íŒ¨: {e}")
            cursor.close()

            # í•˜ìœ„ í…Œì´ë¸” ì ì¬
            self.load_child_tables_with_mapping(plan_id_mapping)
        else:
            logger.warning("âš ï¸ ë§¤ì¹­ëœ ë ˆì½”ë“œê°€ ì—†ì–´ í•˜ìœ„ í…Œì´ë¸” ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        # ìµœì¢… í†µê³„
        logger.info("\n" + "="*80)
        logger.info("âœ… ë§¤ì¹­ ê¸°ë°˜ ì ì¬ ì™„ë£Œ")
        logger.info("="*80)
        logger.info(f"ğŸ“Š ë§¤ì¹­ í†µê³„:")
        logger.info(f"  â€¢ ë§¤ì¹­ ì„±ê³µ: {self.load_stats['matched']}ê±´")
        logger.info(f"  â€¢ ë§¤ì¹­ ì‹¤íŒ¨: {self.load_stats['unmatched']}ê±´")
        logger.info(f"  â€¢ ì°¨ì´ì  ë°œê²¬: {self.load_stats['diff_found']}ê±´")
        logger.info(f"\nğŸ“Š ì ì¬ í†µê³„:")
        logger.info(f"  â€¢ ì´ ë ˆì½”ë“œ: {self.load_stats['total_records']}ê±´")
        for table, count in self.load_stats['records_by_table'].items():
            logger.info(f"  â€¢ {table}: {count}ê±´")

        return self.load_stats

    def close(self):
        """DB ì—°ê²° ì¢…ë£Œ"""
        if hasattr(self, 'db_manager_read'):
            self.db_manager_read.close()
        if hasattr(self, 'db_manager_write'):
            self.db_manager_write.close()
