"""
Oracle ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ ëª¨ë“ˆ - ê°œì„  ë²„ì „
MySQL/CSV â†’ Oracle TB_PLAN_DATA ë° í•˜ìœ„ í…Œì´ë¸”
ì£¼ìš” ê°œì„ ì‚¬í•­:
1. plan_id_mapping ë¬¸ì œ í•´ê²°
2. ê¸ˆì•¡ í¬ë§·íŒ… ì œê±° (NUMBER íƒ€ì… ì§ì ‘ ì‚¬ìš©)
3. ê¸°ì¡´ í…Œì´ë¸” ë³´ì¡´ ì˜µì…˜ ì¶”ê°€
4. í•„ìˆ˜ ì»¬ëŸ¼ ë°ì´í„° ì±„ìš°ê¸°
5. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
6. ìƒì„¸ ë¡œê¹… ê°œì„ 
"""
import pandas as pd
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import re
import json

from oracle_db_manager_improved import OracleDBManager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class OracleDBLoader:
    """Oracle ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ í´ë˜ìŠ¤ - ê°œì„  ë²„ì „"""

    def __init__(self, db_config: Dict[str, Any], data_dir: str, 
                 use_existing_tables: bool = True):
        """
        Args:
            db_config: Oracle ì—°ê²° ì„¤ì •
            data_dir: ë°ì´í„° íŒŒì¼ ë””ë ‰í† ë¦¬
            use_existing_tables: ê¸°ì¡´ í…Œì´ë¸” ì‚¬ìš© ì—¬ë¶€ (Trueë©´ TRUNCATE, Falseë©´ ì¬ìƒì„±)
        """
        self.db_manager = OracleDBManager(db_config)
        self.data_dir = Path(data_dir)
        self.use_existing_tables = use_existing_tables
        self.plan_id_mapping = {}  # sub_project_id â†’ PLAN_ID ë§¤í•‘ (ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜)
        
        # JSON íŒŒì¼ì—ì„œ ì¶”ê°€ ë°ì´í„° ë¡œë“œìš©
        self.json_data_cache = {}
        
        # ì ì¬ í†µê³„
        self.load_stats = {
            'tables_created': 0,
            'tables_truncated': 0,
            'total_records': 0,
            'records_by_table': {},
            'skipped_records': {},
            'errors': []
        }

    def connect(self):
        """Oracle ì—°ê²°"""
        return self.db_manager.connect()

    def prepare_tables(self):
        """í…Œì´ë¸” ì¤€ë¹„ (ê¸°ì¡´ í…Œì´ë¸” ì‚¬ìš© ë˜ëŠ” ì¬ìƒì„±)"""
        if self.use_existing_tables:
            self._truncate_tables()
        else:
            self._recreate_tables()

    def _truncate_tables(self):
        """ê¸°ì¡´ í…Œì´ë¸” TRUNCATE (ë°ì´í„°ë§Œ ì‚­ì œ)"""
        logger.info("ğŸ—‘ï¸ ê¸°ì¡´ í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì¤‘ (TRUNCATE)...")
        
        # ì—­ìˆœìœ¼ë¡œ TRUNCATE (ì™¸ë˜í‚¤ ì œì•½ ë•Œë¬¸)
        tables_to_truncate = [
            'TB_PLAN_DETAILS',
            'TB_PLAN_ACHIEVEMENTS', 
            'TB_PLAN_BUDGETS',
            'TB_PLAN_PERFORMANCES',
            'TB_PLAN_SCHEDULES',
            'TB_PLAN_DATA'
        ]
        
        for table_name in tables_to_truncate:
            try:
                if self.db_manager.table_exists(table_name):
                    self.db_manager.truncate_table(table_name)
                    self.load_stats['tables_truncated'] += 1
                    logger.info(f"  âœ… {table_name} ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
                else:
                    logger.warning(f"  âš ï¸ {table_name} í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
            except Exception as e:
                logger.error(f"  âŒ {table_name} TRUNCATE ì‹¤íŒ¨: {e}")
                self.load_stats['errors'].append(f"{table_name} TRUNCATE: {str(e)}")
                
        logger.info("âœ… í…Œì´ë¸” ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

    def _recreate_tables(self):
        """í…Œì´ë¸” ì¬ìƒì„± (DROP & CREATE)"""
        logger.warning("âš ï¸ í…Œì´ë¸” ì¬ìƒì„±ì€ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. íšŒì‚¬ ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        # ê¸°ì¡´ drop_existing_tables() + create_tables() ë¡œì§
        pass

    def load_json_data(self, json_file: str) -> Dict:
        """JSON íŒŒì¼ ë¡œë“œ ë° ìºì‹±"""
        if json_file not in self.json_data_cache:
            json_path = self.data_dir / json_file
            if json_path.exists():
                with open(json_path, 'r', encoding='utf-8') as f:
                    self.json_data_cache[json_file] = json.load(f)
            else:
                self.json_data_cache[json_file] = {}
        return self.json_data_cache[json_file]

    def get_additional_project_data(self, sub_project_id: int) -> Dict:
        """
        JSON íŒŒì¼ì—ì„œ ì¶”ê°€ í”„ë¡œì íŠ¸ ë°ì´í„° ì¶”ì¶œ
        AREA, REGUL_WEI, WEI, BIZ_CONTENTS_KEYWORD ë“±
        """
        additional_data = {
            'area': None,           # 3ëŒ€ì˜ì—­
            'regul_wei': None,      # ê·œì œ ë¹„ì¤‘
            'wei': None,            # ë¹„ì¤‘
            'biology_wei': None,    # ìƒëª…ê³¼í•™ ë¹„ì¤‘
            'red_wei': None,        # ë ˆë“œ ë¹„ì¤‘
            'green_wei': None,      # ê·¸ë¦° ë¹„ì¤‘  
            'white_wei': None,      # í™”ì´íŠ¸ ë¹„ì¤‘
            'fusion_wei': None,     # ìœµí•© ë¹„ì¤‘
            'biz_contents_keyword': None,  # ì‚¬ì—… ë‚´ìš© í‚¤ì›Œë“œ
            'resperiod': None,      # ì—°êµ¬ê¸°ê°„
            'cur_resperiod': None   # í˜„ ì—°êµ¬ê¸°ê°„
        }
        
        # í”„ë¡œì íŠ¸ ì„¸ë¶€ ì •ë³´ JSON íŒŒì¼ì´ ìˆë‹¤ë©´ ë¡œë“œ
        project_details = self.load_json_data('project_details.json')
        if str(sub_project_id) in project_details:
            details = project_details[str(sub_project_id)]
            
            # 3ëŒ€ì˜ì—­ ì¶”ì¶œ
            if 'area' in details:
                additional_data['area'] = str(details['area'])[:768]
            
            # ê°€ì¤‘ì¹˜ ì •ë³´ ì¶”ì¶œ
            if 'weights' in details:
                weights = details['weights']
                additional_data['biology_wei'] = self._safe_float(weights.get('biology'))
                additional_data['red_wei'] = self._safe_float(weights.get('red'))
                additional_data['green_wei'] = self._safe_float(weights.get('green'))
                additional_data['white_wei'] = self._safe_float(weights.get('white'))
                additional_data['fusion_wei'] = self._safe_float(weights.get('fusion'))
                additional_data['regul_wei'] = self._safe_float(weights.get('regulation'))
                
                # ì „ì²´ ê°€ì¤‘ì¹˜ ë¬¸ìì—´
                if 'total' in weights:
                    additional_data['wei'] = str(weights['total'])[:768]
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            if 'keywords' in details:
                keywords = details['keywords']
                if isinstance(keywords, list):
                    additional_data['biz_contents_keyword'] = ', '.join(keywords)[:4000]
                else:
                    additional_data['biz_contents_keyword'] = str(keywords)[:4000]
            
            # ì—°êµ¬ê¸°ê°„ ì¶”ì¶œ
            if 'research_period' in details:
                additional_data['resperiod'] = str(details['research_period'])[:768]
            if 'current_research_period' in details:
                additional_data['cur_resperiod'] = str(details['current_research_period'])[:768]
        
        return additional_data

    def _safe_float(self, value) -> Optional[float]:
        """ì•ˆì „í•œ float ë³€í™˜"""
        if value is None or pd.isna(value):
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None

    def _safe_int(self, value) -> Optional[int]:
        """ì•ˆì „í•œ int ë³€í™˜"""
        if value is None or pd.isna(value):
            return None
        try:
            return int(value)
        except (ValueError, TypeError):
            return None

    def load_tb_plan_data(self) -> Dict[int, str]:
        """
        TB_PLAN_DATA ì ì¬ (ê°œì„  ë²„ì „)
        Returns: sub_project_id â†’ PLAN_ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("ğŸ“¥ TB_PLAN_DATA ì ì¬ ì¤‘ (ê°œì„  ë²„ì „)...")
        
        # CSV íŒŒì¼ ë¡œë“œ
        csv_file = self.data_dir / "sub_projects.csv"
        if not csv_file.exists():
            raise FileNotFoundError(f"âŒ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        sub_projects = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        # ì¶”ê°€ CSV íŒŒì¼ ë¡œë“œ
        overviews_file = self.data_dir / "normalized_overviews.csv"
        budgets_file = self.data_dir / "normalized_budgets.csv"
        schedules_file = self.data_dir / "normalized_schedules.csv"
        
        overviews = pd.read_csv(overviews_file, encoding='utf-8-sig') if overviews_file.exists() else None
        budgets = pd.read_csv(budgets_file, encoding='utf-8-sig') if budgets_file.exists() else None
        schedules = pd.read_csv(schedules_file, encoding='utf-8-sig') if schedules_file.exists() else None
        
        insert_query = """
            INSERT INTO TB_PLAN_DATA (
                PLAN_ID, YEAR, NUM, NATION_ORGAN_NM, DETAIL_BIZ_NM, BIZ_NM,
                BIZ_TYPE, AREA, REP_FLD, 
                BIOLOGY_WEI, RED_WEI, GREEN_WEI, WHITE_WEI, FUSION_WEI,
                LEAD_ORGAN_NM, MNG_ORGAN_NM,
                BIZ_SDT, BIZ_EDT, RESPERIOD, CUR_RESPERIOD,
                TOTAL_RESPRC, TOTAL_RESPRC_GOV, TOTAL_RESPRC_CIV,
                CUR_RESPRC, CUR_RESPRC_GOV, CUR_RESPRC_CIV,
                LAST_GOAL, BIZ_CONTENTS, BIZ_CONTENTS_KEYWORD,
                REGIST_DT, DELETE_YN, REGIST_ID,
                REGUL_WEI, WEI, PERFORM_PRC, PLAN_PRC
            ) VALUES (
                :1, :2, :3, :4, :5, :6, :7, :8, :9, :10,
                :11, :12, :13, :14, :15, :16,
                TO_DATE(:17, 'YYYY-MM-DD'), TO_DATE(:18, 'YYYY-MM-DD'), :19, :20,
                :21, :22, :23, :24, :25, :26, :27, :28, :29,
                SYSDATE, 'N', :30, :31, :32, :33, :34
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in sub_projects.iterrows():
            try:
                sub_project_id = row['id']
                year = row['document_year']
                num = idx + 1
                plan_id = f"{year}{num:03d}"
                
                # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ë§¤í•‘ ì €ì¥ (ì¤‘ìš”!)
                self.plan_id_mapping[sub_project_id] = plan_id
                
                # ì¶”ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                additional = self.get_additional_project_data(sub_project_id)
                
                # Overview ë°ì´í„°
                overview_data = self._get_overview_data(overviews, sub_project_id)
                
                # ì˜ˆì‚° ë°ì´í„° (ê¸ˆì•¡ì€ NUMBER íƒ€ì…ìœ¼ë¡œ ì§ì ‘ ì €ì¥)
                budget_data = self._get_budget_data(budgets, sub_project_id, year)
                
                # ì‚¬ì—… ê¸°ê°„
                date_range = self._get_date_range(schedules, sub_project_id)
                
                # ì—°êµ¬ê¸°ê°„ ë¬¸ìì—´ ìƒì„±
                resperiod = additional['resperiod']
                cur_resperiod = additional['cur_resperiod']
                
                # ì—°êµ¬ê¸°ê°„ì´ ì—†ìœ¼ë©´ ë‚ ì§œì—ì„œ ìƒì„±
                if not resperiod and date_range['start_date'] and date_range['end_date']:
                    resperiod = f"{date_range['start_date']} ~ {date_range['end_date']}"
                
                # ë°ì´í„° ì¤€ë¹„
                data = (
                    plan_id,                                           # 1. PLAN_ID
                    self._safe_int(year),                            # 2. YEAR
                    num,                                              # 3. NUM
                    str(row['department_name'])[:768] if pd.notna(row['department_name']) else None,  # 4. NATION_ORGAN_NM
                    str(row['sub_project_name'])[:768] if pd.notna(row['sub_project_name']) else None, # 5. DETAIL_BIZ_NM
                    str(row['main_project_name'])[:768] if pd.notna(row['main_project_name']) else None, # 6. BIZ_NM
                    overview_data['biz_type'],                       # 7. BIZ_TYPE
                    additional['area'],                              # 8. AREA âœ…
                    overview_data['rep_fld'],                        # 9. REP_FLD
                    additional['biology_wei'],                       # 10. BIOLOGY_WEI âœ…
                    additional['red_wei'],                           # 11. RED_WEI âœ…
                    additional['green_wei'],                         # 12. GREEN_WEI âœ…
                    additional['white_wei'],                         # 13. WHITE_WEI âœ…
                    additional['fusion_wei'],                        # 14. FUSION_WEI âœ…
                    overview_data['lead_organ'],                     # 15. LEAD_ORGAN_NM
                    overview_data['mng_organ'],                      # 16. MNG_ORGAN_NM
                    date_range['start_date'],                        # 17. BIZ_SDT
                    date_range['end_date'],                          # 18. BIZ_EDT
                    resperiod,                                        # 19. RESPERIOD âœ…
                    cur_resperiod,                                   # 20. CUR_RESPERIOD âœ…
                    budget_data['total_resprc'],                     # 21. TOTAL_RESPRC (NUMBER) âœ…
                    budget_data['total_resprc_gov'],                 # 22. TOTAL_RESPRC_GOV (NUMBER) âœ…
                    budget_data['total_resprc_civ'],                 # 23. TOTAL_RESPRC_CIV (NUMBER) âœ…
                    budget_data['cur_resprc'],                       # 24. CUR_RESPRC (NUMBER) âœ…
                    budget_data['cur_resprc_gov'],                   # 25. CUR_RESPRC_GOV (NUMBER) âœ…
                    budget_data['cur_resprc_civ'],                   # 26. CUR_RESPRC_CIV (NUMBER) âœ…
                    overview_data['last_goal'],                      # 27. LAST_GOAL
                    overview_data['biz_contents'],                   # 28. BIZ_CONTENTS
                    additional['biz_contents_keyword'],              # 29. BIZ_CONTENTS_KEYWORD âœ…
                    'SYSTEM',                                         # 30. REGIST_ID
                    additional['regul_wei'],                         # 31. REGUL_WEI âœ…
                    additional['wei'],                                # 32. WEI âœ…
                    budget_data['perform_prc'],                      # 33. PERFORM_PRC (NUMBER) âœ…
                    budget_data['plan_prc']                          # 34. PLAN_PRC (NUMBER) âœ…
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 50 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_DATA ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}, sub_project_id={sub_project_id}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_DATA í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_DATA: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_DATA'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_DATA'] = skipped_count
        self.load_stats['total_records'] += inserted_count
        
        # ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì¸ self.plan_id_mappingì„ ë°˜í™˜
        return self.plan_id_mapping

    def _get_overview_data(self, overviews: pd.DataFrame, sub_project_id: int) -> Dict:
        """Overview ë°ì´í„° ì¶”ì¶œ"""
        data = {
            'biz_type': None,
            'rep_fld': None,
            'lead_organ': None,
            'mng_organ': None,
            'last_goal': None,
            'biz_contents': None
        }
        
        if overviews is not None:
            overview_rows = overviews[overviews['sub_project_id'] == sub_project_id]
            if not overview_rows.empty:
                ov = overview_rows.iloc[0]
                data['biz_type'] = str(ov['project_type'])[:768] if pd.notna(ov['project_type']) else None
                data['rep_fld'] = str(ov['field'])[:768] if pd.notna(ov['field']) else None
                data['lead_organ'] = str(ov['managing_dept'])[:768] if pd.notna(ov['managing_dept']) else None
                data['mng_organ'] = str(ov['managing_org'])[:768] if pd.notna(ov['managing_org']) else None
                data['last_goal'] = str(ov['objective'])[:4000] if pd.notna(ov['objective']) else None
                data['biz_contents'] = str(ov['content'])[:4000] if pd.notna(ov['content']) else None
        
        return data

    def _get_budget_data(self, budgets: pd.DataFrame, sub_project_id: int, year: int) -> Dict:
        """
        ì˜ˆì‚° ë°ì´í„° ì¶”ì¶œ (ê°œì„ : ê¸ˆì•¡ì„ NUMBERë¡œ ì§ì ‘ ë°˜í™˜)
        """
        data = {
            'total_resprc': None,
            'total_resprc_gov': None,
            'total_resprc_civ': None,
            'cur_resprc': None,
            'cur_resprc_gov': None,
            'cur_resprc_civ': None,
            'perform_prc': None,
            'plan_prc': None
        }
        
        if budgets is not None:
            project_budgets = budgets[budgets['sub_project_id'] == sub_project_id]
            
            if not project_budgets.empty:
                # ì´ ì—°êµ¬ë¹„ ê³„ì‚°
                gov_total = self._safe_float(
                    project_budgets[project_budgets['budget_type'] == 'ì •ë¶€']['amount'].sum()
                )
                
                # 'ë¯¼ê°„' ì¸ì½”ë”© ë¬¸ì œ ì²˜ë¦¬
                civil_mask = project_budgets['budget_type'].str.contains('ë¯¼ê°„|ë¯¼ê°', na=False, regex=True)
                civil_total = self._safe_float(
                    project_budgets[civil_mask]['amount'].sum()
                )
                
                local_total = self._safe_float(
                    project_budgets[project_budgets['budget_type'] == 'ì§€ë°©ë¹„']['amount'].sum()
                )
                
                other_total = self._safe_float(
                    project_budgets[project_budgets['budget_type'] == 'ê¸°íƒ€']['amount'].sum()
                )
                
                # ì´ ì—°êµ¬ë¹„ (ì •ë¶€ + ë¯¼ê°„ + ì§€ë°©ë¹„ + ê¸°íƒ€)
                total = 0
                if gov_total: total += gov_total
                if civil_total: total += civil_total
                if local_total: total += local_total
                if other_total: total += other_total
                
                data['total_resprc_gov'] = gov_total if gov_total and gov_total > 0 else None
                data['total_resprc_civ'] = civil_total if civil_total and civil_total > 0 else None
                data['total_resprc'] = total if total > 0 else None
                
                # í˜„ì¬ ì—°ë„ ì—°êµ¬ë¹„
                cur_budgets = project_budgets[project_budgets['budget_year'] == year]
                if not cur_budgets.empty:
                    cur_gov = self._safe_float(
                        cur_budgets[cur_budgets['budget_type'] == 'ì •ë¶€']['amount'].sum()
                    )
                    
                    cur_civil_mask = cur_budgets['budget_type'].str.contains('ë¯¼ê°„|ë¯¼ê°', na=False, regex=True)
                    cur_civil = self._safe_float(
                        cur_budgets[cur_civil_mask]['amount'].sum()
                    )
                    
                    cur_local = self._safe_float(
                        cur_budgets[cur_budgets['budget_type'] == 'ì§€ë°©ë¹„']['amount'].sum()
                    )
                    
                    cur_other = self._safe_float(
                        cur_budgets[cur_budgets['budget_type'] == 'ê¸°íƒ€']['amount'].sum()
                    )
                    
                    cur_total = 0
                    if cur_gov: cur_total += cur_gov
                    if cur_civil: cur_total += cur_civil
                    if cur_local: cur_total += cur_local
                    if cur_other: cur_total += cur_other
                    
                    data['cur_resprc_gov'] = cur_gov if cur_gov and cur_gov > 0 else None
                    data['cur_resprc_civ'] = cur_civil if cur_civil and cur_civil > 0 else None
                    data['cur_resprc'] = cur_total if cur_total > 0 else None
                
                # ì‹¤ì /ê³„íš ë¹„ìš© (is_actual ì»¬ëŸ¼ ì‚¬ìš©)
                if 'is_actual' in project_budgets.columns:
                    perform = self._safe_float(
                        project_budgets[project_budgets['is_actual'] == True]['amount'].sum()
                    )
                    plan = self._safe_float(
                        project_budgets[project_budgets['is_actual'] == False]['amount'].sum()
                    )
                else:
                    # is_actual ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ categoryë¡œ íŒë‹¨
                    perform = self._safe_float(
                        project_budgets[
                            project_budgets['budget_category'].str.contains('ì‹¤ì ', na=False)
                        ]['amount'].sum()
                    )
                    plan = self._safe_float(
                        project_budgets[
                            project_budgets['budget_category'].str.contains('ê³„íš', na=False)
                        ]['amount'].sum()
                    )
                
                data['perform_prc'] = perform if perform and perform > 0 else None
                data['plan_prc'] = plan if plan and plan > 0 else None
        
        return data

    def _get_date_range(self, schedules: pd.DataFrame, sub_project_id: int) -> Dict:
        """ì¼ì •ì—ì„œ ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ"""
        data = {
            'start_date': None,
            'end_date': None
        }
        
        if schedules is not None:
            project_schedules = schedules[schedules['sub_project_id'] == sub_project_id]
            if not project_schedules.empty:
                if 'start_date' in project_schedules.columns:
                    dates = project_schedules['start_date'].dropna()
                    if len(dates) > 0:
                        data['start_date'] = str(dates.min())[:10]
                
                if 'end_date' in project_schedules.columns:
                    dates = project_schedules['end_date'].dropna()
                    if len(dates) > 0:
                        data['end_date'] = str(dates.max())[:10]
        
        return data

    def load_tb_plan_schedules(self):
        """TB_PLAN_SCHEDULES ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ TB_PLAN_SCHEDULES ì ì¬ ì¤‘...")
        
        csv_file = self.data_dir / "normalized_schedules.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return
        
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        # plan_id ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'plan_id' in df.columns:
            logger.info("  â„¹ï¸ CSVì— plan_id ì»¬ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤.")
        
        insert_query = """
            INSERT INTO TB_PLAN_SCHEDULES (
                PLAN_ID, YEAR, QUARTER, MONTH_START, MONTH_END,
                START_DATE, END_DATE, TASK_CATEGORY, TASK_DESCRIPTION,
                ORIGINAL_PERIOD
            ) VALUES (
                :1, :2, :3, :4, :5, TO_DATE(:6, 'YYYY-MM-DD'), 
                TO_DATE(:7, 'YYYY-MM-DD'), :8, :9, :10
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                # plan_id ê²°ì • ë¡œì§ ê°œì„ 
                plan_id = self._resolve_plan_id(row)
                
                if not plan_id:
                    logger.debug(f"âš ï¸ PLAN_ID ë§¤í•‘ ì—†ìŒ: í–‰ {idx}")
                    skipped_count += 1
                    continue
                
                data = (
                    plan_id,
                    self._safe_int(row['year']) if pd.notna(row.get('year')) else None,
                    self._safe_int(row['quarter']) if pd.notna(row.get('quarter')) else None,
                    self._safe_int(row['month_start']) if pd.notna(row.get('month_start')) else None,
                    self._safe_int(row['month_end']) if pd.notna(row.get('month_end')) else None,
                    str(row['start_date'])[:10] if pd.notna(row.get('start_date')) else None,
                    str(row['end_date'])[:10] if pd.notna(row.get('end_date')) else None,
                    str(row['task_category'])[:200] if pd.notna(row.get('task_category')) else None,
                    str(row['task_description']) if pd.notna(row.get('task_description')) else None,
                    str(row['original_period'])[:100] if pd.notna(row.get('original_period')) else None
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 100 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_SCHEDULES ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_SCHEDULES í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_SCHEDULES: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_SCHEDULES'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_SCHEDULES'] = skipped_count
        self.load_stats['total_records'] += inserted_count

    def _resolve_plan_id(self, row: pd.Series) -> Optional[str]:
        """
        PLAN_ID ê²°ì • ë¡œì§
        1. CSVì— plan_id ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
        2. ì—†ìœ¼ë©´ sub_project_idë¡œ ë§¤í•‘ ì¡°íšŒ
        3. ë§¤í•‘ë„ ì—†ìœ¼ë©´ DBì—ì„œ ì¡°íšŒ ì‹œë„
        """
        # 1. CSVì— plan_idê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if 'plan_id' in row and pd.notna(row['plan_id']):
            return str(row['plan_id'])
        
        # 2. sub_project_idë¡œ ë§¤í•‘ ì¡°íšŒ
        if 'sub_project_id' in row:
            sub_project_id = row['sub_project_id']
            if sub_project_id in self.plan_id_mapping:
                return self.plan_id_mapping[sub_project_id]
            
            # 3. DBì—ì„œ ì¡°íšŒ ì‹œë„ (fallback)
            if hasattr(self.db_manager, 'lookup_plan_id'):
                plan_id = self.db_manager.lookup_plan_id(sub_project_id)
                if plan_id:
                    # ìºì‹œì— ì €ì¥
                    self.plan_id_mapping[sub_project_id] = plan_id
                    return plan_id
        
        return None

    def load_tb_plan_performances(self):
        """TB_PLAN_PERFORMANCES ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ TB_PLAN_PERFORMANCES ì ì¬ ì¤‘...")
        
        csv_file = self.data_dir / "normalized_performances.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return
        
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        insert_query = """
            INSERT INTO TB_PLAN_PERFORMANCES (
                PLAN_ID, PERFORMANCE_YEAR, INDICATOR_CATEGORY,
                INDICATOR_TYPE, VALUE, UNIT, ORIGINAL_TEXT
            ) VALUES (
                :1, :2, :3, :4, :5, :6, :7
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                plan_id = self._resolve_plan_id(row)
                
                if not plan_id:
                    skipped_count += 1
                    continue
                
                data = (
                    plan_id,
                    self._safe_int(row['performance_year']) if pd.notna(row.get('performance_year')) else None,
                    str(row['indicator_category'])[:100] if pd.notna(row.get('indicator_category')) else None,
                    str(row['indicator_type'])[:200] if pd.notna(row.get('indicator_type')) else None,
                    self._safe_float(row['value']) if pd.notna(row.get('value')) else None,
                    str(row['unit'])[:50] if pd.notna(row.get('unit')) else None,
                    str(row['original_text']) if pd.notna(row.get('original_text')) else None
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 100 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_PERFORMANCES ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_PERFORMANCES í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_PERFORMANCES: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_PERFORMANCES'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_PERFORMANCES'] = skipped_count
        self.load_stats['total_records'] += inserted_count

    def load_tb_plan_budgets(self):
        """TB_PLAN_BUDGETS ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ TB_PLAN_BUDGETS ì ì¬ ì¤‘...")
        
        csv_file = self.data_dir / "normalized_budgets.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return
        
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        insert_query = """
            INSERT INTO TB_PLAN_BUDGETS (
                PLAN_ID, BUDGET_YEAR, BUDGET_CATEGORY, BUDGET_TYPE,
                AMOUNT, CURRENCY, IS_ACTUAL, ORIGINAL_TEXT
            ) VALUES (
                :1, :2, :3, :4, :5, :6, :7, :8
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                plan_id = self._resolve_plan_id(row)
                
                if not plan_id:
                    skipped_count += 1
                    continue
                
                # ì˜ˆì‚° íƒ€ì… ì¸ì½”ë”© ë¬¸ì œ ì²˜ë¦¬
                budget_type = str(row['budget_type']) if pd.notna(row.get('budget_type')) else None
                if budget_type and 'ë¯¼' in budget_type and 'ê°„' in budget_type:
                    budget_type = 'ë¯¼ê°„'  # ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì •
                
                # is_actual íŒë‹¨ ê°œì„ 
                is_actual = 'N'
                if 'is_actual' in row:
                    is_actual = 'Y' if row['is_actual'] else 'N'
                elif 'budget_category' in row and pd.notna(row['budget_category']):
                    if 'ì‹¤ì ' in str(row['budget_category']):
                        is_actual = 'Y'
                
                data = (
                    plan_id,
                    self._safe_int(row['budget_year']) if pd.notna(row.get('budget_year')) else None,
                    str(row['budget_category'])[:100] if pd.notna(row.get('budget_category')) else None,
                    budget_type[:100] if budget_type else None,
                    self._safe_float(row['amount']) if pd.notna(row.get('amount')) else None,
                    str(row['currency'])[:10] if pd.notna(row.get('currency')) else 'KRW',
                    is_actual,
                    str(row['original_text']) if pd.notna(row.get('original_text')) else None
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 100 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_BUDGETS ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_BUDGETS í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_BUDGETS: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_BUDGETS'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_BUDGETS'] = skipped_count
        self.load_stats['total_records'] += inserted_count

    def load_tb_plan_achievements(self):
        """TB_PLAN_ACHIEVEMENTS ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ TB_PLAN_ACHIEVEMENTS ì ì¬ ì¤‘...")
        
        csv_file = self.data_dir / "key_achievements.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return
        
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        insert_query = """
            INSERT INTO TB_PLAN_ACHIEVEMENTS (
                PLAN_ID, ACHIEVEMENT_YEAR, ACHIEVEMENT_ORDER, DESCRIPTION
            ) VALUES (
                :1, :2, :3, :4
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                plan_id = self._resolve_plan_id(row)
                
                if not plan_id:
                    skipped_count += 1
                    continue
                
                data = (
                    plan_id,
                    self._safe_int(row['achievement_year']) if pd.notna(row.get('achievement_year')) else None,
                    self._safe_int(row['achievement_order']) if pd.notna(row.get('achievement_order')) else None,
                    str(row['description']) if pd.notna(row.get('description')) else None
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 100 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_ACHIEVEMENTS ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_ACHIEVEMENTS í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_ACHIEVEMENTS: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_ACHIEVEMENTS'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_ACHIEVEMENTS'] = skipped_count
        self.load_stats['total_records'] += inserted_count

    def load_tb_plan_details(self):
        """TB_PLAN_DETAILS ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ TB_PLAN_DETAILS ì ì¬ ì¤‘...")
        
        csv_file = self.data_dir / "plan_details.csv"
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return
        
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        
        insert_query = """
            INSERT INTO TB_PLAN_DETAILS (
                PLAN_ID, PLAN_YEAR, PLAN_ORDER, DESCRIPTION
            ) VALUES (
                :1, :2, :3, :4
            )
        """
        
        inserted_count = 0
        skipped_count = 0
        
        for idx, row in df.iterrows():
            try:
                plan_id = self._resolve_plan_id(row)
                
                if not plan_id:
                    skipped_count += 1
                    continue
                
                data = (
                    plan_id,
                    self._safe_int(row['plan_year']) if pd.notna(row.get('plan_year')) else None,
                    self._safe_int(row['plan_order']) if pd.notna(row.get('plan_order')) else None,
                    str(row['description']) if pd.notna(row.get('description')) else None
                )
                
                self.db_manager.cursor.execute(insert_query, data)
                inserted_count += 1
                
                if inserted_count % 100 == 0:
                    self.db_manager.commit()
                    logger.info(f"  {inserted_count}ê±´ ì ì¬ ì¤‘...")
                    
            except Exception as e:
                logger.error(f"âŒ TB_PLAN_DETAILS ì‚½ì… ì‹¤íŒ¨ (í–‰ {idx}): {e}")
                self.load_stats['errors'].append(f"TB_PLAN_DETAILS í–‰ {idx}: {str(e)}")
                skipped_count += 1
        
        self.db_manager.commit()
        logger.info(f"âœ… TB_PLAN_DETAILS: {inserted_count}ê±´ ì ì¬ ì™„ë£Œ (ìŠ¤í‚µ: {skipped_count}ê±´)")
        
        self.load_stats['records_by_table']['TB_PLAN_DETAILS'] = inserted_count
        self.load_stats['skipped_records']['TB_PLAN_DETAILS'] = skipped_count
        self.load_stats['total_records'] += inserted_count

    def load_all_tables(self):
        """ëª¨ë“  í…Œì´ë¸” ì ì¬ (ê°œì„ )"""
        logger.info("ğŸ“¥ ë°ì´í„° ì ì¬ ì‹œì‘ (ê°œì„  ë²„ì „)...")
        
        # 1. TB_PLAN_DATA ë¨¼ì € ì ì¬ (ë§ˆìŠ¤í„°)
        # ì¤‘ìš”: ë°˜í™˜ëœ ë§¤í•‘ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ì— ì €ì¥ (ì´ë¯¸ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨)
        plan_id_mapping = self.load_tb_plan_data()
        
        # ë§¤í•‘ ê²€ì¦
        logger.info(f"âœ… PLAN_ID ë§¤í•‘ ìƒì„± ì™„ë£Œ: {len(self.plan_id_mapping)}ê±´")
        
        # 2. í•˜ìœ„ í…Œì´ë¸” ì ì¬
        self.load_tb_plan_schedules()
        self.load_tb_plan_performances()
        self.load_tb_plan_budgets()
        self.load_tb_plan_achievements()
        self.load_tb_plan_details()
        
        logger.info("âœ… ëª¨ë“  ë°ì´í„° ì ì¬ ì™„ë£Œ")
        self._print_load_summary()

    def _print_load_summary(self):
        """ì ì¬ ìš”ì•½ ì¶œë ¥ (ê°œì„ )"""
        print("\n" + "="*80)
        print("ğŸ“Š Oracle ë°ì´í„° ì ì¬ ìš”ì•½ (ê°œì„  ë²„ì „)")
        print("="*80)
        
        if self.use_existing_tables:
            print(f"âœ… TRUNCATEëœ í…Œì´ë¸”: {self.load_stats['tables_truncated']}ê°œ")
        else:
            print(f"âœ… ìƒì„±ëœ í…Œì´ë¸”: {self.load_stats['tables_created']}ê°œ")
        
        print(f"âœ… ì´ ì ì¬ ë ˆì½”ë“œ: {self.load_stats['total_records']:,}ê±´")
        print(f"âœ… PLAN_ID ë§¤í•‘: {len(self.plan_id_mapping)}ê±´")
        
        print("\nğŸ“Š í…Œì´ë¸”ë³„ ì ì¬ í˜„í™©:")
        for table, count in self.load_stats['records_by_table'].items():
            skipped = self.load_stats['skipped_records'].get(table, 0)
            if skipped > 0:
                print(f"  â€¢ {table}: {count:,}ê±´ (ìŠ¤í‚µ: {skipped:,}ê±´)")
            else:
                print(f"  â€¢ {table}: {count:,}ê±´")
        
        if self.load_stats['errors']:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {len(self.load_stats['errors'])}ê±´")
            for i, error in enumerate(self.load_stats['errors'][:10], 1):
                print(f"  {i}. {error}")
            if len(self.load_stats['errors']) > 10:
                print(f"  ... ì™¸ {len(self.load_stats['errors']) - 10}ê±´")
        
        print("="*80)

    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        self.db_manager.close()


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    from config import ORACLE_CONFIG
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    data_dir = "data"  # CSV ë° JSON íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
    
    # ì ì¬ ì‹¤í–‰
    loader = OracleDBLoader(
        db_config=ORACLE_CONFIG,
        data_dir=data_dir,
        use_existing_tables=True  # ê¸°ì¡´ í…Œì´ë¸” ì‚¬ìš© (TRUNCATEë§Œ)
    )
    
    try:
        # ì—°ê²°
        logger.info("ğŸ”Œ Oracle ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘...")
        loader.connect()
        
        # í…Œì´ë¸” ì¤€ë¹„
        loader.prepare_tables()
        
        # ë°ì´í„° ì ì¬
        loader.load_all_tables()
        
        print("\nâœ… Oracle ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ ì™„ë£Œ (ê°œì„  ë²„ì „)!")
        
    except Exception as e:
        logger.error(f"âŒ ì ì¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise
        
    finally:
        loader.close()


if __name__ == "__main__":
    main()