#!/usr/bin/env python3
"""
ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ
Streamlit ì›¹ UI
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import json
import time
from datetime import datetime
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from extract_pdf_to_json import extract_pdf_to_json
from normalize_government_standard import GovernmentStandardNormalizer
from load_oracle_direct import OracleDirectLoader
from config import ORACLE_CONFIG, INPUT_DIR, OUTPUT_DIR, NORMALIZED_OUTPUT_GOVERNMENT_DIR

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PDF to Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“„",
    layout="wide"
)

SERVER_INPUT_DIR = Path(INPUT_DIR).resolve()
SERVER_OUTPUT_DIR = Path(OUTPUT_DIR).resolve()
SERVER_NORMALIZED_DIR = Path(NORMALIZED_OUTPUT_GOVERNMENT_DIR).resolve()

# ì„œë²„ì—ì„œ ë””ë ‰í† ë¦¬ ìƒì„± (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
SERVER_INPUT_DIR.mkdir(exist_ok=True)
SERVER_OUTPUT_DIR.mkdir(exist_ok=True)
SERVER_NORMALIZED_DIR.mkdir(exist_ok=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'processing_results' not in st.session_state:
    st.session_state.processing_results = []
if 'normalized_stats' not in st.session_state:
    st.session_state.normalized_stats = None
if 'db_stats' not in st.session_state:
    st.session_state.db_stats = None


def save_uploaded_files(uploaded_files):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥ (ì„œë²„ ì»´í“¨í„°ì— ì €ì¥)"""
    SERVER_INPUT_DIR.mkdir(exist_ok=True)

    saved_files = []
    for file in uploaded_files:
        file_path = SERVER_INPUT_DIR / file.name
        with open(file_path, 'wb') as f:
            f.write(file.getbuffer())
        saved_files.append(file_path)

    return saved_files


def process_single_pdf(pdf_path, progress_callback=None):
    """ë‹¨ì¼ PDF ì²˜ë¦¬ (ì„œë²„ì—ì„œ ì‹¤í–‰)"""
    try:
        # OUTPUT_DIR ìƒì„± í™•ì¸
        SERVER_OUTPUT_DIR.mkdir(exist_ok=True)

        # 1. PDF â†’ JSON
        if progress_callback:
            progress_callback(f"ğŸ“„ {pdf_path.name} - PDF íŒŒì‹± ì¤‘...")

        # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

        # PDF íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = pdf_path.stat().st_size
        if file_size == 0:
            raise ValueError(f"PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {pdf_path}")

        st.info(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path.name} ({file_size:,} bytes)")

        # extract_pdf_to_jsonì€ output_dirë¥¼ ë°›ì•„ì„œ ìë™ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        # output_dirì— pdf_path.stem + ".json" í˜•íƒœë¡œ ì €ì¥ë¨
        try:
            extract_pdf_to_json(str(pdf_path), str(SERVER_OUTPUT_DIR))
        except Exception as extract_error:
            raise Exception(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {extract_error}")

        # ìƒì„±ëœ JSON íŒŒì¼ ê²½ë¡œ
        json_path = SERVER_OUTPUT_DIR / f"{pdf_path.stem}.json"

        # JSON íŒŒì¼ì´ ì •ìƒ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not json_path.exists():
            raise FileNotFoundError(f"JSON íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {json_path}")

        # JSON íŒŒì¼ í¬ê¸° í™•ì¸
        json_size = json_path.stat().st_size
        if json_size == 0:
            raise ValueError(f"JSON íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {json_path}")

        # JSON ë‚´ìš© ê²€ì¦
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            pages_count = len(json_data.get('pages', []))
            st.success(f"âœ… {pdf_path.name}: JSON ìƒì„± ì™„ë£Œ ({pages_count}í˜ì´ì§€, {json_size:,} bytes)")

        except json.JSONDecodeError as e:
            raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

        return {'file': pdf_path.name, 'status': 'success', 'json_path': str(json_path), 'pages': pages_count}

    except Exception as e:
        st.error(f"âŒ {pdf_path.name}: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return {'file': pdf_path.name, 'status': 'failed', 'error': str(e)}


def normalize_all_jsons(progress_callback=None):
    """ëª¨ë“  JSON ì •ê·œí™” (ì„œë²„ì—ì„œ ì‹¤í–‰)"""
    # OUTPUT_DIRì—ì„œ JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(SERVER_OUTPUT_DIR.glob("*.json"))

    # âœ… batch_ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ë§Œ ì œì™¸ (ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ ì²˜ë¦¬)
    json_files = [f for f in json_files if not f.name.startswith('batch_')]

    if not json_files:
        st.error(f"âŒ {SERVER_OUTPUT_DIR}ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    if progress_callback:
        progress_callback(f"ğŸ“‹ {len(json_files)}ê°œ JSON íŒŒì¼ ë°œê²¬")

    # ë°œê²¬ëœ íŒŒì¼ ëª©ë¡ ë¡œê¹…
    st.info(f"ì²˜ë¦¬í•  íŒŒì¼: {', '.join([f.name for f in json_files])}")

    # NORMALIZED_OUTPUT_GOVERNMENT_DIR ìƒì„± í™•ì¸
    SERVER_NORMALIZED_DIR.mkdir(exist_ok=True)

    # âœ… ê° JSON íŒŒì¼ë§ˆë‹¤ ê°œë³„ normalizer ìƒì„± (ì—°ë„ê°€ ì„ì´ì§€ ì•Šë„ë¡)
    all_master = []
    all_details = []
    all_budgets = []
    all_schedules = []
    all_performances = []
    all_weights = []

    success_count = 0
    error_details = []

    for i, json_file in enumerate(json_files):
        if progress_callback:
            progress_callback(f"ğŸ“‹ ì •ê·œí™” ì¤‘: {json_file.name} ({i+1}/{len(json_files)})")

        try:
            # âœ… ê° íŒŒì¼ë§ˆë‹¤ ìƒˆë¡œìš´ normalizer ìƒì„±
            normalizer = GovernmentStandardNormalizer(
                json_path=str(json_file),  # â† íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œë¨!
                output_dir=str(SERVER_NORMALIZED_DIR)
            )

            with open(json_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            # JSON ë°ì´í„° êµ¬ì¡° í™•ì¸
            if not json_data:
                error_msg = f"{json_file.name}: JSONì´ ë¹„ì–´ìˆìŒ"
                st.warning(f"âš ï¸ {error_msg}")
                error_details.append(error_msg)
                continue

            if 'pages' not in json_data:
                error_msg = f"{json_file.name}: 'pages' í‚¤ê°€ ì—†ìŒ (í‚¤: {list(json_data.keys())})"
                st.warning(f"âš ï¸ {error_msg}")
                error_details.append(error_msg)
                continue

            pages_count = len(json_data.get('pages', []))
            if pages_count == 0:
                error_msg = f"{json_file.name}: pagesê°€ ë¹„ì–´ìˆìŒ"
                st.warning(f"âš ï¸ {error_msg}")
                error_details.append(error_msg)
                continue

            # ì •ê·œí™” ì‹¤í–‰
            result = normalizer.normalize(json_data)

            if result:
                # âœ… ë°ì´í„° ëˆ„ì 
                all_master.extend(normalizer.data['master'])
                all_details.extend(normalizer.data['details'])
                all_budgets.extend(normalizer.data['budgets'])
                all_schedules.extend(normalizer.data['schedules'])
                all_performances.extend(normalizer.data['performances'])
                all_weights.extend(normalizer.data['weights'])

                success_count += 1
                st.success(f"âœ… {json_file.name}: ì •ê·œí™” ì„±ê³µ ({pages_count}í˜ì´ì§€, {len(normalizer.data['master'])}ê°œ ë‚´ì—­ì‚¬ì—…)")
            else:
                error_msg = f"{json_file.name}: ì •ê·œí™” ì‹¤íŒ¨ (normalize ë°˜í™˜ê°’ False)"
                st.error(f"âŒ {error_msg}")
                error_details.append(error_msg)

        except json.JSONDecodeError as e:
            error_msg = f"{json_file.name}: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}"
            st.error(f"âŒ {error_msg}")
            error_details.append(error_msg)
        except Exception as e:
            error_msg = f"{json_file.name}: ì •ê·œí™” ì¤‘ ì—ëŸ¬ - {e}"
            st.error(f"âŒ {error_msg}")
            error_details.append(error_msg)
            import traceback
            st.code(traceback.format_exc())

    if success_count == 0:
        st.error("âŒ ì •ê·œí™”ì— ì„±ê³µí•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        if error_details:
            with st.expander("ğŸ” ì—ëŸ¬ ìƒì„¸"):
                for error in error_details:
                    st.text(f"- {error}")
        return None

    # ê²½ê³ : ì¼ë¶€ë§Œ ì„±ê³µí•œ ê²½ìš°
    if error_details:
        st.warning(f"âš ï¸ {success_count}/{len(json_files)}ê°œ íŒŒì¼ë§Œ ì •ê·œí™” ì„±ê³µ")
        with st.expander("ğŸ” ì‹¤íŒ¨í•œ íŒŒì¼"):
            for error in error_details:
                st.text(f"- {error}")

    # âœ… ëˆ„ì ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    try:
        import pandas as pd

        # TB_PLAN_MASTER
        if all_master:
            df = pd.DataFrame(all_master)
            df = df[['PLAN_ID', 'YEAR', 'NUM', 'NATION_ORGAN_NM', 'BIZ_NM', 'DETAIL_BIZ_NM']]
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_MASTER.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_MASTER.csv ì €ì¥ ({len(all_master)}ê±´)")

        # TB_PLAN_DETAIL
        if all_details:
            df = pd.DataFrame(all_details)
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_DETAIL.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_DETAIL.csv ì €ì¥ ({len(all_details)}ê±´)")

        # TB_PLAN_BUDGET
        if all_budgets:
            df = pd.DataFrame(all_budgets)
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_BUDGET.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_BUDGET.csv ì €ì¥ ({len(all_budgets)}ê±´)")

        # TB_PLAN_SCHEDULE
        if all_schedules:
            df = pd.DataFrame(all_schedules)
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_SCHEDULE.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_SCHEDULE.csv ì €ì¥ ({len(all_schedules)}ê±´)")

        # TB_PLAN_PERFORMANCE
        if all_performances:
            df = pd.DataFrame(all_performances)
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_PERFORMANCE.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_PERFORMANCE.csv ì €ì¥ ({len(all_performances)}ê±´)")

        # TB_PLAN_WEIGHT
        if all_weights:
            df = pd.DataFrame(all_weights)
            df.to_csv(SERVER_NORMALIZED_DIR / "TB_PLAN_WEIGHT.csv", index=False, encoding='utf-8-sig')
            st.info(f"âœ… TB_PLAN_WEIGHT.csv ì €ì¥ ({len(all_weights)}ê±´)")

        # í†µê³„
        stats = {
            'master': len(all_master),
            'details': len(all_details),
            'budgets': len(all_budgets),
            'schedules': len(all_schedules),
            'performances': len(all_performances)
        }

        if progress_callback:
            progress_callback(f"âœ… ì •ê·œí™” ì™„ë£Œ: {success_count}/{len(json_files)}ê°œ íŒŒì¼, {stats['master']}ê°œ ë‚´ì—­ì‚¬ì—…")

        return stats

    except Exception as e:
        st.error(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None


def load_to_oracle(progress_callback=None):
    """Oracle DB ì ì¬ (ì„œë²„ì—ì„œ ì‹¤í–‰)"""
    try:
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        csv_files = list(SERVER_NORMALIZED_DIR.glob("TB_PLAN_*.csv"))
        if not csv_files:
            raise FileNotFoundError(f"CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {SERVER_NORMALIZED_DIR}")

        if progress_callback:
            progress_callback(f"ğŸ”Œ Oracle DB ì—°ê²° ì¤‘... ({len(csv_files)}ê°œ CSV ë°œê²¬)")

        loader = OracleDirectLoader(ORACLE_CONFIG, str(SERVER_NORMALIZED_DIR))

        try:
            loader.connect()
        except Exception as e:
            raise Exception(f"Oracle ì—°ê²° ì‹¤íŒ¨: {e}")

        if progress_callback:
            progress_callback("ğŸ—ï¸ í…Œì´ë¸” ìƒì„± ì¤‘...")

        try:
            loader.create_tables()
        except Exception as e:
            loader.db_manager.close()
            raise Exception(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")

        if progress_callback:
            progress_callback("ğŸ“Š ë°ì´í„° ì ì¬ ì¤‘...")

        try:
            loader.load_all_tables()
        except Exception as e:
            loader.db_manager.close()
            raise Exception(f"ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")

        loader.db_manager.close()

        # ì ì¬ëœ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        total_records = loader.load_stats.get('total_records', 0)

        if total_records == 0:
            raise Exception("ì ì¬ëœ ë ˆì½”ë“œê°€ 0ê±´ì…ë‹ˆë‹¤. ì—ëŸ¬ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        return loader.load_stats

    except Exception as e:
        error_msg = str(e)

        # ORA ì—ëŸ¬ ì½”ë“œ í•´ì„
        if "ORA-00001" in error_msg:
            raise Exception(f"ì¤‘ë³µ í‚¤ ì—ëŸ¬ (ORA-00001): ì´ë¯¸ ê°™ì€ ë°ì´í„°ê°€ DBì— ì¡´ì¬í•©ë‹ˆë‹¤.\ní•´ï¿½ï¿½ï¿½: Streamlitì„ ì¬ì‹œì‘í•˜ê±°ë‚˜ DB ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì„¸ìš”.")
        elif "ORA-12541" in error_msg:
            raise Exception(f"Oracle ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ORA-12541): ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif "ORA-01017" in error_msg:
            raise Exception(f"ì¸ì¦ ì‹¤íŒ¨ (ORA-01017): ì‚¬ìš©ìëª…/ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            raise Exception(f"Oracle DB ì ì¬ ì‹¤íŒ¨: {error_msg}")


def display_csv_data(csv_dir):
    """CSV ë°ì´í„° í‘œì‹œ"""
    csv_path = Path(csv_dir)

    if not csv_path.exists():
        st.warning("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    csv_files = [f for f in csv_path.glob("*.csv") if f.name != "raw_data.csv"]

    if not csv_files:
        st.warning("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í…Œì´ë¸”ë³„ íƒ­
    tab_names = [f.stem for f in csv_files]
    tabs = st.tabs(tab_names)

    for tab, csv_file in zip(tabs, csv_files):
        with tab:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8-sig')

                st.write(f"**{csv_file.stem}** - {len(df):,}ê±´")

                # ì²˜ìŒ 100ê°œë§Œ í‘œì‹œ
                display_df = df.head(100)
                st.dataframe(display_df, width=None)

                if len(df) > 100:
                    st.info(f"â„¹ï¸ ì „ì²´ {len(df):,}ê±´ ì¤‘ 100ê±´ë§Œ í‘œì‹œë¨")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button(
                    label=f"ğŸ“¥ {csv_file.stem} ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=csv_file.name,
                    mime='text/csv'
                )

            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ UI"""

    # í—¤ë”
    st.title("ğŸ“„ ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì‹œìŠ¤í…œ")
    st.markdown("**ì •ë¶€ ì‹œí–‰ê³„íš PDF ìë™ íŒŒì‹± ë° ë°ì´í„°ë² ì´ìŠ¤ ì ì¬**")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        enable_db_load = st.checkbox(
            "ğŸ—„ï¸ Oracle DB ì ì¬",
            value=True,
            help="ì²´í¬ í•´ì œ ì‹œ CSVë§Œ ìƒì„±"
        )

        st.markdown("---")

        st.subheader("ğŸ“Š Oracle DB ì •ë³´")
        st.text(f"Host: {ORACLE_CONFIG['host']}")
        st.text(f"SID: {ORACLE_CONFIG['sid']}")
        st.text(f"User: {ORACLE_CONFIG['user']}")

        # DB ì´ˆê¸°í™” ë²„íŠ¼
        st.markdown("---")

        if st.button("ğŸ—‘ï¸ DB ë°ì´í„° ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            try:
                with st.spinner("DB ì´ˆê¸°í™” ì¤‘..."):
                    loader = OracleDirectLoader(ORACLE_CONFIG, str(SERVER_NORMALIZED_DIR))

                    # ì—°ê²°
                    loader.connect()

                    # í…Œì´ë¸” ì‚­ì œ
                    truncated_count = loader.truncate_tables()

                    # ëª…ì‹œì  ì»¤ë°‹
                    loader.db_manager.connection.commit()

                    # ì—°ê²° ì¢…ë£Œ
                    loader.db_manager.close()

                if truncated_count > 0:
                    st.success(f"âœ… DB ë°ì´í„° ì‚­ì œ ì™„ë£Œ! ({truncated_count}ê°œ í…Œì´ë¸”)")
                    st.info("â„¹ï¸ ì´ì œ PDFë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë©´ ì¤‘ë³µ ì—ëŸ¬ ì—†ì´ ì ì¬ë©ë‹ˆë‹¤.")
                else:
                    st.warning("âš ï¸ ì‚­ì œëœ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                import traceback
                with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬"):
                    st.code(traceback.format_exc())

                # í•´ê²° ë°©ë²• ì•ˆë‚´
                st.markdown("""
                **ğŸ’¡ ìˆ˜ë™ í•´ê²° ë°©ë²• (Oracle SQL Developer):**
                ```sql
                -- ì—­ìˆœìœ¼ë¡œ ì‹¤í–‰í•˜ì„¸ìš” (FK ì œì•½ì¡°ê±´ ë•Œë¬¸)
                TRUNCATE TABLE TB_PLAN_WEIGHT CASCADE;
                TRUNCATE TABLE TB_PLAN_PERFORMANCE CASCADE;
                TRUNCATE TABLE TB_PLAN_SCHEDULE CASCADE;
                TRUNCATE TABLE TB_PLAN_BUDGET CASCADE;
                TRUNCATE TABLE TB_PLAN_DETAIL CASCADE;
                TRUNCATE TABLE TB_PLAN_MASTER CASCADE;
                COMMIT;
                ```
                
                ë˜ëŠ” DELETE ì‚¬ìš©:
                ```sql
                DELETE FROM TB_PLAN_WEIGHT;
                DELETE FROM TB_PLAN_PERFORMANCE;
                DELETE FROM TB_PLAN_SCHEDULE;
                DELETE FROM TB_PLAN_BUDGET;
                DELETE FROM TB_PLAN_DETAIL;
                DELETE FROM TB_PLAN_MASTER;
                COMMIT;
                ```
                """)

        st.markdown("---")

        st.info("""
        **ì²˜ë¦¬ ë‹¨ê³„:**
        1. PDF ì—…ë¡œë“œ
        2. PDF â†’ JSON ë³€í™˜
        3. JSON â†’ CSV ì •ê·œí™” (ì •ë¶€ í‘œì¤€)
        4. CSV â†’ Oracle DB ì ì¬
        
        **ìµœì‹  ê°œì„ ì‚¬í•­:** âœ¨
        - ì •ì„±ì  ì„±ê³¼ ìë™ ì¶”ì¶œ
        - ì„¸ë¶€ì¼ì •ì˜ ì‹¤ì œ ë‚ ì§œ íŒŒì‹±
        """)

    # ë©”ì¸ íƒ­
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ì—…ë¡œë“œ", "ğŸ“Š ì²˜ë¦¬ ê²°ê³¼", "ğŸ“ CSV ë°ì´í„°", "ğŸ—„ï¸ DB í†µê³„"])

    with tab1:
        st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")

        uploaded_files = st.file_uploader(
            "PDF íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
            type=['pdf'],
            accept_multiple_files=True,
            help="ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")

            # íŒŒì¼ ëª©ë¡
            with st.expander("ğŸ“‹ ì„ íƒëœ íŒŒì¼", expanded=True):
                for file in uploaded_files:
                    st.write(f"- {file.name} ({file.size:,} bytes)")

            # ì²˜ë¦¬ ì‹œì‘
            col1, col2 = st.columns([3, 1])

            with col1:
                process_button = st.button(
                    "ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰",
                    type="primary",
                    use_container_width=True
                )

            with col2:
                clear_button = st.button(
                    "ğŸ—‘ï¸ ì´ˆê¸°í™”",
                    use_container_width=True
                )

            if clear_button:
                st.session_state.processing_results = []
                st.session_state.normalized_stats = None
                st.session_state.db_stats = None
                st.rerun()

            if process_button:
                progress_container = st.container()

                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    start_time = time.time()

                    try:
                        # 1ë‹¨ê³„: íŒŒì¼ ì €ì¥
                        status_text.text("ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
                        saved_files = save_uploaded_files(uploaded_files)
                        progress_bar.progress(0.1)

                        # 2ë‹¨ê³„: PDF â†’ JSON
                        status_text.text("ğŸ“„ PDF íŒŒì‹± ì¤‘...")
                        results = []

                        for i, pdf_file in enumerate(saved_files):
                            def progress_cb(msg):
                                status_text.text(msg)

                            result = process_single_pdf(pdf_file, progress_cb)
                            results.append(result)
                            progress_bar.progress(0.1 + 0.4 * (i + 1) / len(saved_files))

                        st.session_state.processing_results = results

                        success_count = sum(1 for r in results if r['status'] == 'success')

                        if success_count == 0:
                            st.error("âŒ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
                            return

                        # 3ë‹¨ê³„: JSON â†’ CSV ì •ê·œí™”
                        status_text.text("ğŸ“‹ ë°ì´í„° ì •ê·œí™” ì¤‘...")
                        norm_stats = normalize_all_jsons(lambda msg: status_text.text(msg))
                        st.session_state.normalized_stats = norm_stats
                        progress_bar.progress(0.7)

                        # 4ë‹¨ê³„: Oracle DB ì ì¬
                        db_stats = None  # âœ… ì´ˆê¸°í™”
                        if enable_db_load:
                            status_text.text("ğŸ—„ï¸ Oracle DB ì ì¬ ì¤‘...")
                            try:
                                db_stats = load_to_oracle(lambda msg: status_text.text(msg))
                                st.session_state.db_stats = db_stats
                                progress_bar.progress(1.0)
                            except Exception as db_error:
                                progress_bar.progress(1.0)
                                st.error(f"âŒ Oracle DB ì ì¬ ì‹¤íŒ¨: {db_error}")

                                # ì—ëŸ¬ ìƒì„¸ ì •ë³´
                                with st.expander("ğŸ” DB ì—ëŸ¬ ìƒì„¸"):
                                    st.code(str(db_error))

                                    # í•´ê²° ë°©ë²• ì•ˆë‚´
                                    st.markdown("""
                                    **í•´ê²° ë°©ë²•:**
                                    1. **ì¤‘ë³µ ë°ì´í„° ì—ëŸ¬ (ORA-00001):**
                                       - ì•„ë˜ SQLì„ ì‹¤í–‰í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ:
                                       ```sql
                                       TRUNCATE TABLE TB_PLAN_PERFORMANCE;
                                       TRUNCATE TABLE TB_PLAN_SCHEDULE;
                                       TRUNCATE TABLE TB_PLAN_BUDGET;
                                       TRUNCATE TABLE TB_PLAN_DETAIL;
                                       TRUNCATE TABLE TB_PLAN_MASTER;
                                       TRUNCATE TABLE TB_PLAN_WEIGHT;
                                       ```
                                       - ë˜ëŠ” Streamlit ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.
                                    
                                    2. **ì—°ê²° ì‹¤íŒ¨:**
                                       - Oracle ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                                       - config.pyì˜ ì ‘ì† ì •ë³´ í™•ì¸
                                    """)

                                # DB ì ì¬ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ CSVëŠ” ìƒì„±ë¨
                                st.warning("âš ï¸ CSV íŒŒì¼ì€ ì •ìƒ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 'CSV ë°ì´í„°' íƒ­ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                        else:
                            progress_bar.progress(1.0)

                        elapsed = time.time() - start_time

                        status_text.empty()
                        progress_bar.empty()

                        # ì™„ë£Œ ë©”ì‹œì§€
                        st.success(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
                        st.balloons()

                        # ê²°ê³¼ ìš”ì•½
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ğŸ“„ ì²˜ë¦¬ ì„±ê³µ", f"{success_count}/{len(results)}")
                        with col2:
                            if norm_stats:
                                st.metric("ğŸ“Š ë‚´ì—­ì‚¬ì—…", f"{norm_stats['master']}ê°œ")
                        with col3:
                            if enable_db_load and db_stats:
                                st.metric("ğŸ—„ï¸ DB ì ì¬", f"{db_stats['total_records']:,}ê±´")

                    except Exception as e:
                        st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        import traceback
                        with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬"):
                            st.code(traceback.format_exc())

    with tab2:
        st.header("ì²˜ë¦¬ ê²°ê³¼")

        if st.session_state.processing_results:
            results = st.session_state.processing_results

            success = [r for r in results if r['status'] == 'success']
            failed = [r for r in results if r['status'] == 'failed']

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ íŒŒì¼", len(results))
            with col2:
                st.metric("ì„±ê³µ", len(success), delta_color="normal")
            with col3:
                st.metric("ì‹¤íŒ¨", len(failed), delta_color="inverse")

            # ì„±ê³µ ëª©ë¡
            if success:
                st.subheader("âœ… ì„±ê³µ")
                for r in success:
                    st.write(f"- {r['file']}")

            # ì‹¤íŒ¨ ëª©ë¡
            if failed:
                st.subheader("âŒ ì‹¤íŒ¨")
                for r in failed:
                    st.error(f"- {r['file']}: {r.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

            # ì •ê·œí™” í†µê³„
            if st.session_state.normalized_stats:
                st.subheader("ğŸ“Š ì •ê·œí™” í†µê³„")
                stats = st.session_state.normalized_stats

                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("ë§ˆìŠ¤í„°", stats['master'])
                with col2:
                    st.metric("ìƒì„¸", stats['details'])
                with col3:
                    st.metric("ì˜ˆì‚°", stats['budgets'])
                with col4:
                    st.metric("ì¼ì •", stats['schedules'])
                with col5:
                    st.metric("ì„±ê³¼", stats['performances'])

                st.info("â„¹ï¸ ì„±ê³¼ì—ëŠ” ì •ëŸ‰ì  ì„±ê³¼(íŠ¹í—ˆ, ë…¼ë¬¸)ì™€ ì •ì„±ì  ì„±ê³¼(ì¶”ì§„ì‹¤ì )ê°€ ëª¨ë‘ í¬í•¨ë©ë‹ˆë‹¤.")
        else:
            st.info("â„¹ï¸ ì•„ì§ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab3:
        st.header("CSV ë°ì´í„°")

        st.markdown("""
        **ğŸ“‹ í…Œì´ë¸” êµ¬ì¡°:**
        - **TB_PLAN_MASTER**: ë‚´ì—­ì‚¬ì—… ê¸°ë³¸ ì •ë³´
        - **TB_PLAN_DETAIL**: ì‚¬ì—… ìƒì„¸ ì •ë³´
        - **TB_PLAN_BUDGET**: ì—°ë„ë³„ ì˜ˆì‚° (ì‹¤ì /ê³„íš êµ¬ë¶„)
        - **TB_PLAN_SCHEDULE**: ì¼ì • ì •ë³´ (ì‹¤ì œ ì›” ì •ë³´ ìš°ì„  íŒŒì‹± âœ¨)
        - **TB_PLAN_PERFORMANCE**: ì„±ê³¼ ì •ë³´ (ì •ëŸ‰ì  + ì •ì„±ì  âœ¨)
        """)

        if SERVER_NORMALIZED_DIR.exists():
            display_csv_data(SERVER_NORMALIZED_DIR)
        else:
            st.info("â„¹ï¸ CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”.")

    with tab4:
        st.header("Oracle DB í†µê³„")

        if st.session_state.db_stats:
            stats = st.session_state.db_stats

            st.metric("ì´ ì ì¬ ë ˆì½”ë“œ", f"{stats['total_records']:,}ê±´")

            st.subheader("ğŸ“Š í…Œì´ë¸”ë³„ í†µê³„")

            table_data = []
            for table, count in stats['records_by_table'].items():
                table_data.append({'í…Œì´ë¸”': table, 'ë ˆì½”ë“œ ìˆ˜': f"{count:,}ê±´"})

            df = pd.DataFrame(table_data)
            st.dataframe(df, width=None)

        else:
            st.info("â„¹ï¸ Oracle DB ì ì¬ í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

            if not enable_db_load:
                st.warning("âš ï¸ 'Oracle DB ì ì¬' ì˜µì…˜ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ v1.0 | 2025
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()

