#!/usr/bin/env python3
"""
ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ
Streamlit ì›¹ UI
"""

import streamlit as st
import pandas as pd
from pathlib import Path
import json
import time
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from extract_pdf_to_json import extract_pdf_to_json
from normalize_government_standard import GovernmentStandardNormalizer
from load_oracle_direct import OracleDirectLoader
from config import ORACLE_CONFIG, INPUT_DIR, OUTPUT_DIR, NORMALIZED_OUTPUT_GOVERNMENT_DIR, ORACLE_CONFIG_DEV

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PDF to Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“„",
    layout="wide"
)

SERVER_INPUT_DIR = Path(INPUT_DIR).resolve()
SERVER_OUTPUT_DIR = Path(OUTPUT_DIR).resolve()
SERVER_NORMALIZED_DIR = Path(NORMALIZED_OUTPUT_GOVERNMENT_DIR).resolve()

# ì„œë²„ì—ì„œ ë””ë ‰í† ë¦¬ ìƒì„± (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
SERVER_INPUT_DIR.mkdir(exist_ok=True)
SERVER_OUTPUT_DIR.mkdir(exist_ok=True)
SERVER_NORMALIZED_DIR.mkdir(exist_ok=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'processing_results' not in st.session_state:
    st.session_state.processing_results = []
if 'normalized_stats' not in st.session_state:
    st.session_state.normalized_stats = None
if 'db_stats' not in st.session_state:
    st.session_state.db_stats = None


def save_uploaded_files(uploaded_files):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥ (ì„œë²„ ì»´í“¨í„°ì— ì €ì¥)"""
    SERVER_INPUT_DIR.mkdir(exist_ok=True)

    saved_files = []
    for file in uploaded_files:
        file_path = SERVER_INPUT_DIR / file.name
        with open(file_path, 'wb') as f:
            f.write(file.getbuffer())
        saved_files.append(file_path)

    return saved_files


def process_single_pdf(pdf_path, progress_callback=None):
    """ë‹¨ì¼ PDF ì²˜ë¦¬ (ì„œë²„ì—ì„œ ì‹¤í–‰)"""
    try:
        # OUTPUT_DIR ìƒì„± í™•ì¸
        SERVER_OUTPUT_DIR.mkdir(exist_ok=True)

        # 1. PDF â†’ JSON
        if progress_callback:
            progress_callback(f"ğŸ“„ {pdf_path.name} - PDF íŒŒì‹± ì¤‘...")

        # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

        # PDF íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = pdf_path.stat().st_size
        if file_size == 0:
            raise ValueError(f"PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {pdf_path}")

        st.info(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path.name} ({file_size:,} bytes)")

        # extract_pdf_to_jsonì€ output_dirë¥¼ ë°›ì•„ì„œ ìë™ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
        # output_dirì— pdf_path.stem + ".json" í˜•íƒœë¡œ ì €ì¥ë¨
        try:
            extract_pdf_to_json(str(pdf_path), str(SERVER_OUTPUT_DIR))
        except Exception as extract_error:
            raise Exception(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {extract_error}")

        # ìƒì„±ëœ JSON íŒŒì¼ ê²½ë¡œ
        json_path = SERVER_OUTPUT_DIR / f"{pdf_path.stem}.json"

        # JSON íŒŒì¼ì´ ì •ìƒ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not json_path.exists():
            raise FileNotFoundError(f"JSON íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {json_path}")

        # JSON íŒŒì¼ í¬ê¸° í™•ì¸
        json_size = json_path.stat().st_size
        if json_size == 0:
            raise ValueError(f"JSON íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {json_path}")

        # JSON ë‚´ìš© ê²€ì¦
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)

            pages_count = len(json_data.get('pages', []))
            st.success(f"âœ… {pdf_path.name}: JSON ìƒì„± ì™„ë£Œ ({pages_count}í˜ì´ì§€, {json_size:,} bytes)")

        except json.JSONDecodeError as e:
            raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

        return {'file': pdf_path.name, 'status': 'success', 'json_path': str(json_path), 'pages': pages_count}

    except Exception as e:
        st.error(f"âŒ {pdf_path.name}: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return {'file': pdf_path.name, 'status': 'failed', 'error': str(e)}


def normalize_all_jsons(progress_callback=None):
    """ëª¨ë“  JSON ì •ê·œí™” (ì„œë²„ì—ì„œ ì‹¤í–‰) - main.py ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •"""
    # OUTPUT_DIRì—ì„œ JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(SERVER_OUTPUT_DIR.glob("*.json"))
    json_files = [f for f in json_files if not f.name.startswith('batch_')]

    if not json_files:
        st.error(f"âŒ {SERVER_OUTPUT_DIR}ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    if progress_callback:
        progress_callback(f"ğŸ“‹ {len(json_files)}ê°œ JSON íŒŒì¼ ë°œê²¬")

    st.info(f"ì²˜ë¦¬í•  íŒŒì¼: {', '.join([f.name for f in json_files])}")
    SERVER_NORMALIZED_DIR.mkdir(exist_ok=True)

    try:
        # 1. ëª¨ë“  JSON ë¡œë“œ
        all_json_data = []
        for i, json_file in enumerate(json_files, 1):
            if progress_callback:
                progress_callback(f"ğŸ“‚ JSON ë¡œë“œ ì¤‘: {json_file.name} ({i}/{len(json_files)})")

            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    all_json_data.append(json_data)
            except Exception as e:
                st.error(f"âŒ JSON ë¡œë“œ ì‹¤íŒ¨ {json_file.name}: {e}")

        st.info(f"âœ… {len(all_json_data)}ê°œ JSON ë¡œë“œ ì™„ë£Œ")

        if not all_json_data:
            st.error("âŒ ë¡œë“œëœ JSONì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # 2. Oracle DB ì—°ê²° (PLAN_ID ë§¤ì¹­ìš©)
        from oracle_db_manager import OracleDBManager
        db_manager = None

        try:
            db_manager = OracleDBManager(ORACLE_CONFIG)
            db_manager.connect()
            st.success("ğŸ”— DB ì—°ê²° ì„±ê³µ (PLAN_ID ë§¤ì¹­ìš©)")
        except Exception as e:
            st.warning(f"âš ï¸ DB ì—°ê²° ì‹¤íŒ¨ (ì‹ ê·œ PLAN_IDë¡œ ìƒì„±): {e}")
            db_manager = None

        # 3. ì²« ë²ˆì§¸ íŒŒì¼ë¡œ normalizer ì´ˆê¸°í™” (DB ì—°ê²° ì „ë‹¬)
        if progress_callback:
            progress_callback("ğŸ“‹ ë°ì´í„° ì •ê·œí™” ì‹œì‘...")

        normalizer = GovernmentStandardNormalizer(
            str(json_files[0]),
            str(SERVER_NORMALIZED_DIR),
            db_manager=db_manager  # âœ… DB ì—°ê²° ì „ë‹¬
        )

        # 4. ê° JSON íŒŒì¼ë³„ë¡œ ì²˜ë¦¬ (íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ í›„ ëˆ„ì )
        for json_file, json_data in zip(json_files, all_json_data):
            if progress_callback:
                progress_callback(f"ğŸ“‹ ì •ê·œí™” ì¤‘: {json_file.name}")

            # íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ
            import re
            filename = json_file.stem
            year_match = re.search(r'(20\d{2})', filename)

            if year_match:
                doc_year = int(year_match.group(1))
                st.info(f"ğŸ“… {filename} -> {doc_year}ë…„ë„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

                # âœ… ì—°ë„ë³„ë¡œ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (main.pyì™€ ë™ì¼)
                normalizer.current_context['document_year'] = doc_year
                normalizer.current_context['performance_year'] = doc_year - 1
                normalizer.current_context['plan_year'] = doc_year

            # ì •ê·œí™” ì‹¤í–‰ (ë°ì´í„° ëˆ„ì )
            normalizer.normalize(json_data)

        # 5. í•œ ë²ˆì— CSV ì €ì¥ (main.pyì™€ ë™ì¼)
        if progress_callback:
            progress_callback("ğŸ’¾ CSV ì €ì¥ ì¤‘...")

        normalizer.save_to_csv()

        # DB ì—°ê²° ì¢…ë£Œ
        if db_manager:
            db_manager.close()
            st.info("ğŸ”Œ DB ì—°ê²° ì¢…ë£Œ")

        # 6. í†µê³„ ì¶œë ¥
        stats = {
            'plan_data': len(normalizer.data['plan_data']),
            'budgets': len(normalizer.data['budgets']),
            'schedules': len(normalizer.data['schedules']),
            'performances': len(normalizer.data['performances']),
            'achievements': len(normalizer.data['achievements'])
        }

        st.success(f"""
        âœ… ì •ê·œí™” ì™„ë£Œ!
        - ë‚´ì—­ì‚¬ì—…: {stats['plan_data']}ê°œ
        - ì˜ˆì‚°: {stats['budgets']}ê±´
        - ì¼ì •: {stats['schedules']}ê±´
        - ì„±ê³¼: {stats['performances']}ê±´
        - ëŒ€í‘œì„±ê³¼: {stats['achievements']}ê±´
        """)

        if progress_callback:
            progress_callback(f"âœ… ì •ê·œí™” ì™„ë£Œ: {stats['plan_data']}ê°œ ë‚´ì—­ì‚¬ì—…")

        return stats

    except Exception as e:
        st.error(f"âŒ ì •ê·œí™” ì‹¤íŒ¨: {e}")
        import traceback
        st.code(traceback.format_exc())
        return None


def load_to_oracle(progress_callback=None):
    """Oracle DB ì ì¬ (ì„œë²„ì—ì„œ ì‹¤í–‰)"""
    try:
        # CSV íŒŒì¼ ì¡´ì¬ í™•ì¸
        csv_files = list(SERVER_NORMALIZED_DIR.glob("TB_PLAN_*.csv"))
        if not csv_files:
            raise FileNotFoundError(f"CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {SERVER_NORMALIZED_DIR}")

        if progress_callback:
            progress_callback(f"ğŸ”Œ Oracle DB ì—°ê²° ì¤‘... ({len(csv_files)}ê°œ CSV ë°œê²¬)")

        # 2ê°œ DB ì—°ê²°: ì½ê¸°(BICS) + ì“°ê¸°(BICS_DEV)
        loader = OracleDirectLoader(
            db_config_read=ORACLE_CONFIG,
            db_config_write=ORACLE_CONFIG_DEV,
            csv_dir=str(SERVER_NORMALIZED_DIR)
        )

        try:
            loader.connect()
        except Exception as e:
            raise Exception(f"Oracle ì—°ê²° ì‹¤íŒ¨: {e}")

        if progress_callback:
            progress_callback("ğŸ” ê¸°ì¡´ TB_PLAN_DATAì™€ ë§¤ì¹­ ì¤‘...")

        try:
            # âœ… ë§¤ì¹­ ê¸°ë°˜ ì ì¬ ì‹¤í–‰
            # - BICSì˜ TB_PLAN_DATAë¥¼ BICS_DEVë¡œ ë³µì‚¬ (FKìš©)
            # - ê¸°ì¡´ BICS.TB_PLAN_DATA ì¡°íšŒ (ë§¤ì¹­ìš©)
            # - CSVì™€ ë§¤ì¹­ (YEAR, BIZ_NM, DETAIL_BIZ_NM ê¸°ì¤€)
            # - ë§¤ì¹­ ë¦¬í¬íŠ¸ ìƒì„±
            # - í•˜ìœ„ 4ê°œ í…Œì´ë¸” BICS_DEVì— ì ì¬
            loader.load_with_matching()
        except Exception as e:
            loader.close()
            raise Exception(f"ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")

        loader.close()

        # ì ì¬ í†µê³„
        total_records = loader.load_stats.get('total_records', 0)
        matched = loader.load_stats.get('matched', 0)
        unmatched = loader.load_stats.get('unmatched', 0)
        diff_found = loader.load_stats.get('diff_found', 0)

        if total_records == 0 and matched == 0:
            raise Exception(f"ì ì¬ëœ ë ˆì½”ë“œê°€ 0ê±´ì…ë‹ˆë‹¤.\në§¤ì¹­ ì„±ê³µ: {matched}ê±´, ì‹¤íŒ¨: {unmatched}ê±´\nì°¨ì´ì  ë°œê²¬: {diff_found}ê±´")

        return loader.load_stats

    except Exception as e:
        error_msg = str(e)

        # ORA ì—ëŸ¬ ì½”ë“œ í•´ì„
        if "ORA-00001" in error_msg:
            raise Exception(f"ì¤‘ë³µ í‚¤ ì—ëŸ¬ (ORA-00001): ì´ë¯¸ ê°™ì€ ë°ì´í„°ê°€ í•˜ìœ„ í…Œì´ë¸”ì— ì¡´ì¬í•©ë‹ˆë‹¤.\ní•´ê²°: ì‚¬ì´ë“œë°”ì—ì„œ 'DB ë°ì´í„° ì´ˆê¸°í™”' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")
        elif "ORA-02291" in error_msg:
            raise Exception(f"FK ì œì•½ ì¡°ê±´ ìœ„ë°˜ (ORA-02291): ë¶€ëª¨ í‚¤(PLAN_ID)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nê¸°ì¡´ TB_PLAN_DATAì— í•´ë‹¹ ë‚´ì—­ì‚¬ì—…ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në§¤ì¹­ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: {SERVER_NORMALIZED_DIR}/matching_reports/")
        elif "ORA-12541" in error_msg:
            raise Exception(f"Oracle ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ORA-12541): ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif "ORA-01017" in error_msg:
            raise Exception(f"ì¸ì¦ ì‹¤íŒ¨ (ORA-01017): ì‚¬ìš©ìëª…/ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”. (í˜„ì¬: {ORACLE_CONFIG['user']})")
        else:
            raise Exception(f"Oracle DB ì ì¬ ì‹¤íŒ¨: {error_msg}")


def display_csv_data(csv_dir):
    """CSV ë°ì´í„° í‘œì‹œ"""
    csv_path = Path(csv_dir)

    if not csv_path.exists():
        st.warning("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    csv_files = [f for f in csv_path.glob("*.csv") if f.name != "raw_data.csv"]

    if not csv_files:
        st.warning("âŒ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í…Œì´ë¸”ë³„ íƒ­
    tab_names = [f.stem for f in csv_files]
    tabs = st.tabs(tab_names)

    for tab, csv_file in zip(tabs, csv_files):
        with tab:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8-sig')

                st.write(f"**{csv_file.stem}** - {len(df):,}ê±´")

                # ì²˜ìŒ 100ê°œë§Œ í‘œì‹œ
                display_df = df.head(100)
                st.dataframe(display_df, width=None)

                if len(df) > 100:
                    st.info(f"â„¹ï¸ ì „ì²´ {len(df):,}ê±´ ì¤‘ 100ê±´ë§Œ í‘œì‹œë¨")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button(
                    label=f"ğŸ“¥ {csv_file.stem} ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=csv_file.name,
                    mime='text/csv'
                )

            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ UI"""

    # í—¤ë”
    st.title("ğŸ“„ ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì‹œìŠ¤í…œ")
    st.markdown("**ì •ë¶€ ì‹œí–‰ê³„íš PDF ìë™ íŒŒì‹± ë° ë°ì´í„°ë² ì´ìŠ¤ ì ì¬**")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        enable_db_load = st.checkbox(
            "ğŸ—„ï¸ Oracle DB ì ì¬",
            value=True,
            help="ì²´í¬ í•´ì œ ì‹œ CSVë§Œ ìƒì„±"
        )

        st.markdown("---")

        st.subheader("ğŸ“Š Oracle DB ì •ë³´")
        st.text("ğŸ” ì½ê¸°ìš© (BICS):")
        st.text(f"  Host: {ORACLE_CONFIG['host']}")
        st.text(f"  User: {ORACLE_CONFIG['user']}")
        st.text("")
        st.text("âœï¸ ì“°ê¸°ìš© (BICS_DEV):")
        st.text(f"  Host: {ORACLE_CONFIG_DEV['host']}")
        st.text(f"  User: {ORACLE_CONFIG_DEV['user']}")

        # DB ì´ˆê¸°í™” ë²„íŠ¼
        st.markdown("---")

        if st.button("ğŸ—‘ï¸ BICS_DEV í•˜ìœ„í…Œì´ë¸” ì´ˆê¸°í™”", type="secondary", use_container_width=True):
            try:
                with st.spinner("BICS_DEV í•˜ìœ„ í…Œì´ë¸” ì´ˆê¸°í™” ì¤‘..."):
                    loader = OracleDirectLoader(
                        db_config_read=ORACLE_CONFIG,
                        db_config_write=ORACLE_CONFIG_DEV,
                        csv_dir=str(SERVER_NORMALIZED_DIR)
                    )

                    # ì—°ê²°
                    loader.connect()

                    # BICS_DEVì˜ í•˜ìœ„ í…Œì´ë¸”ë§Œ ì‚­ì œ
                    cursor = loader.db_manager_write.connection.cursor()
                    deleted_tables = []

                    for table in ['TB_PLAN_ACHIEVEMENTS', 'TB_PLAN_PERFORMANCE', 'TB_PLAN_SCHEDULE', 'TB_PLAN_BUDGET']:
                        try:
                            cursor.execute(f"DELETE FROM {table}")
                            deleted_count = cursor.rowcount
                            loader.db_manager_write.connection.commit()
                            deleted_tables.append(f"{table}: {deleted_count}ê±´")
                            st.info(f"âœ… {table} ì‚­ì œ: {deleted_count}ê±´")
                        except Exception as e:
                            st.warning(f"âš ï¸ {table} ì‚­ì œ ì‹¤íŒ¨: {e}")

                    cursor.close()

                    # ì—°ê²° ì¢…ë£Œ
                    loader.close()

                if deleted_tables:
                    st.success(f"âœ… BICS_DEV í•˜ìœ„ í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ!")
                    with st.expander("ğŸ“‹ ì‚­ì œ ë‚´ì—­"):
                        for item in deleted_tables:
                            st.text(f"â€¢ {item}")
                    st.info("â„¹ï¸ TB_PLAN_DATAëŠ” ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ PDFë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•˜ë©´ ì¤‘ë³µ ì—†ì´ ì ì¬ë©ë‹ˆë‹¤.")
                else:
                    st.warning("âš ï¸ ì‚­ì œëœ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                import traceback
                with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬"):
                    st.code(traceback.format_exc())

                # í•´ê²° ë°©ë²• ì•ˆë‚´
                st.markdown("""
                **ğŸ’¡ ìˆ˜ë™ í•´ê²° ë°©ë²• (Oracle SQL Developer):**
                
                âš ï¸ TB_PLAN_DATAëŠ” ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”! (BICSì—ì„œ ë³µì‚¬ëœ ì›ë³¸ ìœ ì§€)
                
                ```sql
                -- BICS_DEV ìŠ¤í‚¤ë§ˆì˜ í•˜ìœ„ í…Œì´ë¸”ë§Œ ì‚­ì œ
                DELETE FROM BICS_DEV.TB_PLAN_ACHIEVEMENTS;
                DELETE FROM BICS_DEV.TB_PLAN_PERFORMANCE;
                DELETE FROM BICS_DEV.TB_PLAN_SCHEDULE;
                DELETE FROM BICS_DEV.TB_PLAN_BUDGET;
                COMMIT;
                ```
                """)

        st.markdown("---")

        st.info("""
        **ì²˜ë¦¬ ë‹¨ê³„:**
        1. PDF ì—…ë¡œë“œ
        2. PDF â†’ JSON ë³€í™˜
        3. JSON â†’ CSV ì •ê·œí™” (ì •ë¶€ í‘œì¤€)
        4. CSV â†’ Oracle DB ì ì¬
        
        **ìµœì‹  ê°œì„ ì‚¬í•­:** âœ¨
        - 2ê°œ DB ì—°ê²° (BICS ì½ê¸° + BICS_DEV ì“°ê¸°)
        - PLAN_ID ìë™ ë§¤ì¹­ (100%)
        - TB_PLAN_DATA ìë™ ë³µì‚¬ (BICS â†’ BICS_DEV)
        - í•˜ìœ„ 4ê°œ í…Œì´ë¸” ì™„ì „ ì ì¬
        - íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
        - FK ì œì•½ì¡°ê±´ ìë™ ì²˜ë¦¬
        """)

    # ë©”ì¸ íƒ­
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ì—…ë¡œë“œ", "ğŸ“Š ì²˜ë¦¬ ê²°ê³¼", "ğŸ“ CSV ë°ì´í„°", "ğŸ—„ï¸ DB í†µê³„"])

    with tab1:
        st.header("PDF íŒŒì¼ ì—…ë¡œë“œ")

        uploaded_files = st.file_uploader(
            "PDF íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)",
            type=['pdf'],
            accept_multiple_files=True,
            help="ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )

        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")

            # íŒŒì¼ ëª©ë¡
            with st.expander("ğŸ“‹ ì„ íƒëœ íŒŒì¼", expanded=True):
                for file in uploaded_files:
                    st.write(f"- {file.name} ({file.size:,} bytes)")

            # ì²˜ë¦¬ ì‹œì‘
            col1, col2 = st.columns([3, 1])

            with col1:
                process_button = st.button(
                    "ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰",
                    type="primary",
                    use_container_width=True
                )

            with col2:
                clear_button = st.button(
                    "ğŸ—‘ï¸ ì´ˆê¸°í™”",
                    use_container_width=True
                )

            if clear_button:
                st.session_state.processing_results = []
                st.session_state.normalized_stats = None
                st.session_state.db_stats = None
                st.rerun()

            if process_button:
                progress_container = st.container()

                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    start_time = time.time()

                    try:
                        # 1ë‹¨ê³„: íŒŒì¼ ì €ì¥
                        status_text.text("ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
                        saved_files = save_uploaded_files(uploaded_files)
                        progress_bar.progress(0.1)

                        # 2ë‹¨ê³„: PDF â†’ JSON
                        status_text.text("ğŸ“„ PDF íŒŒì‹± ì¤‘...")
                        results = []

                        for i, pdf_file in enumerate(saved_files):
                            def progress_cb(msg):
                                status_text.text(msg)

                            result = process_single_pdf(pdf_file, progress_cb)
                            results.append(result)
                            progress_bar.progress(0.1 + 0.4 * (i + 1) / len(saved_files))

                        st.session_state.processing_results = results

                        success_count = sum(1 for r in results if r['status'] == 'success')

                        if success_count == 0:
                            st.error("âŒ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
                            return

                        # 3ë‹¨ê³„: JSON â†’ CSV ì •ê·œí™”
                        status_text.text("ğŸ“‹ ë°ì´í„° ì •ê·œí™” ì¤‘...")
                        norm_stats = normalize_all_jsons(lambda msg: status_text.text(msg))
                        st.session_state.normalized_stats = norm_stats
                        progress_bar.progress(0.7)

                        # 4ë‹¨ê³„: Oracle DB ì ì¬
                        db_stats = None  # âœ… ì´ˆê¸°í™”
                        if enable_db_load:
                            status_text.text("ğŸ—„ï¸ Oracle DB ì ì¬ ì¤‘...")
                            try:
                                db_stats = load_to_oracle(lambda msg: status_text.text(msg))
                                st.session_state.db_stats = db_stats
                                progress_bar.progress(1.0)
                            except Exception as db_error:
                                progress_bar.progress(1.0)
                                st.error(f"âŒ Oracle DB ì ì¬ ì‹¤íŒ¨: {db_error}")

                                # ì—ëŸ¬ ìƒì„¸ ì •ë³´
                                with st.expander("ğŸ” DB ì—ëŸ¬ ìƒì„¸"):
                                    st.code(str(db_error))

                                    # í•´ê²° ë°©ë²• ì•ˆë‚´
                                    st.markdown("""
                                    **í•´ê²° ë°©ë²•:**
                                    1. **ì¤‘ë³µ ë°ì´í„° ì—ëŸ¬ (ORA-00001):**
                                       - ì•„ë˜ SQLì„ ì‹¤í–‰í•˜ì—¬ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ:
                                       ```sql
                                       TRUNCATE TABLE TB_PLAN_ACHIEVEMENTS;
                                       TRUNCATE TABLE TB_PLAN_PERFORMANCE;
                                       TRUNCATE TABLE TB_PLAN_SCHEDULE;
                                       TRUNCATE TABLE TB_PLAN_BUDGET;
                                       TRUNCATE TABLE TB_PLAN_DATA;
                                       ```
                                       - ë˜ëŠ” Streamlit ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.
                                    
                                    2. **ì—°ê²° ì‹¤íŒ¨:**
                                       - Oracle ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                                       - config.pyì˜ ì ‘ì† ì •ë³´ í™•ì¸
                                    """)

                                # DB ì ì¬ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ CSVëŠ” ìƒì„±ë¨
                                st.warning("âš ï¸ CSV íŒŒì¼ì€ ì •ìƒ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 'CSV ë°ì´í„°' íƒ­ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                        else:
                            progress_bar.progress(1.0)

                        elapsed = time.time() - start_time

                        status_text.empty()
                        progress_bar.empty()

                        # ì™„ë£Œ ë©”ì‹œì§€
                        st.success(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
                        st.balloons()

                        # ê²°ê³¼ ìš”ì•½
                        if enable_db_load and db_stats:
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ğŸ“„ ì²˜ë¦¬ ì„±ê³µ", f"{success_count}/{len(results)}")
                            with col2:
                                if norm_stats:
                                    st.metric("ğŸ“Š ë‚´ì—­ì‚¬ì—…", f"{norm_stats['plan_data']}ê°œ")
                            with col3:
                                st.metric("âœ… ë§¤ì¹­ ì„±ê³µ", f"{db_stats.get('matched', 0)}ê±´")
                            with col4:
                                st.metric("ğŸ—„ï¸ DB ì ì¬", f"{db_stats['total_records']:,}ê±´")

                            # ë§¤ì¹­ ì‹¤íŒ¨ ê²½ê³ 
                            if db_stats.get('unmatched', 0) > 0:
                                st.warning(f"âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: {db_stats['unmatched']}ê±´ - ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
                                st.info(f"ğŸ“„ ë¦¬í¬íŠ¸ ìœ„ì¹˜: `{SERVER_NORMALIZED_DIR}/matching_reports/`")

                            # ì°¨ì´ì  ë°œê²¬ ì•ˆë‚´
                            if db_stats.get('diff_found', 0) > 0:
                                st.info(f"â„¹ï¸ {db_stats['diff_found']}ê±´ì˜ ë ˆì½”ë“œì—ì„œ ê¸°ì¡´ ë°ì´í„°ì™€ ì°¨ì´ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. (diff_report.csv í™•ì¸)")
                        else:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ğŸ“„ ì²˜ë¦¬ ì„±ê³µ", f"{success_count}/{len(results)}")
                            with col2:
                                if norm_stats:
                                    st.metric("ğŸ“Š ë‚´ì—­ì‚¬ì—…", f"{norm_stats['plan_data']}ê°œ")
                            with col3:
                                st.metric("ğŸ“‹ CSV ìƒì„±", "ì™„ë£Œ")

                    except Exception as e:
                        st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        import traceback
                        with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬"):
                            st.code(traceback.format_exc())

    with tab2:
        st.header("ì²˜ë¦¬ ê²°ê³¼")

        if st.session_state.processing_results:
            results = st.session_state.processing_results

            success = [r for r in results if r['status'] == 'success']
            failed = [r for r in results if r['status'] == 'failed']

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ íŒŒì¼", len(results))
            with col2:
                st.metric("ì„±ê³µ", len(success), delta_color="normal")
            with col3:
                st.metric("ì‹¤íŒ¨", len(failed), delta_color="inverse")

            # ì„±ê³µ ëª©ë¡
            if success:
                st.subheader("âœ… ì„±ê³µ")
                for r in success:
                    st.write(f"- {r['file']}")

            # ì‹¤íŒ¨ ëª©ë¡
            if failed:
                st.subheader("âŒ ì‹¤íŒ¨")
                for r in failed:
                    st.error(f"- {r['file']}: {r.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

            # ì •ê·œí™” í†µê³„
            if st.session_state.normalized_stats:
                st.subheader("ğŸ“Š ì •ê·œí™” í†µê³„")
                stats = st.session_state.normalized_stats

                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("ë©”ì¸ ë°ì´í„°", stats['plan_data'])
                with col2:
                    st.metric("ì˜ˆì‚°", stats['budgets'])
                with col3:
                    st.metric("ì¼ì •", stats['schedules'])
                with col4:
                    st.metric("ì„±ê³¼", stats['performances'])
                with col5:
                    st.metric("ëŒ€í‘œì„±ê³¼", stats['achievements'])

                st.info("â„¹ï¸ TB_PLAN_DATA(ë©”ì¸) + 4ê°œ í•˜ìœ„ í…Œì´ë¸”ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.")
        else:
            st.info("â„¹ï¸ ì•„ì§ ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab3:
        st.header("CSV ë°ì´í„°")

        st.markdown("""
        **ğŸ“‹ í…Œì´ë¸” êµ¬ì¡°:**
        - **TB_PLAN_DATA**: ë‚´ì—­ì‚¬ì—… ë©”ì¸ ì •ë³´ (íšŒì‚¬ ê¸°ì¡´ 43ê°œ ì»¬ëŸ¼)
        - **TB_PLAN_BUDGET**: ì—°ë„ë³„ ì˜ˆì‚° ìƒì„¸ (ì‹¤ì /ê³„íš êµ¬ë¶„)
        - **TB_PLAN_SCHEDULE**: ì¼ì • ìƒì„¸ (ì‹¤ì œ ì›” ì •ë³´ ìš°ì„  íŒŒì‹± âœ¨)
        - **TB_PLAN_PERFORMANCE**: ì„±ê³¼ ìƒì„¸ (ì •ëŸ‰ì  + ì •ì„±ì  âœ¨)
        - **TB_PLAN_ACHIEVEMENTS**: ëŒ€í‘œì„±ê³¼
        """)

        if SERVER_NORMALIZED_DIR.exists():
            display_csv_data(SERVER_NORMALIZED_DIR)
        else:
            st.info("â„¹ï¸ CSV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ì„¸ìš”.")

    with tab4:
        st.header("Oracle DB í†µê³„")

        if st.session_state.db_stats:
            stats = st.session_state.db_stats

            # ë§¤ì¹­ í†µê³„
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ì ì¬ ë ˆì½”ë“œ", f"{stats['total_records']:,}ê±´")
            with col2:
                st.metric("âœ… ë§¤ì¹­ ì„±ê³µ", f"{stats.get('matched', 0)}ê±´", delta_color="normal")
            with col3:
                st.metric("âŒ ë§¤ì¹­ ì‹¤íŒ¨", f"{stats.get('unmatched', 0)}ê±´", delta_color="inverse")
            with col4:
                st.metric("âš ï¸ ì°¨ì´ì  ë°œê²¬", f"{stats.get('diff_found', 0)}ê±´", delta_color="off")

            # ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ í‘œì‹œ
            if stats.get('unmatched', 0) > 0:
                st.warning(f"âš ï¸ {stats['unmatched']}ê±´ì˜ ë ˆì½”ë“œê°€ ê¸°ì¡´ TB_PLAN_DATAì™€ ë§¤ì¹­ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                # unmatched_records.csv ì½ê¸°
                unmatched_csv = SERVER_NORMALIZED_DIR / "matching_reports" / "unmatched_records.csv"
                if unmatched_csv.exists():
                    with st.expander("ğŸ“„ ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ ìƒì„¸ ë³´ê¸°", expanded=True):
                        try:
                            unmatched_df = pd.read_csv(unmatched_csv, encoding='utf-8-sig')

                            st.write(f"**ì´ {len(unmatched_df)}ê±´ì˜ ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ**")

                            # í•„í„°ë§ ì˜µì…˜
                            col_filter1, col_filter2 = st.columns(2)
                            with col_filter1:
                                year_filter = st.multiselect(
                                    "ì—°ë„ í•„í„°",
                                    options=sorted(unmatched_df['year'].unique()),
                                    default=sorted(unmatched_df['year'].unique())
                                )
                            with col_filter2:
                                search_text = st.text_input("ê²€ìƒ‰ (BIZ_NM ë˜ëŠ” DETAIL_BIZ_NM)", "")

                            # í•„í„° ì ìš©
                            filtered_df = unmatched_df[unmatched_df['year'].isin(year_filter)]
                            if search_text:
                                filtered_df = filtered_df[
                                    filtered_df['biz_nm'].str.contains(search_text, case=False, na=False) |
                                    filtered_df['detail_biz_nm'].str.contains(search_text, case=False, na=False)
                                ]

                            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
                            display_cols = ['csv_index', 'year', 'biz_nm', 'detail_biz_nm', 'reason']
                            if all(col in filtered_df.columns for col in display_cols):
                                display_df = filtered_df[display_cols]
                            else:
                                display_df = filtered_df

                            st.dataframe(
                                display_df,
                                use_container_width=True,
                                height=400
                            )

                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            csv_data = unmatched_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ ë‹¤ìš´ë¡œë“œ (CSV)",
                                data=csv_data,
                                file_name="unmatched_records.csv",
                                mime='text/csv'
                            )

                            # íŒ¨í„´ ë¶„ì„
                            st.subheader("ğŸ” ë§¤ì¹­ ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„")

                            # BIZ_NM = DETAIL_BIZ_NMì¸ ê²½ìš°
                            same_name = unmatched_df[unmatched_df['biz_nm'] == unmatched_df['detail_biz_nm']]
                            if len(same_name) > 0:
                                st.info(f"ğŸ“Œ BIZ_NMê³¼ DETAIL_BIZ_NMì´ ë™ì¼í•œ ê²½ìš°: {len(same_name)}ê±´ (ì‹ ê·œ ì‚¬ì—…ì¼ ê°€ëŠ¥ì„±)")

                            # ì—°ë„ë³„ ë§¤ì¹­ ì‹¤íŒ¨ ê±´ìˆ˜
                            year_counts = unmatched_df['year'].value_counts().sort_index()
                            st.write("**ì—°ë„ë³„ ë§¤ì¹­ ì‹¤íŒ¨ ê±´ìˆ˜:**")
                            for year, count in year_counts.items():
                                st.write(f"- {year}ë…„: {count}ê±´")

                        except Exception as e:
                            st.error(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨ ë ˆì½”ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                else:
                    st.info("ğŸ“„ ë§¤ì¹­ ë¦¬í¬íŠ¸: `normalized_output_government/matching_reports/unmatched_records.csv`")

            # ì°¨ì´ì  ë°œê²¬ ë ˆì½”ë“œ í‘œì‹œ
            if stats.get('diff_found', 0) > 0:
                st.info(f"â„¹ï¸ {stats['diff_found']}ê±´ì˜ ë ˆì½”ë“œì—ì„œ ê¸°ì¡´ ë°ì´í„°ì™€ ì°¨ì´ì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # diff_report.csv ì½ê¸°
                diff_csv = SERVER_NORMALIZED_DIR / "matching_reports" / "diff_report.csv"
                if diff_csv.exists():
                    with st.expander("ğŸ“„ ì°¨ì´ì  ë°œê²¬ ë ˆì½”ë“œ ìƒì„¸ ë³´ê¸°"):
                        try:
                            diff_df = pd.read_csv(diff_csv, encoding='utf-8-sig')

                            st.write(f"**ì´ {len(diff_df)}ê±´ì˜ ì°¨ì´ì  ë°œê²¬**")

                            st.dataframe(
                                diff_df,
                                use_container_width=True,
                                height=300
                            )

                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            csv_data = diff_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ ì°¨ì´ì  ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (CSV)",
                                data=csv_data,
                                file_name="diff_report.csv",
                                mime='text/csv'
                            )
                        except Exception as e:
                            st.error(f"âŒ ì°¨ì´ì  ë¦¬í¬íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                else:
                    st.info("ğŸ“„ ì°¨ì´ì  ë¦¬í¬íŠ¸: `normalized_output_government/matching_reports/diff_report.csv`")

            st.subheader("ğŸ“Š í…Œì´ë¸”ë³„ í†µê³„")

            table_data = []
            for table, count in stats['records_by_table'].items():
                table_data.append({'í…Œì´ë¸”': table, 'ë ˆì½”ë“œ ìˆ˜': f"{count:,}ê±´"})

            df = pd.DataFrame(table_data)
            st.dataframe(df, width=None)

        else:
            st.info("â„¹ï¸ Oracle DB ì ì¬ í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

            if not enable_db_load:
                st.warning("âš ï¸ 'Oracle DB ì ì¬' ì˜µì…˜ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    ìƒëª…ê³µí•™ìœ¡ì„±ì‹œí–‰ê³„íš PDF â†’ Oracle DB ì²˜ë¦¬ ì‹œìŠ¤í…œ v1.0 | 2025
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()

